{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e07442d8-4d84-4dc1-83b3-75a7f310644f",
   "metadata": {},
   "source": [
    "# Cross Tokenizer Knowledge Distillation\n",
    "- Quelle: https://github.com/Nicolas-BZRD/llm-recipes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2926a1-8646-423e-a694-d68ebfc6cd86",
   "metadata": {},
   "source": [
    "## Activate Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "005873f3-d82b-418a-af36-4b0526571ba4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(/home/thsch026/my-envs/llm-distillation) \n"
     ]
    }
   ],
   "source": [
    "conda activate llm-distillation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8547592-0bb5-4451-a4ad-6944066b8de0",
   "metadata": {},
   "source": [
    "## 1. Im ersten Schritt wird aus einem Datenset eine Antwort Datei mit dem Teacher Modell erstellt\n",
    "- Für \"train\" und \"validation\" getrennt ausführen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26015bc5-9037-4028-a52b-3f53da8f0b6b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Erstellt die Antwort Datei für die Distillation mit Mistral-7B-Instruct-v0.2 als teacher - Basis Dataset ist rajpurkar/squad\n",
    "\n",
    "- Muss einmal mit train und einmal mit validation ausgeführt werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e51541-8e20-40e3-a362-f5fb24a1e9c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cd /home/thsch026/\n",
    "\n",
    "python llm-distillation/datasets/generator.py \\\n",
    "--model_id mistralai/Mistral-7B-Instruct-v0.2 \\\n",
    "--model_tokenizer mistralai/Mistral-7B-Instruct-v0.2 \\\n",
    "--dataset_id rajpurkar/squad \\\n",
    "--split_name train \\\n",
    "--number_few_shot 5 \\\n",
    "--batch_size 4 \\\n",
    "--bfloat \\\n",
    "--task qa_generative \\\n",
    "--mapping llm-distillation/benchmark/mapping/squad.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca81ca1-72f2-4356-874e-d65c272849c1",
   "metadata": {},
   "source": [
    "### Erstellt die Antwort Datei für die Distillation mit Llama-2-7b-chat-hf als teacher - Basis Dataset ist rajpurkar/squad\n",
    "- Muss einmal mit train und einmal mit validation ausgeführt werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8982bf-368f-400c-a916-4413971f6f96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(/home/thsch026/my-envs/llm-distillation) \n",
      "(/home/thsch026/my-envs/llm-distillation) \n",
      "INFO:root:Start\n",
      "INFO:root:Device: cuda\n",
      "INFO:root:Loading tokenizer...\n",
      "INFO:root:Tokenizer loaded.\n",
      "INFO:root:Loading model...\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.61s/it]\n",
      "INFO:root:Model loaded.\n",
      "INFO:root:Processing dataset...\n",
      "Map: 100%|████████████████████████| 10570/10570 [00:23<00:00, 453.19 examples/s]\n",
      "Map: 100%|████████████████████████| 10570/10570 [00:16<00:00, 655.03 examples/s]\n",
      "meta-llama/Llama-2-7b-chat-hf\n",
      "<s>[INST] <<SYS>>\n",
      "You are an expert agent in reading comprehension (question answering). You must read and understand the contextual text step by step, then answer the question. The answer must be brief between 0 to 15 words\n",
      "<</SYS>>\n",
      "\n",
      "Context: So, she jumped up with her lint and her lint cards, and the tailor jumped up with his great shears, and one apprentice grasped the line measure, while another took up the saucer full of pins; and they all tried to catch the wee bannock. But it dodged them round and round the fire, and at last it got safely out of the door and ran down the road, with one of the apprentices after it, who tried to snip it in two with his shears. It ran too quickly for him, however, and at last he stopped and went back to the house, while the wee bannock ran on until it came to a tiny cottage by the roadside. it trundled in at the door, and there was a weaver sitting at his loom, with his wife beside him, winding a clue of yarn.\n",
      "Question: How did the bannock escape from the tailor's wife and the three tailors? [/INST] Answer: Dodged them round and round the fire, and at last it got safely out of the door and ran down the road. </s><s>[INST] Context: Then he took the prince by the hand, led him deep down in the earth into his cave, and there on the wall hung a suit of armor altogether forged of the clearest silver, and so bright that it shone afar. Right beside it stood a snow - white steed, saddled and bridled, pawing the earth with his silver hoofs, and champing his bit till the foam dropped to the ground. The wild man said: 'now get quickly into your armor, ride out and try your luck! in the meantime I will tend your oxen.' The prince did not wait to be told a second time; but put on his helmet and armor in all haste, securely buckled on his spurs, hung his sword at his side, and felt as light in his silver armor as a bird in the air. Then he leaped into the saddle so that every clasp and buckle rang, laid his reins on the neck of his steed, and rode hastily toward the glass mountain.\n",
      "Question: What was the suit of armor given by the wild man forged from? [/INST] Answer: The clearest silver. </s><s>[INST] Context: He knew very well that he had enough inside him to buy up all the other toys, and this gave him a very good opinion of his own value. The rest thought of this fact also, although they did not express it, for there were so many other things to talk about. A large doll, still handsome, though rather old, for her neck had been mended, lay inside one of the drawers which was partly open. She called out to the others, 'let us have a game at being men and women, that is something worth playing at.'\n",
      "Question: Why didn't the other toys talk about how valuable the pig was? [/INST] Answer: There were so many other things to talk about. </s><s>[INST] Context: When confucius came to the earth, the kilin, that strange beast which is the prince of all four - footed animals, and only appears when there is a great man on earth, sought the child and spat out a jade whereon was written: 'son of the watercrystal you are destined to become an uncrowned king!' and confucius grew up, studied diligently, learned wisdom and came to be a saint. He did much good on earth, and ever since his death has been reverenced as the greatest of teachers and masters. He had foreknowledge of many things and even after he had died, he gave evidence of this.\n",
      "Question: Why was confucius's death reverenced as the greatest of teachers and masters? [/INST] Answer: He did much good on earth. </s><s>[INST] Context: 'Oh, let me in! Let me in! I'm cold, and I'm so wet!' Exclaimed suddenly a child that stood crying at the door and knocking for admittance, while the rain poured down, and the wind made all the windows rattle. 'Poor thing!' said the old poet, as he went to open the door. there stood a little boy, quite naked, and the water ran down from his long golden hair. He trembled with cold, and had he not come into a warm room he would most certainly have perished in the frightful tempest.\n",
      "Question: Why did the boy ask to come inside? [/INST] Answer: He was cold and wet. </s><s>[INST] Context: Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.\n",
      "Question: Which NFL team represented the AFC at Super Bowl 50? [/INST] Answer:\n",
      "INFO:root:Dataset processed...\n",
      "INFO:root:Starting predictions...\n",
      "  0%|                                                  | 0/1322 [00:00<?, ?it/s]/home/thsch026/my-envs/llm-distillation/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/thsch026/my-envs/llm-distillation/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      " 13%|████▉                                 | 170/1322 [27:13<3:05:13,  9.65s/it]\r"
     ]
    }
   ],
   "source": [
    "cd /home/thsch026/\n",
    "\n",
    "python llm-distillation/datasets/generator.py \\\n",
    "--model_id meta-llama/Llama-2-7b-chat-hf \\\n",
    "--model_tokenizer meta-llama/Llama-2-7b-chat-hf \\\n",
    "--dataset_id rajpurkar/squad \\\n",
    "--split_name validation \\\n",
    "--number_few_shot 5 \\\n",
    "--batch_size 8 \\\n",
    "--task qa_generative \\\n",
    "--mapping llm-distillation/benchmark/mapping/squad.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391ebdd1-ade1-451e-8b50-8790f50f3cd4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Im zweiten Schritt wird die eigentliche Knowledge Distillation (mittels der Antwort Datei) mit dem Student Model durchgeführt \n",
    "- Vorher müssen die Antwortdateien (für train und vaildation) mit dem jeweiligen Datenset und dem Lehremodell erstellt werden - Schritt 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fb233fe-2237-48a3-aca0-05305f728657",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(/home/thsch026/my-envs/llm-distillation) \n"
     ]
    }
   ],
   "source": [
    "export CUDA_VISIBLE_DEVICES=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9881405-4370-4efd-aa38-c1ebd24cf389",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cd /home/thsch026/\n",
    "export SAVEDIR=\"/home/thsch026/masterarbeit/models/generated/dist/Llama2_dist_pythia-410_deduped\"\n",
    "\n",
    "python -m torch.distributed.launch llm-recipes/finetuning.py \\\n",
    "--model_name EleutherAI/pythia-410m-deduped \\\n",
    "--dataset.file llm-distillation/datasets/loader/squad.py \\\n",
    "--lr 1e-6 \\\n",
    "--num_epochs 1 \\\n",
    "--batch_size_training 8 \\\n",
    "--val_batch_size 8 \\\n",
    "--output_dir $SAVEDIR \\\n",
    "--distillation_config.model_name meta-llama/Llama-2-7b-chat-hf \\\n",
    "--distillation \\\n",
    "--distillation_config.enable_fsdp \\\n",
    "--distillation_config.distil_factor 1.5 \\\n",
    "--save_step 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e91e47-ef8f-4e68-868a-3a7183adbadf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "###  3. Ein Beispiel für den Versuch das ganze mit Mistral und dem squad datenset zu machen\n",
    "- Auch wenn run_validation auf False steht muss ein validation Dataset vorhanden sein!\n",
    "- Das Loader File ist recht knifflig. Es soll beide Datensätze laden, validation und train\n",
    "- Epochs habe ich auf 1 gesetzt, wobei das schon lange dauert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e13352-0304-498a-9a5d-3ad45d354010",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Variablen setzen als Workaround (Wird wohl nicht gebraucht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c01558c5-9582-4cca-b345-a738db7a9209",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(/home/thsch026/my-envs/torchtune) \n",
      "(/home/thsch026/my-envs/torchtune) \n",
      "(/home/thsch026/my-envs/torchtune) \n",
      "(/home/thsch026/my-envs/torchtune) \n",
      "(/home/thsch026/my-envs/torchtune) \n"
     ]
    }
   ],
   "source": [
    "export RANK=1\n",
    "export WORLD_SIZE=1\n",
    "export MASTER_ADDR=localhost\n",
    "export MASTER_PORT=12345\n",
    "cd /home/thsch026/masterarbeit/experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68496290-a626-491a-94d6-0c89e0714452",
   "metadata": {},
   "source": [
    "Hier ein funktionierender Approach für das squad datenset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615dcb53-e496-4f70-aadf-e8e85df63035",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cd /home/thsch026/\n",
    "export SAVEDIR=\"/home/thsch026/masterarbeit/models/generated/dist/Llama2_dist_pythia-410_deduped\"\n",
    "\n",
    "python -m torch.distributed.launch llm-recipes/finetuning.py \\\n",
    "--model_name EleutherAI/pythia-410m-deduped \\\n",
    "--enable_fsdp \\\n",
    "--run_validation False \\\n",
    "--dataset.file llm-distillation/datasets/loader/squad.py \\\n",
    "--lr 1e-6 \\\n",
    "--num_epochs 1 \\\n",
    "--batch_size_training 4 \\\n",
    "--val_batch_size 4 \\\n",
    "--output_dir $SAVEDIR \\\n",
    "--save_step 1000 \\\n",
    "--distillation \\\n",
    "--distillation_config.model_name mistralai/Mistral-7B-Instruct-v0.2 \\\n",
    "--distillation_config.enable_fsdp \\\n",
    "--distillation_config.distil_factor 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceac3cd0-53cf-4417-ad81-042d81dc93aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
