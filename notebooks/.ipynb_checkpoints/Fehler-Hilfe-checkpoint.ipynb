{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8f1ac5-6980-4cf0-8e73-b88bab44a63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Traceback (most recent call last):\n",
    "  File \"/home/thsch026/my-envs/eval/bin/lm_eval\", line 8, in <module>\n",
    "    sys.exit(cli_evaluate())\n",
    "  File \"/home/thsch026/masterarbeit/work/lm-evaluation-harness/lm_eval/__main__.py\", line 347, in cli_evaluate\n",
    "    results = evaluator.simple_evaluate(\n",
    "  File \"/home/thsch026/masterarbeit/work/lm-evaluation-harness/lm_eval/utils.py\", line 316, in _wrapper\n",
    "    return fn(*args, **kwargs)\n",
    "  File \"/home/thsch026/masterarbeit/work/lm-evaluation-harness/lm_eval/evaluator.py\", line 292, in simple_evaluate\n",
    "    results[\"config\"].update(lm.get_model_info())\n",
    "  File \"/home/thsch026/masterarbeit/work/lm-evaluation-harness/lm_eval/models/huggingface.py\", line 1310, in get_model_info\n",
    "    \"model_num_parameters\": get_model_num_params(self._model),\n",
    "  File \"/home/thsch026/masterarbeit/work/lm-evaluation-harness/lm_eval/models/huggingface.py\", line 1287, in get_model_num_params\n",
    "    return model.num_parameters()\n",
    "  File \"/home/thsch026/my-envs/eval/lib/python3.10/site-packages/transformers/modeling_utils.py\", line 1165, in num_parameters\n",
    "    quant_storage.itemsize if hasattr(quant_storage, \"itemsize\") else quant_storage.element_size()\n",
    "AttributeError: 'torch.dtype' object has no attribute 'element_size'\n",
    "wandb: üöÄ View run Llama3 8B Instruct QLora at: https://wandb.ai/pumaai/lm-eval-harness-integration/runs/saiaja98\n",
    "wandb: ‚≠êÔ∏è View project at: https://wandb.ai/pumaai/lm-eval-harness-integration\n",
    "wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
    "wandb: Find logs at: ./wandb/run-20240703_081438-saiaja98/logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88f0fb0-8c20-486f-aa12-1423b6f425e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Fehler slow tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a030d5ad-7c68-4f71-baa5-11227222884f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ValueError: Cannot instantiate this tokenizer from a slow version. If it's based on sentencepiece, make sure you have sentencepiece installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0de8ee4-a6b7-44c7-bd50-fe8c8c06e428",
   "metadata": {},
   "outputs": [],
   "source": [
    "L√∂sung: Sentencepiece installieren auch wenn es eigentlich schon im Environment it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43eb625-e1ce-4447-9e69-bdcbc95a36ec",
   "metadata": {},
   "source": [
    "## Mergen eines LORA Modells (Adapter + Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bb3c5f-8444-4088-8ced-2ea9782073ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import AutoPeftModelForCausalLM\n",
    "\n",
    "# Local path, check post scriptum for explanation\n",
    "model_id = \"./ArcturusAI/Crystalline-1.1B-v23.12-tagger\"\n",
    "peft_model = AutoPeftModelForCausalLM.from_pretrained(model_id)\n",
    "print(type(peft_model))\n",
    "\n",
    "merged_model = peft_model.merge_and_unload()\n",
    "# The adapters are merged now and it is transformers class again\n",
    "print(type(merged_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8f05e1-4e98-4285-8983-5363d772b4aa",
   "metadata": {},
   "source": [
    "## Probleme mit wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a746ae5f-9f91-4276-8128-fe4291a6086c",
   "metadata": {},
   "outputs": [],
   "source": [
    "AttributeError: module 'wandb' has no attribute 'log'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067ebf4b-2ec5-4131-ae1f-723011998951",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5f5a0f-2671-4493-9cff-3b5aba79d143",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install wandb\n",
    "# restart notebook\n",
    "import wandb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
