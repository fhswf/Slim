{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58a16ba8-ce96-479f-8e25-eb48bd7affc4",
   "metadata": {},
   "source": [
    "# LM evaluation harness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9fce36-6947-49a3-b4c8-c943353185d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Das Evaluation framework scheint gut geeignet für Tests mit verschiedenen Benchmarks. Das Repository hierzu ist https://github.com/EleutherAI/lm-evaluation-harness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e13934-9c8a-4aac-a3cd-3274b20c17a6",
   "metadata": {},
   "source": [
    "Cite\n",
    "@misc{eval-harness,\n",
    "  author       = {Gao, Leo and Tow, Jonathan and Abbasi, Baber and Biderman, Stella and Black, Sid and DiPofi, Anthony and Foster, Charles and Golding, Laurence and Hsu, Jeffrey and Le Noac'h, Alain and Li, Haonan and McDonell, Kyle and Muennighoff, Niklas and Ociepa, Chris and Phang, Jason and Reynolds, Laria and Schoelkopf, Hailey and Skowron, Aviya and Sutawika, Lintang and Tang, Eric and Thite, Anish and Wang, Ben and Wang, Kevin and Zou, Andy},\n",
    "  title        = {A framework for few-shot language model evaluation},\n",
    "  month        = 12,\n",
    "  year         = 2023,\n",
    "  publisher    = {Zenodo},\n",
    "  version      = {v0.4.0},\n",
    "  doi          = {10.5281/zenodo.10256836},\n",
    "  url          = {https://zenodo.org/records/10256836}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f83c29b-0866-486e-b14f-9b100ac98b5f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup Environment (Muss nach jedem Neustart des Servers erfolgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c128c22-ea8c-46f0-8afa-2117627be1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(/home/thsch026/my-envs/eval) \n",
      "(/home/thsch026/my-envs/eval) \n",
      "(/home/thsch026/my-envs/eval) \n"
     ]
    }
   ],
   "source": [
    "conda activate eval\n",
    "#pip install torch==2.0.1 packaging\n",
    "cd \"/home/thsch026/masterarbeit/work/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8b202c-cffb-4de1-8dac-2b1c3e8ccf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone Git Repo and install dependencies\n",
    "git clone https://github.com/EleutherAI/lm-evaluation-harness\n",
    "cd lm-evaluation-harness\n",
    "pip install -e .\n",
    "# pip install torch==2.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d20d83c-1d06-43ad-a28c-cf0cbd1dfed1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### In einigen Fällen wird 'sentencepiece' verwendet und muss installiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1c5296-97b5-4aa2-9dc1-3a75ba877a77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1ad3c4-8524-4d78-b473-f4d74af10b92",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Installliert wandb falls nicht vorhanden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c11bac-3e86-4d06-9ffc-d95ffdafdaf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install lm_eval[wandb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43095741-716f-48f1-b861-b6be04e8aead",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072a96de-dfc2-4a20-bc46-a0beae36e57b",
   "metadata": {},
   "outputs": [],
   "source": [
    " #export MODEL=\"/home/thsch026/masterarbeit/models/llama3/Meta-Llama-3-8B-Instruct-HF\"\n",
    "export MODEL=\"/home/thsch026/masterarbeit/models/generated/llama3-8B-lora-instruct-toxic\"\n",
    "lm_eval \\\n",
    "    --model hf \\\n",
    "    --model_args pretrained=$MODEL \\\n",
    "    --tasks hellaswag \\\n",
    "    --device cuda:0 \\\n",
    "    --batch_size 8 \\\n",
    "    --log_samples \\\n",
    "    --output_path output/llama2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884f0180-2e33-4808-84bf-a33d7a8f5e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = \"EleutherAI/gpt-j-6B\"\n",
    "#!export MODEL=\"/home/thsch026/masterarbeit/models/llama3/Meta-Llama-3-8B-Instruct-HF\"\n",
    "export MODEL=\"Weyaxi/Einstein-v6.1-Llama3-8B\"\n",
    "\n",
    "lm_eval --model hf  --model_args pretrained=$MODEL  --tasks hellaswag --device cuda:0 --batch_size 8 --output_path \"../../out_eval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eedb6b6-73ec-4c84-af47-ecee705eaf57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Beispiel für eine Visualisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddc4dd9-ae78-4ae3-84be-36eb4f37a671",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize\n",
    "# Zeno APi Key = zen_JmwQ0TQiAxDxsbV34hDZSBA6XcI4GFR88cNBTLSCruY\n",
    "\n",
    "export ZENO_API_KEY=zen_JmwQ0TQiAxDxsbV34hDZSBA6XcI4GFR88cNBTLSCruY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a9abfd-e1fc-4f5e-8f68-b21219164d65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conda activate eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce1e050-5b78-4a88-9e82-1b7761de00d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export MODEL=\"Weyaxi/Einstein-v6.1-Llama3-8B\" # Precached LlamaModel from HF\n",
    "\n",
    "lm_eval --model hf  --model_args pretrained=$MODEL,dtype=float16  --tasks hellaswag --device cuda:0 --batch_size 4 --log_samples --output_path \"/home/thsch026/masterarbeit/experiment/out_eval\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b51f0b-97c6-4ce4-984c-405a36811fa0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cd /home/thsch026/masterarbeit/experiment/lm-evaluation-harness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8674163-1bec-4584-94a9-82c6a43ff2c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "python scripts/zeno_visualize.py --data_path ../out_eval --project_name \"Initial Tests\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94548b4-be57-49c2-aa62-4623309df86a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export MODEL=\"Weyaxi/Einstein-v6.1-Llama3-8B\" # Precached LlamaModel from HF\n",
    "#export MODEL=\"/home/thsch026/masterarbeit/models/generated/llama3-8B-lora-instruct-toxic/checkpoint-3810\"\n",
    "export MODEL=\"/home/thsch026/masterarbeit/models/llama3/Meta-Llama-3-8B-Instruct-HF\"\n",
    "export MODEL=\"/home/thsch026/masterarbeit/models/llama3/Meta-Llama-3-8B-Instruct-HF\"\n",
    "\n",
    "lm_eval --model hf  --model_args pretrained=$MODEL,dtype=float16,tokenizer=\"/home/thsch026/masterarbeit/models/llama3/Meta-Llama-3-8B-Instruct-HF\"  --tasks hellaswag --device cuda:0 --batch_size 4 --wandb_args project=lm-eval-harness-integration --log_samples --output_path \"/home/thsch026/masterarbeit/experiment/out_wan\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b52f75-aa1b-48e9-969f-9fe05b8267c8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Produktive Evaluierungen mit Visualisierung (Mit Weights and Biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7709b69e-edd6-424e-9ac4-554b888f3463",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation run HINWEISE\n",
    "-> Das JSON config file des Checkpoints muss nach config.json kopiert werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db4e05c-5bc5-4bf9-9d3b-4d77dd913e75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conda activate eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1578520a-dd7a-477b-b24a-99cf3e53a0d2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Benchmarks für die Referenzmodelle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0f6c62-53e9-4144-b820-f7305f55cd83",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Reference Model Llama-3-8B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e75a3e-c048-4d1e-b6ac-ee1ba68f2a29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export MODEL=\"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "export WANDB_NAME=\"Llama 3 8B instruct Referenz\"\n",
    "export WANDB_NOTES=\"Llama 3 8B instruct Referenz Messung\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5cbf69-9fcf-4395-a2c6-57dca59dfb61",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Reference Model LLama-3-8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046b1906-7068-490a-9f80-858303e06664",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export MODEL=\"meta-llama/Meta-Llama-3-8B\"\n",
    "export WANDB_NAME=\"meta-llama/Meta-Llama-3-8B\"\n",
    "export WANDB_NOTES=\"Meta-Llama-3-8B Referenz Messung\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9178a104-eacb-4216-a2d8-8f9673643a79",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Reference Model Mistral-7B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47414e4f-d417-43a5-b26c-786586d19fff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(/home/thsch026/my-envs/eval) \n",
      "(/home/thsch026/my-envs/eval) \n",
      "(/home/thsch026/my-envs/eval) \n",
      "(/home/thsch026/my-envs/eval) \n"
     ]
    }
   ],
   "source": [
    "# Reference Model Mistral-7B-Instruct\n",
    "export MODEL=\"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "export WANDB_NAME=\"Mistral-7B-Instruct Referenz\"\n",
    "export WANDB_NOTES=\"Mistral-7B-Instruct Referenz Messung\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d934aab3-0694-4501-b0d2-710d83b085f6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Reference Model Llama-2-7B chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129cb4a1-16b8-43ac-95fb-af12e689a3c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reference Model Llama-2-7B chat\n",
    "export MODEL=\"meta-llama/Llama-2-7b-chat-hf\"\n",
    "export WANDB_NAME=\"Llama-2-7B-chat-hf\"\n",
    "export WANDB_NOTES=\"Llama2-7B-chat Referenz Messung\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d641358a-0888-4efc-9084-2432b269a511",
   "metadata": {},
   "source": [
    "#### Pruned Model Mistral 7B ohne die Layer 22-29"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b4d10d-4123-4cf3-962e-7e205b394e61",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Benchmarks AutoAWQ Kompression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447c11fa-612b-49df-ae39-f4ac9374f627",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install autoawq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2154ba4f-fe53-4eaa-b92a-50a9d07e9d5b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Llama-3-8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdcd88b-c3cd-490f-ab5d-f826b6e7a6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Llama-3-8B AutoAWQ\n",
    "export MODEL=\"/home/thsch026/masterarbeit/models/generated/llm-awq/Llama-3-8B-AWQ-4bit\"\n",
    "\n",
    "# Settings für die WANDB Darstellung\n",
    "export WANDB_NAME=\"Llama-3-8B AutoAWQ \"\n",
    "export WANDB_NOTES=\"Llama3 quantized in 4 Bit with Autoawq\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a155685-7a52-49e8-8e58-cf34c49c2ed9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### LLama-3-8B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6191bda9-4d41-4dc3-be2c-d9140a842ecf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Llama-3-8B AutoAWQ\n",
    "export MODEL=\"/home/thsch026/masterarbeit/models/generated/llm-awq/Meta-Llama-3-8B-Instruct-AWQ\"\n",
    "\n",
    "# Settings für die WANDB Darstellung\n",
    "export WANDB_NAME=\"Llama 3 8B Instruct AWQ \"\n",
    "export WANDB_NOTES=\"Llama3 8B Instruct quantized in 4 Bit with Autoawq\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69435d96-0ae2-4c55-a337-8f1c757ea2d2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Mistral 7B instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d544d80-5989-4dab-9d85-0ccf8e12525b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "export MODEL=\"/home/thsch026/masterarbeit/models/generated/llm-awq/Mistral-7B-Instruct-v0.2-AWQ-4bit\"\n",
    "\n",
    "# Settings für die WANDB Darstellung\n",
    "export WANDB_NAME=\"Mistral 7B Instruct v0.2 AWQ-4bit\"\n",
    "export WANDB_NOTES=\"Mistral 7B quantized with AWQ to 4 Bit\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6b6486-ec10-4ca0-ae1e-9d8cd67e1c41",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Llama2-7B-chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013b1be7-5f91-4215-aac8-db7528a19346",
   "metadata": {},
   "outputs": [],
   "source": [
    "export MODEL=\"/home/thsch026/masterarbeit/models/generated/llm-awq/Llama-2-7b-chat-HF-AWQ-4bit\"\n",
    "\n",
    "# Settings für die WANDB Darstellung\n",
    "export WANDB_NAME=\"Llama-2-7b-chat-HF-AWQ-4bit\"\n",
    "export WANDB_NOTES=\"LLama-2-7B quantized with AWQ to 4 Bit\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4500d1b1-7799-4258-87ef-68322112c204",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Benchmarks Pruning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7f6eeb-56f6-49b3-a078-cce766fdee0f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Benchmarks Pruning mit Wanda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec971da-6f54-43d9-889d-cfa80036a919",
   "metadata": {},
   "outputs": [],
   "source": [
    "export MODEL=\"/home/thsch026/masterarbeit/models/generated/prune/wanda/\"\n",
    "\n",
    "# Settings für die WANDB Darstellung\n",
    "export WANDB_NAME=\"Llama-2-7b-chat-HF-Pruned\"\n",
    "export WANDB_NOTES=\"LLama-2-7B pruned with wanda\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d0443d-f03e-491b-817f-58c24d28b385",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Benchmarks Pruning  mit PruneMe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a466fe-a93c-4349-b28b-b3c5bb3e3bfd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Pruned Model Llama3-8B-Instruct-HF 8 Layer reduziert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c976b2-9dea-4817-9684-f6a7f813da65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export MODEL=\"/home/thsch026/masterarbeit/models/generated/prune/pruneme/Meta-Llama-3-8B-Instruct-8_Ext\"\n",
    "export WANDB_NAME=\"Llama-3-8B-Instruct PruneMe 8_Ext \"\n",
    "export WANDB_NOTES=\"Llama3 8B Instruct Layer 23-29 mit PruneMe extrahiert\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86c016e-42b6-4c86-bb9b-c9f64005a08c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Pruned Model Llama3-8B-Instruct-HF 12 Layer reduziert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d82056-bc4c-48a7-b44f-ebba1fd282ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export MODEL=\"/home/thsch026/masterarbeit/models/generated/prune/pruneme/Meta-Llama-3-8B-Instruct-12_Ext\"\n",
    "export WANDB_NAME=\"Llama-3-8B-Instruct PruneMe 12_Ext \"\n",
    "export WANDB_NOTES=\"Llama3 8B Instruct 12 Layer mit PruneMe extrahiert\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9279779-6112-48a1-bcc0-6b6f556e66fd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Pruned Model Llama3-8B 8 Layer reduziert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511b0726-1849-4608-bc50-21806c3d92a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export MODEL=\"/home/thsch026/masterarbeit/models/generated/prune/pruneme/Meta-Llama-3-8B-8_Ext\"\n",
    "export WANDB_NAME=\"Llama-3-8B PruneMe 8_Ext \"\n",
    "export WANDB_NOTES=\"Llama3 8B Instruct 8 Layer mit PruneMe extrahiert\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514040fd-07ee-4ed2-8f97-72b6ddd322bc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Pruned Model Llama3-8B 12 Layer reduziert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8361b6dc-22c7-42d7-8b14-b98bc53b587e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export MODEL=\"/home/thsch026/masterarbeit/models/generated/prune/pruneme/Meta-Llama-3-8B-12_Ext\"\n",
    "export WANDB_NAME=\"Llama-3-8B PruneMe 12_Ext \"\n",
    "export WANDB_NOTES=\"Llama3 8B Instruct 12 Layer mit PruneMe extrahiert\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93755c80-7e9b-4994-8bfa-ab2933b6c8b8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Pruned Model Mistral 7B 8 Layer reduziert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f124c3-4e11-4f9d-8302-f183746f9387",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export MODEL=\"/home/thsch026/masterarbeit/models/generated/prune/pruneme/Mistral-7B-Instruct-v0.2-8_Ext\"\n",
    "export WANDB_NAME=\"Mistral 7B Instruct PruneMe 8_Ext \"\n",
    "export WANDB_NOTES=\"Mistral 7B Instruct 8 Layer mit PruneMe extrahiert\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9142eed1-bda6-4e48-95e9-b920cbc5a463",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Pruned Model Mistral 7B 12 Layer reduziert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df0e187-fc1d-490f-8fca-d4fa5763cba6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export MODEL=\"/home/thsch026/masterarbeit/models/generated/prune/pruneme/Mistral-7B-Instruct-v0.2-12_Ext\"\n",
    "export WANDB_NAME=\"Mistral 7B Instruct PruneMe 12_Ext \"\n",
    "export WANDB_NOTES=\"Mistral 7B Instruct 12 Layer mit PruneMe extrahiert\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1951c52-fb83-4518-8e88-f90b789864fb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Pruned Model Llama2 7B Chat 8 Layer reduziert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a596fd-e429-4e38-b326-58f28645476a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export MODEL=\"/home/thsch026/masterarbeit/models/generated/prune/pruneme/Llama-2-7b-chat-hf-8_Ext\"\n",
    "export WANDB_NAME=\"Llama2 7B chat PruneMe 8_Ext \"\n",
    "export WANDB_NOTES=\"Llama2 7B chat 8 Layer mit PruneMe extrahiert\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf642c3-0be0-4c1f-af38-939453e868c7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Pruned Model Llama2 7B Chat 12 Layer reduziert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bfc1f9-a750-40a6-8801-9039b5818077",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export MODEL=\"/home/thsch026/masterarbeit/models/generated/prune/pruneme/Llama-2-7b-chat-hf-12_Ext\"\n",
    "export WANDB_NAME=\"Llama2 7B chat PruneMe 12_Ext \"\n",
    "export WANDB_NOTES=\"Llama2 7B chat 12 Layer mit PruneMe extrahiert\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee023a3-4598-41dc-9e62-d399132a6234",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Pruned Model Mistral 7B ohne die Layer 22-29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66be1d4b-2741-4fbf-9f1c-cf15491dba0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export MODEL=\"/home/thsch026/masterarbeit/models/generated/prune/pruneme/mistral7_pruneme\"\n",
    "export WANDB_NAME=\"Mistral7 B PruneMe \"\n",
    "export WANDB_NOTES=\"Mistral7B Layer 22-29 mit PruneMe extrahiert\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3221c68-2e39-4d4d-9d91-d3f414828334",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Pruned Model Llama2-7B-Chat-HF ohne die Layer 21-29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97fac01-01ee-4583-9ed2-410fe14c8a6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export MODEL=\"/home/thsch026/masterarbeit/models/generated/prune/pruneme/llama2_pruneme\"\n",
    "export WANDB_NAME=\"Llama2 PruneMe \"\n",
    "export WANDB_NOTES=\"Llama2 Layer 21-29 mit PruneMe extrahiert\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11dfb4c-4e7e-4d80-87e4-625f84f32557",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Pruned Model Llama2-7B-Chat-HF ohne die Layer 18-30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73641b8c-8a2c-47e5-a5ea-9121dfd279ac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Pruning mit shortened-llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa677da8-fb29-4ab4-bda9-fbbf845a1320",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Meta-LLama-3-8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e653992-aa8d-44cd-a36e-946c68a3f122",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export MODEL=\"/home/thsch026/masterarbeit/models/generated/prune/shortened-llm/Meta-LLama-3-8B\"\n",
    "export WANDB_NAME=\"Meta LLama 3 8B shortened llm\"\n",
    "export WANDB_NOTES=\"Meta LLama 3 8B shortened llm six layers extracted\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6924a6ab-1b12-41b9-a0d6-f2bbcb9937f5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Meta LLama 3 8B instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698f99fd-e99a-4d57-ad82-262d61be7f59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export MODEL=\"/home/thsch026/masterarbeit/models/generated/prune/shortened-llm/Meta-LLama-3-8B-instruct\"\n",
    "export WANDB_NAME=\"Meta LLama 3 8B instruct shortened llm\"\n",
    "export WANDB_NOTES=\"Meta LLama 3 8B instruct shortened llm six layers extracted\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7265bc70-c699-4f77-8712-c81ad515ba4b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Mistral-7B-Instruct-v02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedcf0f0-a16b-4dc9-92c5-db53932c147c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export MODEL=\"/home/thsch026/masterarbeit/models/generated/prune/shortened-llm/Mistral-7B-Instruct-v02\"\n",
    "export WANDB_NAME=\"Mistral-7B-Instruct-v02 shortened llm\"\n",
    "export WANDB_NOTES=\"Mistral-7B-Instruct-v02 shortened llm six layers extracted\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e60b5c-163c-446e-904d-570f53aa0f09",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Llama-2-7b-hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7178eae-0658-4bfc-b558-c200984b6ac0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export MODEL=\"/home/thsch026/masterarbeit/models/generated/prune/shortened-llm/Llama-2-7b-hf\"\n",
    "export WANDB_NAME=\"Llama-2-7b-hf shortened llm\"\n",
    "export WANDB_NOTES=\"Llama-2-7b-hf shortened llm six layers extracted\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec199dc-83cc-4f12-b4c2-bff072ac0694",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Llama 2 7b chat hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5285fc4d-2bb1-40ad-8331-723c8fa5293b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export MODEL=\"/home/thsch026/masterarbeit/models/generated/prune/shortened-llm/Llama-2-7b-chat-hf\"\n",
    "export WANDB_NAME=\"Llama 2 7b chat hf shortened llm\"\n",
    "export WANDB_NOTES=\"Llama 2 7b chat hf shortened llm six layers extracted\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fd8740-8f94-46ca-a4ea-620c1c871ea5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Benchmarks LORA Kompression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654828e6-85f7-4fbf-8869-a42a478b97ec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Llama-3-8B (Daten ms_marco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b02fb41-ec3f-4095-aab3-8b2ad5269a92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export MODEL=\"/home/thsch026/masterarbeit/models/generated/lora/Meta-Llama-3-8B_ms-marco/model\"\n",
    "export WANDB_NAME=\"Llama3 8B Lora\"\n",
    "export WANDB_NOTES=\"Llama3 8B Lora mit Datensatz ms_marco v1.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c264dea-2d3e-4bba-af29-d60a0363d1a0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Mistral 7B Instruct(Daten ms_marco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd8b598-a4f7-41b3-99e8-ab55be5f4f0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export MODEL=\"/home/thsch026/masterarbeit/models/generated/lora/mistral_7B-Instruct_ms-marco/model\"\n",
    "export WANDB_NAME=\"Mistral 7B Instruct Lora\"\n",
    "export WANDB_NOTES=\"Mistral 7B Instruct - Lora mit Datensatz ms_marco v1.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ef0202-a9f8-4dd2-988d-250771f1fe70",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Llama 3 8B instruct (Daten ms_marco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b5cb76-0883-4553-bfc4-c95754834843",
   "metadata": {},
   "outputs": [],
   "source": [
    "export MODEL=\"/home/thsch026/masterarbeit/models/generated/lora/Llama-3-8B-Instruct-HF_ms-marco\"\n",
    "export WANDB_NAME=\"Llama 3 8B instruct Lora ms_marco\"\n",
    "export WANDB_NOTES=\"Llama 3 8B instruct Lora mit Datensatz ms_marco v1.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfefaf7-d3f4-4594-bb3d-81104ee442b7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Llama 2 7B chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ce87e6-de5b-4f8c-9499-cfd2256133ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export MODEL=\"/home/thsch026/masterarbeit/models/generated/lora/Llama-2-7b-chat_ms-marco/model\"\n",
    "export WANDB_NAME=\"Llama 2 7B chat Lora ms_marco\"\n",
    "export WANDB_NOTES=\"Llama 2 7B chat - Lora mit Datensatz ms_marco v1.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1da2250-4694-4435-abb2-942314d59fac",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Benchmarks Qlora Kompression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faafbe4-5766-4760-adaa-6d20e2dc1513",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Llama2 7B Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118dafc3-968c-4ad2-96a4-ee000b5568fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export MODEL=\"/home/thsch026/masterarbeit/models/generated/qlora/Llama-2-7b-chat-hf_qlora\"\n",
    "export WANDB_NAME=\"Llama2 7B chat QLora\"\n",
    "export WANDB_NOTES=\"Llama2 7B chat QLora mit Datensatz ?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd2496c-1dd8-43ef-8acd-274403dd6d2d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Llama3 8B Instruct 17.500 Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e863eae-3990-4fe4-8846-928f26b4dc81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(/home/thsch026/my-envs/eval) \n",
      "(/home/thsch026/my-envs/eval) \n",
      "(/home/thsch026/my-envs/eval) \n",
      "(/home/thsch026/my-envs/eval) \n",
      "(/home/thsch026/my-envs/eval) \n"
     ]
    }
   ],
   "source": [
    "# export MODEL=\"/home/thsch026/masterarbeit/models/generated/qlora/Meta-Llama-3-8B-Instruct_qlora\"\n",
    "export MODEL=\"/home/thsch026/masterarbeit/models/generated/qlora/Meta-Llama-3-8B-Instruct_qlora/merged\"\n",
    "export TOKENIZER=\"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "export WANDB_NAME=\"Llama 3 8B instruct QLoRA\"\n",
    "export WANDB_NOTES=\"Llama 3 8B instruct QLoRA mit Datensatz utlrachat\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccccaab5-82ae-4a8a-817f-d7ba7a7fa663",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Llama3 8B Instruct 5000 Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7b3ec4d-9ea3-499a-a44c-f66d80e0ba2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(/home/thsch026/my-envs/eval) \n",
      "(/home/thsch026/my-envs/eval) \n",
      "(/home/thsch026/my-envs/eval) \n",
      "(/home/thsch026/my-envs/eval) \n"
     ]
    }
   ],
   "source": [
    "export MODEL=\"/home/thsch026/masterarbeit/models/generated/qlora/Meta-Llama-3-8B-Instruct_qlora/merged_low\"\n",
    "export TOKENIZER=\"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "export WANDB_NAME=\"Llama 3 8B instruct QLoRA low\"\n",
    "export WANDB_NOTES=\"Llama 3 8B instruct QLoRA mit Datensatz utlrachat 5000 Steps\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b50631-521e-403b-bc08-6ab139d32ae6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Mistral 7B instruct v02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c269ed7d-2506-4428-805d-a20cc6bb848b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(/home/thsch026/my-envs/eval) \n",
      "(/home/thsch026/my-envs/eval) \n",
      "(/home/thsch026/my-envs/eval) \n",
      "(/home/thsch026/my-envs/eval) \n"
     ]
    }
   ],
   "source": [
    "export MODEL=\"/home/thsch026/masterarbeit/models/generated/qlora/Mistral-7B-Instruct-v0.2_qlora\"\n",
    "export ADAPTER=\"/home/thsch026/masterarbeit/models/generated/qlora/Meta-Llama-3-8B-Instruct_qlora/checkpoint-17241\"\n",
    "export WANDB_NAME=\"Mistral 7B instruct v02 QLora\"\n",
    "export WANDB_NOTES=\"Mistral 7B instruct v02 mit Datensatz ?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f2b321-ca8b-4cbe-a861-b2a6daeaee4c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Benchmarks Lora plus Pruning Kompression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5147bb-10f9-42d4-97c5-e4048eaa741d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Meta Llama 3 8B (prune + lora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99e1e6d-3d17-4fc8-b871-ba95c2b1fb3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export MODEL=\"/home/thsch026/masterarbeit/models/generated/prune_plus_lora/shortened-llm/Meta-Llama-3-8B_prune_lora\"\n",
    "export WANDB_NAME=\"Meta Llama 3 8B prune + lora\"\n",
    "export WANDB_NOTES=\"Meta Llama 3 8B prune + lora\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75df298f-fafa-4a6e-b32b-1e915591a6b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Meta Llama 3 8B instruct (prune + lora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808d2f69-defc-445e-a9d0-645a13336b09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export MODEL=\"/home/thsch026/masterarbeit/models/generated/prune_plus_lora/shortened-llm/Meta-Llama-3-8B-instruct_prune_lora\"\n",
    "export WANDB_NAME=\"Meta Llama 3 8B instruct prune + lora\"\n",
    "export WANDB_NOTES=\"Meta Llama 3 8B  instruct prune + lora\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9d1bbc-dc15-43df-b48c-428ba2160fbf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Mistral 7B Instruct v02 (prune + lora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6172be2-8c65-4a95-b4f8-574cacf20586",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export MODEL=\"/home/thsch026/masterarbeit/models/generated/prune_plus_lora/shortened-llm/Mistral-7B-Instruct-v02_prune_lora\"\n",
    "export WANDB_NAME=\"Mistral 7B Instruct v02 prune + lora\"\n",
    "export WANDB_NOTES=\"Mistral 7B Instruct v02 prune + lora\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf13f10b-6541-4bb4-8e87-79f32fbaafbb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Llama 2 7b hf (prune + lora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d612ab1-b9f5-4c90-9ab4-06af73fd289d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export MODEL=\"/home/thsch026/masterarbeit/models/generated/prune_plus_lora/shortened-llm/Llama-2-7b-hf_prune_lora\"\n",
    "export WANDB_NAME=\"Llama 2 7b hf prune + lora\"\n",
    "export WANDB_NOTES=\"Llama 2 7b hf prune + lora\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ceedbf3-06e8-4bba-bc24-e4f9f89ec6cc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Llama 2 7b chat hf (prune + lora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2255d9c9-878d-4ae1-bf4a-bfdeed54626d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export MODEL=\"/home/thsch026/masterarbeit/models/generated/prune_plus_lora/shortened-llm/Llama-2-7b-chat-hf_prune_lora\"\n",
    "export WANDB_NAME=\"Llama 2 7b chat hf prune + lora\"\n",
    "export WANDB_NOTES=\"Llama 2 7b chat hf prune + lora\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90fd28e-2ad8-4d33-8a21-b022bf1991b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### GPTQ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaeedd25-d2b5-489e-af2d-fa5b62da98fa",
   "metadata": {},
   "source": [
    "#### Llama 3 8B Instruct GPTQ 4bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b485701-59e5-4192-bd03-97812ba8f145",
   "metadata": {},
   "outputs": [],
   "source": [
    "export MODEL=\"/home/thsch026/masterarbeit/models/generated/gptq/Meta-Llama-3-8B-instruct_gptq\"\n",
    "export WANDB_NAME=\"Llama 3 8B Instruct GPTQ\"\n",
    "export WANDB_NOTES=\"Llama 3 8B Instruct GPTQ 4Bit GroupSize 128\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba28733-71b5-41c3-b70f-b05ccbe530e0",
   "metadata": {},
   "source": [
    "#### Llama 3 8B Instruct GPTQ 3bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29965da0-89ba-41f7-8731-d52346d2d5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(/home/thsch026/my-envs/eval) \n",
      "(/home/thsch026/my-envs/eval) \n",
      "(/home/thsch026/my-envs/eval) \n"
     ]
    }
   ],
   "source": [
    "export MODEL=\"/home/thsch026/masterarbeit/models/generated/gptq/Meta-Llama-3-8B-instruct_gptq_3bit\"\n",
    "export WANDB_NAME=\"Llama 3 8B Instruct GPTQ 3bit\"\n",
    "export WANDB_NOTES=\"Llama 3 8B Instruct GPTQ 3Bit GroupSize 128\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8808c0fc-19da-4d03-a72e-8579e5a14559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(/home/thsch026/my-envs/eval) \n",
      "(/home/thsch026/my-envs/eval) \n",
      "(/home/thsch026/my-envs/eval) \n"
     ]
    }
   ],
   "source": [
    "export MODEL=\"/home/thsch026/masterarbeit/models/generated/gptq/Meta-Llama-3-8B-instruct_gptq_2bit\"\n",
    "export WANDB_NAME=\"Llama 3 8B Instruct GPTQ 2bit\"\n",
    "export WANDB_NOTES=\"Llama 3 8B Instruct GPTQ 2Bit GroupSize 128\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02fd6f2-c0f7-49f4-a596-c8676d29c1d9",
   "metadata": {},
   "source": [
    "#### Mistral 7B Instruct GPTQ 4 Bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9dabbe-c1ff-468a-bd10-01f2cc42e04e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export MODEL=\"/home/thsch026/masterarbeit/models/generated/gptq/Mistral-7B-Instruct-v0.2_gptq\"\n",
    "export WANDB_NAME=\"Mistral 7B Instruct v02 GPTQ\"\n",
    "export WANDB_NOTES=\"Mistral 7B Instruct v02 GPTQ 4Bit GroupSize 128\"\n",
    "#export TOKENIZER=\"meta-llama/Meta-Llama-3-8B-Instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e454c3-2727-40a6-8ec5-7b8a20cf3d70",
   "metadata": {},
   "source": [
    "#### Mistral 7B Instruct GPTQ 3 Bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e55279a-f8ce-49e8-a0b9-61aa1a7f305b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export MODEL=\"/home/thsch026/masterarbeit/models/generated/gptq/Mistral-7B-Instruct-v0.2_gptq_3bit\"\n",
    "export WANDB_NAME=\"Mistral 7B Instruct v02 GPTQ 3Bit\"\n",
    "export WANDB_NOTES=\"Mistral 7B Instruct v02 GPTQ 3Bit GroupSize 128\"\n",
    "#export TOKENIZER=\"meta-llama/Meta-Llama-3-8B-Instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e706176b-ccfe-42a5-9c86-eff81e7abeaa",
   "metadata": {},
   "source": [
    "#### Mistral 7B Instruct GPTQ 2 Bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fdfed5e-1ee3-495a-b6a9-b5c764cdb5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(/home/thsch026/my-envs/eval) \n",
      "(/home/thsch026/my-envs/eval) \n",
      "(/home/thsch026/my-envs/eval) \n"
     ]
    }
   ],
   "source": [
    "export MODEL=\"/home/thsch026/masterarbeit/models/generated/gptq/Mistral-7B-Instruct-v0.2_gptq_2bit\"\n",
    "export WANDB_NAME=\"Mistral 7B Instruct v02 GPTQ 2Bit\"\n",
    "export WANDB_NOTES=\"Mistral 7B Instruct v02 GPTQ 2Bit GroupSize 128\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d917250b-dc39-4abe-b3b0-061b752d84dd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## TEST Lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab4e2d9d-63c6-4582-9dbe-c73c6cb32870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(/home/thsch026/my-envs/eval) \n",
      "(/home/thsch026/my-envs/eval) \n",
      "(/home/thsch026/my-envs/eval) \n",
      "(/home/thsch026/my-envs/eval) \n"
     ]
    }
   ],
   "source": [
    "export MODEL=\"/home/thsch026/masterarbeit/models/generated/lora/Llama-3-8B-Instruct_ms-marco/merged\"\n",
    "export TOKENIZER=\"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "export WANDB_NAME=\"Llama-3-8B-Instruct_ms-marco\"\n",
    "export WANDB_NOTES=\"Llama-3-8B-Instruct_ms-marco\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ed3849-d294-4086-904e-5e2c744f3257",
   "metadata": {},
   "source": [
    "# EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36c6b231-89d0-4671-b554-64db09310cf8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(/home/thsch026/my-envs/eval) \n",
      "0,1,2,3\n",
      "(/home/thsch026/my-envs/eval) \n"
     ]
    }
   ],
   "source": [
    "export CUDA_VISIBLE_DEVICES=\"0,1,2,3\"\n",
    "echo $CUDA_VISIBLE_DEVICES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008948cd-707c-4a66-bc59-8112140a0622",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Perplexity evaluation  with wikitext\n",
    "- Runs seperate because of high memory consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf346160-5e9f-4f40-a814-2e81bb81534e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lm_eval --tasks list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91b17bb1-15fa-466b-89c3-fd6d5f2fe087",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(/home/thsch026/my-envs/eval) \n",
      "(/home/thsch026/my-envs/eval) \n",
      "(/home/thsch026/my-envs/eval) \n",
      "Running task for:\n",
      "(/home/thsch026/my-envs/eval) \n",
      "Llama 3 8B instruct QLoRA low WIKI WIKI\n",
      "(/home/thsch026/my-envs/eval) \n",
      "Llama 3 8B instruct QLoRA mit Datensatz utlrachat 5000 Steps WIKI WIKI\n",
      "(/home/thsch026/my-envs/eval) \n",
      "(/home/thsch026/my-envs/eval) \n",
      "(/home/thsch026/my-envs/eval) \n",
      "usage: lm_eval [-h] [--model MODEL] [--tasks task1,task2]\n",
      "               [--model_args MODEL_ARGS] [--num_fewshot N]\n",
      "               [--batch_size auto|auto:N|N] [--max_batch_size N]\n",
      "               [--device DEVICE] [--output_path DIR|DIR/file.json]\n",
      "               [--limit N|0<N<1] [--use_cache DIR]\n",
      "               [--cache_requests {true,refresh,delete}] [--check_integrity]\n",
      "               [--write_out] [--log_samples]\n",
      "               [--system_instruction SYSTEM_INSTRUCTION]\n",
      "               [--apply_chat_template [APPLY_CHAT_TEMPLATE]]\n",
      "               [--fewshot_as_multiturn] [--show_config] [--include_path DIR]\n",
      "               [--gen_kwargs GEN_KWARGS]\n",
      "               [--verbosity CRITICAL|ERROR|WARNING|INFO|DEBUG]\n",
      "               [--wandb_args WANDB_ARGS] [--hf_hub_log_args HF_HUB_LOG_ARGS]\n",
      "               [--predict_only] [--seed SEED] [--trust_remote_code]\n",
      "lm_eval: error: unrecognized arguments: dtype=float16,use_safetensors=True,parallelize=True\n",
      "(/home/thsch026/my-envs/eval) \n"
     ]
    },
    {
     "ename": "",
     "evalue": "2",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "# Modify entries for the results\n",
    "export WANDB_NAME=$WANDB_NAME\" WIKI\"\n",
    "export WANDB_NOTES=$WANDB_NOTES\" WIKI\"\n",
    "echo \"Running task for:\"\n",
    "echo $WANDB_NAME\n",
    "echo $WANDB_NOTES\n",
    "# --wandb_args project=lm-eval-harness-integration\n",
    "# Run Task\n",
    "lm_eval --model hf  --model_args pretrained=$MODEL,tokenizer=$TOKENIZER,dtype=float16,use_safetensors=True,parallelize=True --tasks wikitext \\\n",
    "        --limit 0.1 --device cuda --batch_size auto  --log_samples \\\n",
    "        --output_path \"/home/thsch026/masterarbeit/Slim/results\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e855ea19-1663-48e9-aaa0-9886a4e3d9f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluation with Standard Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c437d8e-0dbc-49f1-83e0-3dca5586c090",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bc3c0e6-2eb8-462e-b6aa-58b287b17205",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mthomas-t-schmitt\u001b[0m (\u001b[33mpumaai\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.18.1 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/thsch026/masterarbeit/work/wandb/run-20240923_124918-ilafzkw5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mLlama 3 8B instruct QLoRA low\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/pumaai/lm-eval-harness-integration\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/pumaai/lm-eval-harness-integration/runs/ilafzkw5\u001b[0m\n",
      "2024-09-23:12:49:28,454 INFO     [__main__.py:279] Verbosity set to INFO\n",
      "2024-09-23:12:49:33,721 INFO     [__init__.py:491] `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.\n",
      "2024-09-23:12:50:21,520 INFO     [__main__.py:376] Selected Tasks: ['arc_challenge', 'hellaswag', 'truthfulqa_mc2', 'winogrande']\n",
      "2024-09-23:12:50:21,610 INFO     [evaluator.py:161] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2024-09-23:12:50:21,610 INFO     [evaluator.py:198] Initializing hf model, with arguments: {'pretrained': '/home/thsch026/masterarbeit/models/generated/qlora/Meta-Llama-3-8B-Instruct_qlora/merged_low', 'dtype': 'float16', 'tokenizer': 'meta-llama/Meta-Llama-3-8B-Instruct'}\n",
      "2024-09-23:12:50:21,773 INFO     [huggingface.py:138] Device not specified\n",
      "2024-09-23:12:50:21,774 INFO     [huggingface.py:139] Cuda Available? True\n",
      "/home/thsch026/my-envs/eval/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "2024-09-23:12:50:22,810 INFO     [huggingface.py:366] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda'}\n",
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "Loading checkpoint shards: 100%|█████████████████| 2/2 [03:54<00:00, 117.17s/it]\n",
      "2024-09-23:12:54:21,144 WARNING  [big_modeling.py:450] You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "2024-09-23:12:55:03,262 INFO     [evaluator.py:279] Setting fewshot random generator seed to 1234\n",
      "2024-09-23:12:55:03,263 INFO     [evaluator.py:279] Setting fewshot random generator seed to 1234\n",
      "2024-09-23:12:55:03,263 INFO     [evaluator.py:279] Setting fewshot random generator seed to 1234\n",
      "2024-09-23:12:55:03,263 INFO     [evaluator.py:279] Setting fewshot random generator seed to 1234\n",
      "2024-09-23:12:55:03,263 WARNING  [model.py:422] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.\n",
      "2024-09-23:12:55:03,325 INFO     [task.py:423] Building contexts for winogrande on rank 0...\n",
      "100%|████████████████████████████████████| 1267/1267 [00:00<00:00, 94980.93it/s]\n",
      "2024-09-23:12:55:03,379 INFO     [task.py:423] Building contexts for truthfulqa_mc2 on rank 0...\n",
      "100%|███████████████████████████████████████| 817/817 [00:00<00:00, 1003.01it/s]\n",
      "2024-09-23:12:55:04,250 INFO     [task.py:423] Building contexts for hellaswag on rank 0...\n",
      "100%|███████████████████████████████████| 10042/10042 [00:03<00:00, 3258.99it/s]\n",
      "2024-09-23:12:55:09,712 INFO     [task.py:423] Building contexts for arc_challenge on rank 0...\n",
      "100%|█████████████████████████████████████| 1172/1172 [00:00<00:00, 1600.81it/s]\n",
      "2024-09-23:12:55:10,505 INFO     [evaluator.py:465] Running loglikelihood requests\n",
      "Running loglikelihood requests:   0%|                 | 0/53271 [00:00<?, ?it/s]Passed argument batch_size = auto:1. Detecting largest batch size\n",
      "Determined largest batch size: 64\n",
      "Running loglikelihood requests: 100%|████| 53271/53271 [07:36<00:00, 116.67it/s]\n",
      "2024-09-23:13:03:14,556 WARNING  [huggingface.py:1344] Failed to get model SHA for /home/thsch026/masterarbeit/models/generated/qlora/Meta-Llama-3-8B-Instruct_qlora/merged_low at revision main. Error: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/home/thsch026/masterarbeit/models/generated/qlora/Meta-Llama-3-8B-Instruct_qlora/merged_low'. Use `repo_type` argument if needed.\n",
      "fatal: not a git repository (or any parent up to mount point /home)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
      "2024-09-23:13:03:53,107 INFO     [evaluation_tracker.py:206] Saving results aggregated\n",
      "2024-09-23:13:03:53,150 INFO     [evaluation_tracker.py:287] Saving per-sample results for: arc_challenge\n",
      "2024-09-23:13:04:00,972 INFO     [evaluation_tracker.py:287] Saving per-sample results for: hellaswag\n",
      "2024-09-23:13:04:58,291 INFO     [evaluation_tracker.py:287] Saving per-sample results for: truthfulqa_mc2\n",
      "2024-09-23:13:05:03,142 INFO     [evaluation_tracker.py:287] Saving per-sample results for: winogrande\n",
      "hf (pretrained=/home/thsch026/masterarbeit/models/generated/qlora/Meta-Llama-3-8B-Instruct_qlora/merged_low,dtype=float16,tokenizer=meta-llama/Meta-Llama-3-8B-Instruct), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: auto (64)\n",
      "|    Tasks     |Version|Filter|n-shot| Metric |   |Value |   |Stderr|\n",
      "|--------------|------:|------|-----:|--------|---|-----:|---|-----:|\n",
      "|arc_challenge |      1|none  |     0|acc     |↑  |0.5290|±  |0.0146|\n",
      "|              |       |none  |     0|acc_norm|↑  |0.5478|±  |0.0145|\n",
      "|hellaswag     |      1|none  |     0|acc     |↑  |0.5715|±  |0.0049|\n",
      "|              |       |none  |     0|acc_norm|↑  |0.7539|±  |0.0043|\n",
      "|truthfulqa_mc2|      2|none  |     0|acc     |↑  |0.5169|±  |0.0153|\n",
      "|winogrande    |      1|none  |     0|acc     |↑  |0.7190|±  |0.0126|\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             arc_challenge/acc ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        arc_challenge/acc_norm ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: arc_challenge/acc_norm_stderr ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      arc_challenge/acc_stderr ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 hellaswag/acc ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            hellaswag/acc_norm ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     hellaswag/acc_norm_stderr ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          hellaswag/acc_stderr ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            truthfulqa_mc2/acc ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     truthfulqa_mc2/acc_stderr ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                winogrande/acc ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         winogrande/acc_stderr ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             arc_challenge/acc 0.52901\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        arc_challenge/acc_norm 0.54778\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: arc_challenge/acc_norm_stderr 0.01454\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      arc_challenge/acc_stderr 0.01459\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           arc_challenge/alias arc_challenge\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 hellaswag/acc 0.5715\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            hellaswag/acc_norm 0.75393\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     hellaswag/acc_norm_stderr 0.0043\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          hellaswag/acc_stderr 0.00494\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               hellaswag/alias hellaswag\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            truthfulqa_mc2/acc 0.51689\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     truthfulqa_mc2/acc_stderr 0.0153\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          truthfulqa_mc2/alias truthfulqa_mc2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                winogrande/acc 0.71902\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         winogrande/acc_stderr 0.01263\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              winogrande/alias winogrande\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mLlama 3 8B instruct QLoRA low\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/pumaai/lm-eval-harness-integration/runs/ilafzkw5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/pumaai/lm-eval-harness-integration\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 5 media file(s), 10 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240923_124918-ilafzkw5/logs\u001b[0m\n",
      "(/home/thsch026/my-envs/eval) \n"
     ]
    }
   ],
   "source": [
    "lm_eval --model hf  --model_args pretrained=$MODEL,dtype=float16,tokenizer=$TOKENIZER  --tasks arc_challenge,truthfulqa_mc2,winogrande,hellaswag \\\n",
    "        --device cuda:$CUDA_VISIBLE_DEVICES --batch_size auto --wandb_args project=lm-eval-harness-integration --log_samples \\\n",
    "        --output_path \"/home/thsch026/masterarbeit/Slim/results\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62d91dd-f69d-4313-9ee7-d558b722e5b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## lm_eval HELP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e574a66-397e-468f-bafa-c1681a44889c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lm-eval --tasks list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d98dba-8c95-4ec5-8863-7309a69e12c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_eval --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4b74b5-2e8f-4f5a-9ddf-30e35273e619",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
