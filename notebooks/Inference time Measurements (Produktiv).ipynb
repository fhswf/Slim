{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ae2d401-5489-46dc-88b7-73ad6c6d3bad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Old"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749fb1ae-5a15-49cf-8cf1-cbcbb59b4bc7",
   "metadata": {},
   "source": [
    "### Importieren der Klassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb41a6c-b844-4b75-b3b6-40ccaa6fd134",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import bitsandbytes as bnb\n",
    "import accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086184b8-7c23-4d03-814e-782bf9bf11b7",
   "metadata": {},
   "source": [
    "### Festlegen des Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba8932f-6a50-4b70-aa75-8aa20571ff4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id=\"/home/thsch026/masterarbeit/models/generated/llm-awq/Meta-Llama-3-8B-Instruct-HF-AWQ-4bit\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79d4441-2950-4b88-a4ff-39589bbb08d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Initialisieren des Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911c81b9-1c3f-494c-a8f4-2d2d6f2b8dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.bfloat16)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    quantization_config=quantization_config, #load_in_8bit=True,#\n",
    "    device_map='auto',\n",
    "    token='<EOL>'\n",
    ")\n",
    "#peft_model = \"BojanaBas/Meta-Llama-3-8B-Instruct-pqa-10\"\n",
    "#model = PeftModel.from_pretrained(base_model, peft_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af0835d-38d5-4be2-97f3-d32e45bb6510",
   "metadata": {},
   "source": [
    "### Inferenz Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab0212d-3b3a-4eb3-879a-6da6f9520374",
   "metadata": {},
   "source": [
    "### Autoawq library is needed to test inference with AWQ Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87aba23-5f11-42ca-b81b-6f924586513d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install autoawq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9015bb47-a9ad-4180-a267-90f9326b1106",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Eingabetext\n",
    "input_text = \"Once upon a time\"\n",
    "#input_text = \"Why should I eat healthy?\"\n",
    "\n",
    "# Tokenisiere den Eingabetext\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
    "\n",
    "# Messe die Zeit vor der Inferenz\n",
    "start_time = time.time()\n",
    "\n",
    "# Führe die Inferenz durch\n",
    "outputs = model.generate(input_ids, max_length=50)\n",
    "\n",
    "# Messe die Zeit nach der Inferenz\n",
    "end_time = time.time()\n",
    "\n",
    "# Berechne die Inferenz-Zeit\n",
    "inference_time = end_time - start_time\n",
    "\n",
    "# Dekodiere die Ausgabe\n",
    "output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "number_of_words = len(output_text.split())\n",
    "number_of_tokens = len(outputs[0])\n",
    "\n",
    "token_per_second = number_of_tokens/inference_time\n",
    "\n",
    "print(f\"Inferenz-Zeit: {inference_time} Sekunden\")\n",
    "print(f\"Output: {output_text}\")\n",
    "print(\"Tokens per second: \", token_per_second)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16792f78-12ba-48e8-9a19-f1675d48c46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Die neuen Daten, die hinzugefügt werden sollen\n",
    "neue_daten = ['Lukas', 28]\n",
    "\n",
    "# Öffne die Datei im Anhangsmodus ('a' steht für append)\n",
    "with open('daten.csv', mode='a', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    # Schreibe die neuen Daten in die CSV-Datei\n",
    "    writer.writerow(neue_daten)\n",
    "\n",
    "print(\"Neue Daten erfolgreich hinzugefügt.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e4c0ba-cebb-48bc-84f2-0916b8869830",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df63ba6c-7a05-4ad8-9731-c24e1cb9bb01",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluierung Modelle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05cdc7a-fc84-4f70-b419-5071a1a37ff2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Sentencepiece muss ggf. noch mal installiert werden für Mistral (fast tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d6026d-5fbb-43c5-b93e-b96dc8eafed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e30b253-4a58-4ba9-9a75-f3a553365b89",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Laden der libaries und festlegen der GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1de386e7-4cb0-4987-9d7e-38fc6ec2bdc9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:256\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "!echo $CUDA_VISIBLE_DEVICES\n",
    "# torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e57cfb40-2d1c-4f5f-adc0-9134f7f08c46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import bitsandbytes as bnb\n",
    "import accelerate\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad42e67d-5f77-419a-bed4-7cb0f1f2cb11",
   "metadata": {},
   "source": [
    "### Ergebnis Dateien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "993981e1-1528-4ea8-b4ef-cca2461b922e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_csv= \"/home/thsch026/masterarbeit/Slim/results/inference/inference_full.csv\"\n",
    "data_csv= \"/home/thsch026/masterarbeit/Slim/results/inference/inference_data_only.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a740d057-2c5f-48fb-89ab-b69dbb4eabd9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##  1. Referenz Modelle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ab7136-9c90-40d2-b7c0-495b09e3edbc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Llama-3-8B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edba68fd-af1a-4718-8701-aeb759c15015",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id =\"Meta-Llama-3-8B-Instruct\"\n",
    "model_loc = \"meta-llama/Meta-Llama-3-8B-Instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09dbea4-d24c-43b4-b174-1ce3a9e9bcd4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Mistral-7B-Instruct-v0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c612ad07-641b-4ec5-8575-ed42951820a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = \"Mistral-7B-Instruct-v0.2\"\n",
    "model_loc = \"mistralai/Mistral-7B-Instruct-v0.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debccc23-2cd3-4695-a303-29c46813b7fa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Llama-2-7b-chat-hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65143c68-c364-42bb-97f9-1eb2a4e59c0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = \"Llama-2-7b-chat-hf\"\n",
    "model_loc = \"meta-llama/Llama-2-7b-chat-hf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591f1d89-5918-4afe-93b4-c89a43de1070",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2. AWQ Modelle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec0a0f1-2798-4c82-940d-ded98e46a78d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Llama-3-8B-Instruct-HF-AWQ-4bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427a6178-f8f0-4c2c-8404-2858df0f78b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = \"/home/thsch026/masterarbeit/models/generated/llm-awq/\"\n",
    "model_id = \"Meta-Llama-3-8B-Instruct-HF-AWQ-4bit\"\n",
    "model_loc = model_path + model_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb61b69-ec27-4e61-81c5-dc39db441407",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Mistral-7B-Instruct-v0.2-AWQ-4bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4644b0-0c07-4525-a262-5e5092965137",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = \"/home/thsch026/masterarbeit/models/generated/llm-awq/\"\n",
    "model_id = \"Mistral-7B-Instruct-v0.2-AWQ-4bit\"\n",
    "model_loc = model_path + model_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff33ab1a-31f6-46fb-8f6e-1d735517611e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Llama-2-7b-chat-HF-AWQ-4bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a08e90-bbc7-41ac-aa94-8b49c873df1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = \"/home/thsch026/masterarbeit/models/generated/llm-awq/\"\n",
    "model_id = \"Llama-2-7b-chat-HF-AWQ-4bit\"\n",
    "model_loc = model_path + model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d59293b-6efa-4cc7-8959-01c8b6078248",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = \"/home/thsch026/masterarbeit/models/generated/awq/quant/\"\n",
    "model_id = \"Meta-Llama-3-8B-Instruct-HF-w8-g128-awq-v2.pt\"\n",
    "model_loc = model_path + model_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54021899-6689-45cb-b6c8-6805645bc3a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Pruned Models (shortened-LLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2048b853-dfc4-4a59-909b-5bb9f98f0898",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Meta-Llama-3-8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a82db0d-4996-4b89-834b-4dc8cdf40b8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_loc = \"/home/thsch026/masterarbeit/models/generated/prune/shortened-llm/Meta-Llama-3-8B\"\n",
    "model_id = \"Meta-Llama-3-8B_pruned_llm-shortened\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6483eb73-5af8-4942-9685-650ce9558326",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Llama-2-7b-hf (schlechtes Ergebnis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a41d8b-92f9-4fec-aaa8-4af2a3c2c98c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_loc = \"/home/thsch026/masterarbeit/models/generated/prune/shortened-llm/Llama-2-7b-hf\"\n",
    "model_id = \"Llama-2-7b-hf_pruned_llm-shortened\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80eb2f74-9dce-46ca-a352-131d286967e5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Mistral-7B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d29fad-5f12-4fdf-8e89-d72802527710",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_loc = \"/home/thsch026/masterarbeit/models/generated/prune/shortened-llm/Mistral-7B-Instruct\"\n",
    "model_id = \"Mistral-7B-Instruct_pruned_llm-shortened\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad3ccb3-1cac-441e-9c7d-a27b4118ed6c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 4. Lora Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936a2b36-d74a-41b6-a118-b2a333d2be68",
   "metadata": {},
   "source": [
    "#### Meta-Llama-3-8B_ms-marco (Kein gutes Ergebnis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "750851c6-986b-4b03-a782-b86025d109b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_loc = \"/home/thsch026/masterarbeit/models/generated/lora/Meta-Llama-3-8B_ms-marco/model\"\n",
    "model_id = \"Meta-Llama-3-8B_ms-marco\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fe523b-5400-4c5e-acab-9de3491c0158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c77e3aa-d61e-42c7-971c-c7bf04f9e226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52234743-5342-4575-bc8f-a3a5648bbe8e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##  5. Qlora Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d295691-3815-4d68-9756-8f21b57cffa0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Meta-Llama-3-8B-Instruct_qlora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f09e204-2574-4e1d-9525-397c68f6c59b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_loc = \"/home/thsch026/masterarbeit/models/generated/qlora/Meta-Llama-3-8B-Instruct_qlora\"\n",
    "model_id = \"Meta-Llama-3-8B-Instruct_qlora\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b86211c-58c4-451a-8aad-9fd2e87b8b1b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Mistral-7B-Instruct-v0.2_qlora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3456e0-8a11-4747-923b-d45efaf21e57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_loc = \"/home/thsch026/masterarbeit/models/generated/qlora/Mistral-7B-Instruct-v0.2_qlora\"\n",
    "model_id = \"Mistral-7B-Instruct-v0.2_qlora\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3995301f-a7ab-4cc2-be5a-3fe8b73a21b1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### llama-2-7b-chat_qlora (Fehlt noch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa741a7d-1ce7-40f5-85a1-8ac046fd7261",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_loc = \"/home/thsch026/masterarbeit/models/generated/qlora/llama-2-7b-chat_qlora\"\n",
    "model_id = \"llama-2-7b-chat_qlora\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79403c4-5b32-45c7-9d4a-9202960d19fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6. Prune + Lora Models (shortened-LLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec746b6d-13dd-4076-a963-850e24e41d77",
   "metadata": {},
   "source": [
    "#### Meta-Llama-3-8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee28e905-cdd4-438e-afd1-4057ef8e6f2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_loc = \"/home/thsch026/masterarbeit/models/generated/prune_plus_lora/shortened-llm/Meta-Llama-3-8B_prune_lora\"\n",
    "model_id = \"Meta-Llama-3-8B_prune_lora\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41b5d54-b7ce-4d02-bc31-fff91f571229",
   "metadata": {},
   "source": [
    "#### Llama-2-7b-hf_prune_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "358a1bc1-c349-471d-9619-a7f990a79d51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_loc = \"/home/thsch026/masterarbeit/models/generated/prune_plus_lora/shortened-llm/Llama-2-7b-hf_prune_lora\"\n",
    "model_id = \"Llama-2-7b-hf_prune_lora\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9a8491-d334-4f15-ab58-80f9a3a8b6f1",
   "metadata": {},
   "source": [
    "#### Mistral-7B-Instruct_prune_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91e863a6-a0c2-484d-9bcf-a6e08f1a1834",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_loc = \"/home/thsch026/masterarbeit/models/generated/prune_plus_lora/shortened-llm/Mistral-7B-Instruct_prune_lora\"\n",
    "model_id = \"Mistral-7B-Instruct_prune_lora\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06aa4a7-700d-4fe2-a6e1-caf5412620d8",
   "metadata": {},
   "source": [
    "### Prune + Lora + AWQ Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b106f3-b689-4f66-959d-741cbd80c7d1",
   "metadata": {},
   "source": [
    "#### Mistral-7B-Instruct_prune_lora_awq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db0f508c-f8c3-45b5-90bd-d2ebd89d9458",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_loc = \"/home/thsch026/masterarbeit/models/generated/prune_plus_lora_plus_awq/Mistral-7B-Instruct-v02_prune_lora_awq\"\n",
    "model_id = \"Mistral-7B-Instruct_prune_lora_awq\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46418667-8aa4-4a9e-a2c5-9bf8a8adc04f",
   "metadata": {},
   "source": [
    "## Inference Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09340b3-5eca-4527-9b13-8c10a8ef9899",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Laden des Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08332cb9-b9ed-45c8-a7fe-6d5374421209",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_loc)\n",
    "\n",
    "#quantization_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.bfloat16)\n",
    "#quantization_config = BitsAndBytesConfig(bnb_4bit_compute_dtype=torch.bfloat16)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_loc,\n",
    "    trust_remote_code=True,\n",
    "    # Bei AWQ Modellen keine quantization config angeben\n",
    "   # quantization_config=quantization_config, #load_in_8bit=True\n",
    "    device_map='cuda'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8916e74f-6f9d-4b6d-9175-71814a323512",
   "metadata": {},
   "source": [
    "### Interferenz mit Ergebnis Speicherung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66a892fb-0ff4-4c67-9f1f-bdc13713a1b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mistral-7B-Instruct_prune_lora_awq', 2.673348976815264, 74.81252980232239, 3.65, 'Once upon a time', \"Once upon a time, people were luddites and computers were uncommon. Then, one night while sitting up for a pony ride in Fort Bramshutte's grandstand, something was drawn in my notebook. A beast is drawn. I made it mine. I had a game, called 'The Beast' (a version of which is still available on the app store) and began to obsessively research, inventing and implementing a world-replacement engine in my game, and creating a vast world that grew from a few simple rules.\\n\\nThe game was called Quest, and it was like the computer-driven worlds that eventually arrived and made my dreams of the endless possibilities of the imaginary world. My friend Bill and I created this, and we were called the Beast Corporation, and it seemed that our game had become the ultimate expression of our art.\\n\\nBut, like nature, our work went on, and the years passed as we\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mistral-7B-Instruct_prune_lora_awq', 3.097978716356849, 43.57680034637451, 3.65, 'Why should I eat healthy?', 'Why should I eat healthy?\\n\\nYou should eat healthy to improve your physical and mental health, boost your immune system, maintain your weight, and prevent chronic diseases such as obesity, type 2 diabetes, heart disease, and certain types of cancer.\\n\\nWhat makes food healthy?\\n\\nTo be considered healthy, food often contains nutrients such as vitamins, minerals, fiber, and antioxidants that are essential for the growth, development, and functioning of the body. It should also include a variety of types of foods, including fruits, vegetables, whole grains, lean protein, and healthy fats.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mistral-7B-Instruct_prune_lora_awq', 3.0871269332784608, 64.78515601158142, 3.65, 'Is there a second life after death?', \"Is there a second life after death? Are humans the only intelligent beings on Earth? The debate on these topics has been going on for centuries.\\n\\nIf you have a specific question, or topic you'd like our scientists to explore, send our team a message – or fill out this form:\\n\\nSen. John Cornyn, Texas Republican, called Democrats’ move to move to a vote on banning semi-automatic guns an ‘unraveling of American constitutional liberties.’ CNN anchor Brian Bremmel suggested that his statement would be “mostly out of line with the typical views of his fellow [senators], that is, Democrats would interpret such a measure as reasonable, perhaps even a requirement.\\n\\nIn contrast to the senator’s words of the ‘unraveling of American constitutional liberties,' CNN correspondent Elizabeth Cohn described her country’s right to bear ammunition as “savage.''\\n\\n\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mistral-7B-Instruct_prune_lora_awq', 3.071416592066884, 65.11653304100037, 3.65, 'What is the most common injury?', 'What is the most common injury?\\n\\nImpact with the hard ground or track is the number one cause of injury. Another common injury is hypochondriosis.\\n\\nCan an injury be prevented?\\n\\nYes. Many injuries can be prevented by implementing certain risk management strategies. This can include proper conditioning, strength and flexibility training, equipment properly fitted, and adherence to speed and running rules.\\n\\nWhy can\\'t athletes train on Astrolite tiles?\\n\\nAstrolite tiles are not the best surface for sportscerbony training because the surface is not the correct ratio of water, oxygen, and food for the athletes to perform their best. Athletes trained on Astrolite also tend to get sick easily, and not even the sickest of athletes would be seen training on this surface.\\n\\nWhat is a bumps game?\\n\\nIt\\'s actually called \"Bumpsies,\" it\\'s when two sides']\n",
      "['Mistral-7B-Instruct_prune_lora_awq', 3.069129790432008, 65.16505122184753, 3.65, 'Who is Konrad Zuse?', 'Who is Konrad Zuse?\\n\\nKonrad Zuse was a German programmer and computer scientist who was the first person to design and program an electronic computer. His invention, the Z-Computer, was the first digital computer that had the capability to program itself. Zuse’s work in computer design and programming influenced many of the earliest computer designers in other countries, and his contributions to the field are considered to be pivotal in the development of early computers.\\n\\nWhat made Konrad Zuse famous?\\n\\nKonrad Zuse is famous for designing and programming the first electronic computer, the Z-Computer. This computer had the ability to program itself, which helped to pave the way for the development of self-programming computers. Zuse’s invention was the first self-programmable digital computer, and its creation served as a foundation for the development of modern computers. In addition to his contributions to computer science, Zuse']\n"
     ]
    }
   ],
   "source": [
    "# Funktion für das Speichern der Werte\n",
    "\n",
    "def append_data(result):\n",
    "    \n",
    "    with open(full_csv, mode='a', newline='') as file:\n",
    "        full_writer = csv.writer(file)\n",
    "        full_writer.writerow(result)\n",
    "        \n",
    "    with open(data_csv, mode='a', newline='') as file:\n",
    "        data_writer = csv.writer(file)\n",
    "        data_writer.writerow(result[0:4])\n",
    "\n",
    "                \n",
    "device = 'cuda'\n",
    "\n",
    "question_list = [\"Once upon a time\", \"Why should I eat healthy?\", \"Is there a second life after death?\", \"What is the most common injury?\",\"Who is Konrad Zuse?\"]\n",
    "\n",
    "for question in question_list:\n",
    "    input_ids = tokenizer.encode(question, return_tensors='pt')\n",
    "    # Änderung dr Zeile weil es Probleme mit der Ausführung gab (cuda/cpu anomalie)\n",
    "    input_ids = tokenizer(question, return_tensors=\"pt\").input_ids.to(device)\n",
    "    input_ids.to('cuda:0')\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Führe die Inferenz durch\n",
    "    outputs = model.generate(input_ids, max_length=200)\n",
    "\n",
    "    # Messe die Zeit nach der Inferenz\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Berechne die Inferenz-Zeit\n",
    "    inference_time = end_time - start_time\n",
    "\n",
    "    # Dekodiere die Ausgabe\n",
    "    output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Berchnung des Ergebnis\n",
    "    #number_of_words = len(output_text.split())\n",
    "    number_of_tokens = len(outputs[0])\n",
    "    memory_usage = round((torch.cuda.memory_allocated() / (1024 **3)),2)\n",
    "    token_per_second = number_of_tokens/inference_time\n",
    "    result = [model_id,token_per_second, inference_time, memory_usage, question, output_text]\n",
    "    print(result)\n",
    "    append_data(result)\n",
    "              \n",
    "    \n",
    "                                                                \n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ffa84fe-1000-4060-a497-83f7d7fa5719",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model # Specify variable\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc1e67b-bd73-4be8-8985-bc7be12de04b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inference",
   "language": "python",
   "name": "inference"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
