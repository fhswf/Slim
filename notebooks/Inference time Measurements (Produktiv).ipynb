{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ae2d401-5489-46dc-88b7-73ad6c6d3bad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Old"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749fb1ae-5a15-49cf-8cf1-cbcbb59b4bc7",
   "metadata": {},
   "source": [
    "### Importieren der Klassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb41a6c-b844-4b75-b3b6-40ccaa6fd134",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import bitsandbytes as bnb\n",
    "import accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086184b8-7c23-4d03-814e-782bf9bf11b7",
   "metadata": {},
   "source": [
    "### Festlegen des Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba8932f-6a50-4b70-aa75-8aa20571ff4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id=\"/home/thsch026/masterarbeit/models/generated/llm-awq/Meta-Llama-3-8B-Instruct-HF-AWQ-4bit\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79d4441-2950-4b88-a4ff-39589bbb08d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Initialisieren des Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911c81b9-1c3f-494c-a8f4-2d2d6f2b8dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.bfloat16)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    quantization_config=quantization_config, #load_in_8bit=True,#\n",
    "    device_map='auto',\n",
    "    token='<EOL>'\n",
    ")\n",
    "#peft_model = \"BojanaBas/Meta-Llama-3-8B-Instruct-pqa-10\"\n",
    "#model = PeftModel.from_pretrained(base_model, peft_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af0835d-38d5-4be2-97f3-d32e45bb6510",
   "metadata": {},
   "source": [
    "### Inferenz Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab0212d-3b3a-4eb3-879a-6da6f9520374",
   "metadata": {},
   "source": [
    "### Autoawq library is needed to test inference with AWQ Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87aba23-5f11-42ca-b81b-6f924586513d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install autoawq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9015bb47-a9ad-4180-a267-90f9326b1106",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Eingabetext\n",
    "input_text = \"Once upon a time\"\n",
    "#input_text = \"Why should I eat healthy?\"\n",
    "\n",
    "# Tokenisiere den Eingabetext\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
    "\n",
    "# Messe die Zeit vor der Inferenz\n",
    "start_time = time.time()\n",
    "\n",
    "# Führe die Inferenz durch\n",
    "outputs = model.generate(input_ids, max_length=50)\n",
    "\n",
    "# Messe die Zeit nach der Inferenz\n",
    "end_time = time.time()\n",
    "\n",
    "# Berechne die Inferenz-Zeit\n",
    "inference_time = end_time - start_time\n",
    "\n",
    "# Dekodiere die Ausgabe\n",
    "output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "number_of_words = len(output_text.split())\n",
    "number_of_tokens = len(outputs[0])\n",
    "\n",
    "token_per_second = number_of_tokens/inference_time\n",
    "\n",
    "print(f\"Inferenz-Zeit: {inference_time} Sekunden\")\n",
    "print(f\"Output: {output_text}\")\n",
    "print(\"Tokens per second: \", token_per_second)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16792f78-12ba-48e8-9a19-f1675d48c46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Die neuen Daten, die hinzugefügt werden sollen\n",
    "neue_daten = ['Lukas', 28]\n",
    "\n",
    "# Öffne die Datei im Anhangsmodus ('a' steht für append)\n",
    "with open('daten.csv', mode='a', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    # Schreibe die neuen Daten in die CSV-Datei\n",
    "    writer.writerow(neue_daten)\n",
    "\n",
    "print(\"Neue Daten erfolgreich hinzugefügt.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e4c0ba-cebb-48bc-84f2-0916b8869830",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df63ba6c-7a05-4ad8-9731-c24e1cb9bb01",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluierung Modelle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05cdc7a-fc84-4f70-b419-5071a1a37ff2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Sentencepiece muss ggf. noch mal installiert werden für Mistral (fast tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d6026d-5fbb-43c5-b93e-b96dc8eafed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e30b253-4a58-4ba9-9a75-f3a553365b89",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Laden der libaries und festlegen der GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1de386e7-4cb0-4987-9d7e-38fc6ec2bdc9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:256\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "!echo $CUDA_VISIBLE_DEVICES\n",
    "# torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e57cfb40-2d1c-4f5f-adc0-9134f7f08c46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import bitsandbytes as bnb\n",
    "import accelerate\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad42e67d-5f77-419a-bed4-7cb0f1f2cb11",
   "metadata": {},
   "source": [
    "### Ergebnis Dateien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "993981e1-1528-4ea8-b4ef-cca2461b922e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_csv= \"/home/thsch026/masterarbeit/Slim/results/inference/inference_full.csv\"\n",
    "data_csv= \"/home/thsch026/masterarbeit/Slim/results/inference/inference_data_only.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a740d057-2c5f-48fb-89ab-b69dbb4eabd9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##  1. Referenz Modelle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ab7136-9c90-40d2-b7c0-495b09e3edbc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Llama-3-8B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edba68fd-af1a-4718-8701-aeb759c15015",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id =\"Meta-Llama-3-8B-Instruct\"\n",
    "model_loc = \"meta-llama/Meta-Llama-3-8B-Instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09dbea4-d24c-43b4-b174-1ce3a9e9bcd4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Mistral-7B-Instruct-v0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c612ad07-641b-4ec5-8575-ed42951820a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = \"Mistral-7B-Instruct-v0.2\"\n",
    "model_loc = \"mistralai/Mistral-7B-Instruct-v0.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debccc23-2cd3-4695-a303-29c46813b7fa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Llama-2-7b-chat-hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65143c68-c364-42bb-97f9-1eb2a4e59c0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = \"Llama-2-7b-chat-hf\"\n",
    "model_loc = \"meta-llama/Llama-2-7b-chat-hf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591f1d89-5918-4afe-93b4-c89a43de1070",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2. AWQ Modelle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec0a0f1-2798-4c82-940d-ded98e46a78d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Llama-3-8B-Instruct-HF-AWQ-4bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427a6178-f8f0-4c2c-8404-2858df0f78b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = \"/home/thsch026/masterarbeit/models/generated/llm-awq/\"\n",
    "model_id = \"Meta-Llama-3-8B-Instruct-HF-AWQ-4bit\"\n",
    "model_loc = model_path + model_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb61b69-ec27-4e61-81c5-dc39db441407",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Mistral-7B-Instruct-v0.2-AWQ-4bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4644b0-0c07-4525-a262-5e5092965137",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = \"/home/thsch026/masterarbeit/models/generated/llm-awq/\"\n",
    "model_id = \"Mistral-7B-Instruct-v0.2-AWQ-4bit\"\n",
    "model_loc = model_path + model_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff33ab1a-31f6-46fb-8f6e-1d735517611e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Llama-2-7b-chat-HF-AWQ-4bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a08e90-bbc7-41ac-aa94-8b49c873df1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = \"/home/thsch026/masterarbeit/models/generated/llm-awq/\"\n",
    "model_id = \"Llama-2-7b-chat-HF-AWQ-4bit\"\n",
    "model_loc = model_path + model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d59293b-6efa-4cc7-8959-01c8b6078248",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = \"/home/thsch026/masterarbeit/models/generated/awq/quant/\"\n",
    "model_id = \"Meta-Llama-3-8B-Instruct-HF-w8-g128-awq-v2.pt\"\n",
    "model_loc = model_path + model_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54021899-6689-45cb-b6c8-6805645bc3a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Pruned Models (shortened-LLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2048b853-dfc4-4a59-909b-5bb9f98f0898",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Meta-Llama-3-8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a82db0d-4996-4b89-834b-4dc8cdf40b8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_loc = \"/home/thsch026/masterarbeit/models/generated/prune/shortened-llm/Meta-Llama-3-8B\"\n",
    "model_id = \"Meta-Llama-3-8B_pruned_llm-shortened\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6483eb73-5af8-4942-9685-650ce9558326",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Llama-2-7b-hf (schlechtes Ergebnis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a41d8b-92f9-4fec-aaa8-4af2a3c2c98c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_loc = \"/home/thsch026/masterarbeit/models/generated/prune/shortened-llm/Llama-2-7b-hf\"\n",
    "model_id = \"Llama-2-7b-hf_pruned_llm-shortened\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80eb2f74-9dce-46ca-a352-131d286967e5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Mistral-7B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d29fad-5f12-4fdf-8e89-d72802527710",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_loc = \"/home/thsch026/masterarbeit/models/generated/prune/shortened-llm/Mistral-7B-Instruct\"\n",
    "model_id = \"Mistral-7B-Instruct_pruned_llm-shortened\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad3ccb3-1cac-441e-9c7d-a27b4118ed6c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 4. Lora Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936a2b36-d74a-41b6-a118-b2a333d2be68",
   "metadata": {},
   "source": [
    "#### Meta-Llama-3-8B_ms-marco (Kein gutes Ergebnis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "750851c6-986b-4b03-a782-b86025d109b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_loc = \"/home/thsch026/masterarbeit/models/generated/lora/Meta-Llama-3-8B_ms-marco/model\"\n",
    "model_id = \"Meta-Llama-3-8B_ms-marco\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fe523b-5400-4c5e-acab-9de3491c0158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c77e3aa-d61e-42c7-971c-c7bf04f9e226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52234743-5342-4575-bc8f-a3a5648bbe8e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##  5. Qlora Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d295691-3815-4d68-9756-8f21b57cffa0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Meta-Llama-3-8B-Instruct_qlora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f09e204-2574-4e1d-9525-397c68f6c59b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_loc = \"/home/thsch026/masterarbeit/models/generated/qlora/Meta-Llama-3-8B-Instruct_qlora\"\n",
    "model_id = \"Meta-Llama-3-8B-Instruct_qlora\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b86211c-58c4-451a-8aad-9fd2e87b8b1b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Mistral-7B-Instruct-v0.2_qlora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3456e0-8a11-4747-923b-d45efaf21e57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_loc = \"/home/thsch026/masterarbeit/models/generated/qlora/Mistral-7B-Instruct-v0.2_qlora\"\n",
    "model_id = \"Mistral-7B-Instruct-v0.2_qlora\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3995301f-a7ab-4cc2-be5a-3fe8b73a21b1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### llama-2-7b-chat_qlora (Fehlt noch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa741a7d-1ce7-40f5-85a1-8ac046fd7261",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_loc = \"/home/thsch026/masterarbeit/models/generated/qlora/llama-2-7b-chat_qlora\"\n",
    "model_id = \"llama-2-7b-chat_qlora\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79403c4-5b32-45c7-9d4a-9202960d19fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6. Prune + Lora Models (shortened-LLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec746b6d-13dd-4076-a963-850e24e41d77",
   "metadata": {},
   "source": [
    "#### Meta-Llama-3-8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee28e905-cdd4-438e-afd1-4057ef8e6f2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_loc = \"/home/thsch026/masterarbeit/models/generated/prune_plus_lora/shortened-llm/Meta-Llama-3-8B_prune_lora\"\n",
    "model_id = \"Meta-Llama-3-8B_prune_lora\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41b5d54-b7ce-4d02-bc31-fff91f571229",
   "metadata": {},
   "source": [
    "#### Llama-2-7b-hf_prune_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "358a1bc1-c349-471d-9619-a7f990a79d51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_loc = \"/home/thsch026/masterarbeit/models/generated/prune_plus_lora/shortened-llm/Llama-2-7b-hf_prune_lora\"\n",
    "model_id = \"Llama-2-7b-hf_prune_lora\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9a8491-d334-4f15-ab58-80f9a3a8b6f1",
   "metadata": {},
   "source": [
    "#### Mistral-7B-Instruct_prune_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91e863a6-a0c2-484d-9bcf-a6e08f1a1834",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_loc = \"/home/thsch026/masterarbeit/models/generated/prune_plus_lora/shortened-llm/Mistral-7B-Instruct_prune_lora\"\n",
    "model_id = \"Mistral-7B-Instruct_prune_lora\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06aa4a7-700d-4fe2-a6e1-caf5412620d8",
   "metadata": {},
   "source": [
    "## 7. Prune + Lora + AWQ Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b106f3-b689-4f66-959d-741cbd80c7d1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Mistral-7B-Instruct_prune_lora_awq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db0f508c-f8c3-45b5-90bd-d2ebd89d9458",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_loc = \"/home/thsch026/masterarbeit/models/generated/prune_plus_lora_plus_awq/Mistral-7B-Instruct-v02_prune_lora_awq\"\n",
    "model_id = \"Mistral-7B-Instruct_prune_lora_awq\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1295e2a-ddc3-4876-9440-86dbfd0efa3c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Meta-Llama-3-8B_prune_lora_awq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efa35d37-8c34-48aa-a957-8df37b280c4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_loc = \"/home/thsch026/masterarbeit/models/generated/prune_plus_lora_plus_awq/Meta-Llama-3-8B_prune_lora_awq\"\n",
    "model_id =\"Meta-Llama-3-8B_prune_lora_awq\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0e5d84-707f-40e0-ad48-c030230a8bf1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Llama-2-7b-chat-hf_prune_lora_awq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19aea15c-da65-41c6-96e6-fff44cddc23c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_loc = \"/home/thsch026/masterarbeit/models/generated/prune_plus_lora_plus_awq/Llama-2-7b-chat-hf_prune_lora_awq\"\n",
    "model_id =\"Llama-2-7b-chat-hf_prune_lora_awq\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46418667-8aa4-4a9e-a2c5-9bf8a8adc04f",
   "metadata": {},
   "source": [
    "## Inference Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09340b3-5eca-4527-9b13-8c10a8ef9899",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Laden des Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08332cb9-b9ed-45c8-a7fe-6d5374421209",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_loc)\n",
    "\n",
    "#quantization_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.bfloat16)\n",
    "#quantization_config = BitsAndBytesConfig(bnb_4bit_compute_dtype=torch.bfloat16)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_loc,\n",
    "    trust_remote_code=True,\n",
    "    # Bei AWQ Modellen keine quantization config angeben\n",
    "   # quantization_config=quantization_config, #load_in_8bit=True\n",
    "    device_map='cuda'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8916e74f-6f9d-4b6d-9175-71814a323512",
   "metadata": {},
   "source": [
    "### Interferenz mit Ergebnis Speicherung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66a892fb-0ff4-4c67-9f1f-bdc13713a1b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Llama-2-7b-chat-hf_prune_lora_awq', 3.1914819509381283, 62.66681218147278, 3.13, 'Once upon a time', 'Once upon a time, there was a poor farmer named J. Hinweis desktops were used for many years. However, with the advent of portable computing and mobile devices, the usage shifted towards laptops, handheld devices and tablets. Now, the trend is moving towards virtual and augmented reality devices and IoT (Internet of Things) devices for remote working and home automation.\\n\\nLetting a software monopolist develop something of great importance like a voting device means giving them the power to manipulate it as they see fit. The internet has made inter-regulatory compliance less about \"foreign control\" and more about security at the perimeter and around the edge. But not every device is trustworthy; some are hacked by malware attacks which can influence the outcome of the votes.\\n\\nTo ensure the integrity and trustworthiness of voting systems, these must be designed and designed-conducted through a']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Llama-2-7b-chat-hf_prune_lora_awq', 3.3487477940305626, 59.723816871643066, 3.13, 'Why should I eat healthy?', 'Why should I eat healthy?\\n Unterscheidung zwischen Eating healthy and eating cravings\\nWhy should I eat healthy?\\n\"’ll die’ll die’ll never ever try: the end of the story, one day’.” This is not the ending you’re looking for, I imagine! Instead, here are some reasons for living, especially when it comes to eating:\\nEating healthy is the best way to maintain good physical and mental health. One great way to do so is by eating a balance of nutrient-rich foods such as fruits, vegetables, whole grains, and lean proteins.\\nThe Foods to Eat\\nFruits and Vegetables: Both are great sources of essential vitamins, minerals and fiber.\\nFruits: Provides nutrient-rich nuggets full of vitamins, minervs, antioxidants,']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Llama-2-7b-chat-hf_prune_lora_awq', 3.4837896382184175, 33.29707360267639, 3.13, 'Is there a second life after death?', 'Is there a second life after death?\\n nobody knows\\n\\nIn religion and spirituality, there are beliefs and theories about the possibility of a second life or afterlife. The concept of eternal life, immortality or even reincarnation vary among different religions, depending on their teachings. Overall, the existence of a second life remains a topic of speculation and argument for those who are skeptical about the nature of existence, and others who believe their soul or consciousness will carry out existence after a physical life is lived.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Llama-2-7b-chat-hf_prune_lora_awq', 3.4295234987689414, 36.739797830581665, 3.13, 'What is the most common injury?', 'What is the most common injury?\\n Hinweis - This article discusses the most common injuries, particularly in the workplace or on and off the job site. Some injuries, such as fractures and head injuries, can happen suddenly due to falls, accidents, and unavoidable physical or natural causes, as mentioned herein. However, these are very rare and likely to occur due to unavoidable situations. However, as mentioned above, the most common injuries are from repetitive stress and sprains, and all care should be taken to avoid any sudden injuries.']\n",
      "['Llama-2-7b-chat-hf_prune_lora_awq', 3.347256333181027, 59.750428438186646, 3.13, 'Who is Konrad Zuse?', 'Who is Konrad Zuse?\\n✿ Ingridhöistock.com 🎓\\nKonrad Zuse is an German inventor and computer enthusiast who is widely recognized for being the first person to write a program that built a calculating machine and implement it.\\n\\nHe is known for inventing the first operational programmable computer, the Z  (Z for \"Zulauf, \" a German word meaning \"elastic strengthening\"), which completed the first programmable computation sometime between 1937 and 1940 (the year when he completed the machine, its completion had to wait for the final tension screws to be inserted).\\n\\nHe also implemented a binary-analytic algorithm for determining the princssutability of numbers, and developed an approach for finding a solution to the Factor Settling Tombstones\\' problem in mathematics.\\n\\nThe first use']\n"
     ]
    }
   ],
   "source": [
    "# Funktion für das Speichern der Werte\n",
    "\n",
    "def append_data(result):\n",
    "    \n",
    "    with open(full_csv, mode='a', newline='') as file:\n",
    "        full_writer = csv.writer(file)\n",
    "        full_writer.writerow(result)\n",
    "        \n",
    "    with open(data_csv, mode='a', newline='') as file:\n",
    "        data_writer = csv.writer(file)\n",
    "        data_writer.writerow(result[0:4])\n",
    "\n",
    "                \n",
    "device = 'cuda'\n",
    "\n",
    "question_list = [\"Once upon a time\", \"Why should I eat healthy?\", \"Is there a second life after death?\", \"What is the most common injury?\",\"Who is Konrad Zuse?\"]\n",
    "\n",
    "for question in question_list:\n",
    "    input_ids = tokenizer.encode(question, return_tensors='pt')\n",
    "    # Änderung dr Zeile weil es Probleme mit der Ausführung gab (cuda/cpu anomalie)\n",
    "    input_ids = tokenizer(question, return_tensors=\"pt\").input_ids.to(device)\n",
    "    input_ids.to('cuda:0')\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Führe die Inferenz durch\n",
    "    outputs = model.generate(input_ids, max_length=200)\n",
    "\n",
    "    # Messe die Zeit nach der Inferenz\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Berechne die Inferenz-Zeit\n",
    "    inference_time = end_time - start_time\n",
    "\n",
    "    # Dekodiere die Ausgabe\n",
    "    output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Berchnung des Ergebnis\n",
    "    #number_of_words = len(output_text.split())\n",
    "    number_of_tokens = len(outputs[0])\n",
    "    memory_usage = round((torch.cuda.memory_allocated() / (1024 **3)),2)\n",
    "    token_per_second = number_of_tokens/inference_time\n",
    "    result = [model_id,token_per_second, inference_time, memory_usage, question, output_text]\n",
    "    print(result)\n",
    "    append_data(result)\n",
    "              \n",
    "    \n",
    "                                                                \n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ffa84fe-1000-4060-a497-83f7d7fa5719",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model # Specify variable\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc1e67b-bd73-4be8-8985-bc7be12de04b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inference",
   "language": "python",
   "name": "inference"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
