{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "493334c9-5d20-41bd-abfc-333b6bebaacd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Qlora for Llama3. runs with \"qlora3\" kernel\n",
    "- Source: https://medium.com/@avishekpaul31/fine-tuning-llama-3-8b-instruct-qlora-using-low-cost-resources-89075e0dfa04\n",
    "- Source: https://github.com/AvisP/LM_Finetune/blob/main/llama-3-finetune-qlora.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b58dbf-35a3-43b4-8852-15ae3b274d95",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup for kernel (qlora3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc5b723-0043-433b-ac04-b8d527b13b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# workaround for packaging fehler\n",
    "pip install setuptools==69.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530eb66b-52f5-499c-8c42-628e5884b0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch==2.0.1\n",
    "!pip install bitsandbytes\n",
    "!pip install -U transformers[torch] datasets\n",
    "!pip install -q bitsandbytes trl peft accelerate\n",
    "!pip install flash-attn --no-build-isolation\n",
    "!pip install transformers==4.40.2 # Es geht nur genau diese Version!!\n",
    "!pip install trl\n",
    "!pip install autoawq\n",
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cc0704-8c66-45bc-9a54-4e4be5775b28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install sentencepiece\n",
    "!pip install mistral_inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46074ac4-8243-4eb7-b1d5-94e1ece5afe9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!conda list | grep trl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f713146b-6adf-48e9-9ca8-709d86d33c37",
   "metadata": {},
   "source": [
    "## Qlora Training Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a889b1c-59fd-4437-a61e-c9faf6523d01",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Set GPU and import Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eac015a-2721-4e8b-89e2-4674158c1903",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:256\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "!echo $CUDA_VISIBLE_DEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92a8e1d0-32ad-489e-9f6d-b07c3c4beff4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "#notebook_login()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75387894-b2b7-454f-b8c5-d9bf745b2afc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Set Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222b86be-979e-452f-b8fb-79e217c4c3e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### LLama-3-8B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "951cf6e1-11e5-4b75-b5df-33548cba7dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "# Storage Location\n",
    "trained_model_id = \"Meta-Llama-3-8B-Instruct_qlora\"\n",
    "output_dir = '/home/thsch026/masterarbeit/models/generated/qlora/' + trained_model_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4fd613-aa1b-4b13-9d24-0c4acc760189",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Mistral 7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2409fa9d-c159-40d7-b02e-495f28ee258a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "# Storage Location\n",
    "trained_model_id = \"Mistral-7B-Instruct-v0.2_qlora\"\n",
    "output_dir = '/home/thsch026/masterarbeit/models/generated/qlora/' + trained_model_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe8f7b1-b540-40a1-ad6b-c04cdc8f34b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Llama-2-7b-chat-hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4092b176-0903-4a48-9a13-036f310cd6fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "\n",
    "# Storage Location\n",
    "trained_model_id = \"Llama-2-7b-chat-hf_qlora\"\n",
    "output_dir = '/home/thsch026/masterarbeit/models/generated/qlora/' + trained_model_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c24a69-f2e2-401a-8457-2e3842f6ee98",
   "metadata": {},
   "source": [
    "### Load Model and choose GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83a31a82-9158-420b-b960-5a4839043c66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thsch026/my-envs/qlora3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ccb33b9007c443a9671821737fd2c11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thsch026/my-envs/qlora3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f247ca16-4229-4e4e-9451-a03ee24b1073",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load Dataset and trim for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4b83eea-46fa-4540-a8b3-5f0b14b9d532",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# based on config\n",
    "raw_datasets = load_dataset(\"HuggingFaceH4/ultrachat_200k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67e0ba5b-0453-4575-b1b9-ab927db6d910",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['prompt', 'prompt_id', 'messages'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['prompt', 'prompt_id', 'messages'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "# remove this when done debugging to include whole dataset\n",
    "indices = range(0,10000)\n",
    "\n",
    "dataset_dict = {\"train\": raw_datasets[\"train_sft\"].select(indices),\n",
    "                \"test\": raw_datasets[\"test_sft\"].select(indices)}\n",
    "\n",
    "#dataset_dict = {\"train\": raw_datasets[\"train_sft\"],\n",
    "  #              \"test\": raw_datasets[\"test_sft\"]}\n",
    "\n",
    "raw_datasets = DatasetDict(dataset_dict)\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cad6c45-6a5d-488d-ae87-b8ff878e7724",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user                :  These instructions apply to section-based themes (Responsive 6.0+, Retina 4.0+, Parallax 3.0+ Turbo 2.0+, Mobilia 5.0+). What theme version am I using?\n",
      "On your Collections pages & Featured Collections sections, you can easily show the secondary image of a product on hover by enabling one of the theme's built-in settings!\n",
      "Your Collection pages & Featured Collections sections will now display the secondary product image just by hovering over that product image thumbnail.\n",
      "Does this feature apply to all sections of the theme or just specific ones as listed in the text material?\n",
      "assistant           :  This feature only applies to Collection pages and Featured Collections sections of the section-based themes listed in the text material.\n",
      "user                :  Can you guide me through the process of enabling the secondary image hover feature on my Collection pages and Featured Collections sections?\n",
      "assistant           :  Sure, here are the steps to enable the secondary image hover feature on your Collection pages and Featured Collections sections:\n",
      "\n",
      "1. Log in to your Shopify account and go to your Online Store.\n",
      "2. Click on Customize theme for the section-based theme you are using.\n",
      "3. Navigate to the Collection pages or Featured Collections section where you want to enable the secondary image hover feature.\n",
      "4. With the section open, click on the section's setting (gear) icon in the top-left corner.\n",
      "5. In the settings panel that appears, look for an option labeled 'Image display' or 'Image hover'.\n",
      "6. If available, select 'Show secondary image on hover'.\n",
      "7. Save the changes and preview the Collection/Featured Collection page to see the effect.\n",
      "\n",
      "If you're having trouble finding the setting, the best thing to do is refer to your theme's documentation, since the location and labeling of settings can vary between themes.\n",
      "user                :  Can you provide me with a link to the documentation for my theme?\n",
      "assistant           :  I don't have access to your store's theme information. However, you can usually find the documentation for your theme by going to the shopify theme store, finding your theme and clicking on the 'support' link located in the bottom right corner of the page. Alternatively, you can do a google search for the name of your theme followed by 'documentation' or 'user guide'.\n",
      "user                :  Can you confirm if this feature also works for the Quick Shop section of my theme?\n",
      "assistant           :  The secondary image hover feature may or may not work for your Quick Shop section, depending on the configuration of your theme. Some themes include this feature in the Quick Shop section by default, while others may require additional customization. To check if this feature is available for the Quick Shop section of your theme, follow these steps:\n",
      "\n",
      "1. Go to the Quick Shop section where you would like to enable the feature. 2. Click on the Quick Shop settings icon (gear icon) and look for 'Image display' or 'Image hover'. 3. If available, select 'Show secondary image on hover'. 4. Save the changes. If this option is not available in your Quick Shop section settings, you may need to reach out to your theme developer for assistance with customizing your Quick Shop section to include this feature.\n"
     ]
    }
   ],
   "source": [
    "example = raw_datasets[\"train\"][0]\n",
    "messages = example[\"messages\"]\n",
    "for message in messages:\n",
    "  role = message[\"role\"]\n",
    "  content = message[\"content\"]\n",
    "  print('{0:20}:  {1}'.format(role, content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0876077e-e22b-4691-8900-52ca3d3ecdde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b51cae3-1486-43b0-bddd-60e40bceca16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "064303d1-aa7c-4c83-9b29-c6a475312341",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "def apply_chat_template(example, tokenizer):\n",
    "    messages = example[\"messages\"]\n",
    "    # We add an empty system message if there is none\n",
    "    #if messages[0][\"role\"] != \"system\":\n",
    "     #   messages.insert(0, {\"role\": \"system\", \"content\": \"\"})\n",
    "    example[\"text\"] = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35e13907-bdbc-4a94-810d-076314565511",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "column_names = list(raw_datasets[\"train\"].features)\n",
    "raw_datasets = raw_datasets.map(apply_chat_template,\n",
    "                                num_proc=cpu_count(),\n",
    "                                fn_kwargs={\"tokenizer\": tokenizer},\n",
    "                                remove_columns=column_names,\n",
    "                                desc=\"Applying chat template\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf7a7737-31e6-48f1-8aa7-770f001917ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set pad_token_id equal to the eos_token_id if not set\n",
    "if tokenizer.pad_token_id is None:\n",
    "  tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Set reasonable default for models without max length\n",
    "if tokenizer.model_max_length > 100_000:\n",
    "  tokenizer.model_max_length = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c88d141-2dd3-4fc4-9132-d55ba4cc2be3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 7833 of the processed training set:\n",
      "\n",
      "<s>[INST] Can you provide information on the top vineyards to tour in Wexford and wine tastings available? [/INST] I do not have access to real-time information or personal preferences, but I can give an overview of some top vineyards to tour in wexford and wine tastings available.\n",
      "\n",
      "1. Wexford vineyard tours: get an insight to the behind-the-scenes of irish winemaking with wexford vineyard tours. They offer tours to various vineyards in wexford, including the award-winning domaine de montville and lusca.\n",
      "\n",
      "2. Montague heritage services: montague heritage services provides specialized tours to vineyards on behalf of the vineyards. These tours include vip visits, behind-the-scenes tours, as well as wine tastings. Some of the vineyards they usually visit include horetown vineyard and domaine de montville.\n",
      "\n",
      "3. Lusca: lusca is ireland's first commercial vineyard and specializes in organic wine production. They offer guided tours of the vineyard on a request basis, and visitors get to learn about grape varieties, and the processes involved in winemaking. \n",
      "\n",
      "4. Lamber de bie flowers: located in kilkenny, lamber de bie flowers not only offers floral design services but has also gone into the wine and cheese business. They have a wine tasting room and a bottom floor filled with cheese and spanish products that you can purchase.\n",
      "\n",
      "5. The harvest stone: the harvest stone is a deli and wine shop located in enniscorthy, county wexford. They offer wine tastings of their exquisite wines and also wine-making workshops.\n",
      "\n",
      "note: as the world navigates through the covid-19 pandemic, some vineyards may not be operational. It is best to check on their websites or social media pages for updates or restrictions before visiting. </s><s>[INST] Can you suggest the most affordable vineyard tour in Wexford that I can take with my friends? [/INST] I do not have access to real-time information or personal preferences, but I can suggest some vineyard tours in wexford that may fit an affordable budget:\n",
      "\n",
      "1. Wexford vineyard tours: this tour company offers affordable tours that start at €35 per person. They have various tour packages that take you to different vineyards in wexford, so you can choose a package that fits your budget.\n",
      "\n",
      "2. Horetown vineyard: horetown vineyard offers guided tours and wine tastings for a fee of €12 per person. The tour lasts for approximately 45 minutes, and guests get to learn about the process of winemaking, grape varieties, and the history of the vineyard.\n",
      "\n",
      "3. Lamber de bie flowers: lamber de bie flowers offers a wine tasting experience for €10 per person, which includes four samples of wines and finger foods. They are located in kilkenny, which is not too far from wexford.\n",
      "\n",
      "4. Wicklow way wines: wicklow way wines is a micro-winery located in wicklow, not too far from wexford. They offer tours and tastings for a fee of €12 per person, and visitors get to learn about the process of winemaking and get to try some of their award-winning wines.\n",
      "\n",
      "it's always best to check the websites or social media pages of the vineyards for the latest pricing and availability before booking a tour. </s><s>[INST] Can you recommend any vineyard tours that also include transportation to and from the vineyards? I want to make sure my friends and I can enjoy the wine tastings without having to worry about driving. [/INST] Yes, there are some vineyard tours in Wexford that include transportation to and from the vineyards. Here are some recommendations:\n",
      "\n",
      "1. Wexford Vineyard Tours: This tour company offers packages that include transportation to and from the vineyards. They pick you up from your accommodation in Wexford or other designated pickup points and take you to the vineyards for a day of wine tasting. You can contact them to discuss a customized package for your group.\n",
      "\n",
      "2. Montague Heritage Services: Montague Heritage Services offers vineyard tours with transportation. They can arrange a bespoke tour to include hotel accommodation, transport, and private tastings. Some of the vineyards they usually visit include Horetown Vineyard, Domaine de Montville, and Ballycross Apple Farm.\n",
      "\n",
      "3. Lusca: Lusca offers a unique vineyard tour experience with limited spaces, that includes transport. Visitors can take a tour of the vineyard and learn about the history of the vineyard, winemaking process, and wine tasting.\n",
      "\n",
      "4. South East Tours: South East Tours has a Wine and Dine tour, which includes transportation to and from Horetown Vineyard. You can also opt for a customized package to explore other wineries in the region.\n",
      "\n",
      "Note: It's always best to confirm with the tour company if transportation is included before booking the tour. </s><s>[INST] Can you recommend any vineyard tours in Wexford that have unique wine tasting experiences? I want to impress my friends with something different than just a typical wine tasting. [/INST] Yes, there are some vineyard tours in Wexford that offer unique wine tasting experiences that your friends will surely love. Here are some recommendations:\n",
      "\n",
      "1. Wicklow Way Wines: Wicklow Way Wines is a micro-winery located in Wicklow that offers a unique wine tasting experience. They offer a foraging and wine tasting package where you get to forage for wild berries and other edibles and then have a wine tasting with their award-winning wines. This experience is unique and memorable.\n",
      "\n",
      "2. Montague Heritage Services: Montague Heritage Services offer customized vineyard tours that include unique wine tasting experiences. They offer a range of innovative wine tastings and can create something unique and bespoke for your group.\n",
      "\n",
      "3. The Harvest Stone: The Harvest Stone is a deli and wine shop in Enniscorthy that offers wine and food pairing experiences. They have a vast selection of wine, cheese, and charcuterie, and they can create a perfect pairing experience for your group.\n",
      "\n",
      "4. Horetown Vineyard: Horetown Vineyard offers a unique wine tasting experience with a twist. They offer a pairing experience where they pair their hand-crafted wines with chocolates. This is a fun and unique experience to impress your friends.\n",
      "\n",
      "Note: It's always best to check with the vineyards for the latest updates and availability before booking a tour. </s><s>[INST] Wow, these are all great recommendations! I had no idea there were so many vineyards and unique experiences in Wexford. I think I'll have to do some more research and narrow it down with my friends. [/INST] I'm glad I could be of help. Wexford is a beautiful part of Ireland with some incredible vineyards and wine tasting experiences. I'm sure you and your friends will have an amazing time no matter what you decide to do. Enjoy your trip! </s>\n",
      "#####################################\n",
      "Sample 1452 of the processed training set:\n",
      "\n",
      "<s>[INST] How did architecture evolve during the medieval period in Europe? [/INST] During the medieval period in Europe, architecture evolved significantly. \n",
      "\n",
      "In the early medieval period, architecture was often characterized by simple designs and construction methods, with a focus on functionality rather than ornamentation. Most buildings were made of wood or other locally available materials, and often had thatched roofs.\n",
      "\n",
      "As the period progressed, however, architecture became more complex and ornate. Gothic architecture emerged in the 12th century and was characterized by the use of pointed arches, ribbed vaults, and flying buttresses. During this time, many of Europe’s great cathedrals were built, including Notre Dame in Paris and Canterbury Cathedral in England.\n",
      "\n",
      "Religious architecture was also a significant feature of the medieval period. Monasteries and abbeys were built throughout Europe, often in remote locations, and were designed to be self-sufficient communities. These buildings were often large and imposing, with thick walls and small windows.\n",
      "\n",
      "While religious architecture dominated the period, secular architecture also evolved significantly. Medieval castles were built throughout Europe for defensive purposes, and often featured complex system of walls, towers, and gates. As the period progressed, castles also became more ornate, with decorative elements such as towers and turrets.\n",
      "\n",
      "Overall, the medieval period in Europe saw significant advances in architecture, with a move from simple, functional designs to more complex and ornate structures. </s><s>[INST] It's interesting how religious architecture dominated the period. Were there any notable examples of secular architecture that emerged during that time? [/INST] Yes, there were several notable examples of secular architecture that emerged during the medieval period in Europe. One of the most iconic examples of secular architecture from this period is the castle.\n",
      "\n",
      "Castles were built throughout Europe during the medieval period and served as defensive fortifications for nobles, lords, and monarchs. Castles came in many shapes and sizes, ranging from small fortified towers to sprawling complexes with multiple buildings and courtyards.\n",
      "\n",
      "Many of these castles were designed to be imposing and intimidating, with high walls and towers that projected strength and authority. However, as the period progressed, castles also became more ornate and decorative, with features like turrets, battlements, and moats that added both functionality and aesthetic appeal.\n",
      "\n",
      "Another notable example of secular architecture from the medieval period is the townhouse or city palace. These buildings were often constructed by wealthy merchants, aristocrats, or royalty and were designed to showcase their wealth and power.\n",
      "\n",
      "Townhouses and city palaces were typically large and grandiose, with multiple floors, grand entrances, and ornate decorations like stonework, carvings, and frescoes. Many of these buildings also included spacious courtyards or gardens, which provided a private space for the family to relax and entertain guests.\n",
      "\n",
      "Overall, while religious architecture dominated the medieval period in Europe, there were many notable examples of secular architecture that emerged during this time, including castles and townhouses. </s><s>[INST] It's fascinating how castles served as both defensive fortifications and ornate structures. Do any of these castles still exist today? [/INST] Yes, many castles from the medieval period in Europe still exist today, and some have been preserved and restored as historical monuments.\n",
      "\n",
      "One of the most famous and well-preserved castles from the medieval period is the Tower of London in England. Built in the 11th century, the Tower of London served as a royal palace, fortress, and later, a prison. Today it is open to the public and is one of London's most popular tourist attractions.\n",
      "\n",
      "Another famous example of a medieval castle that still exists today is the Chateau de Versailles in France. Originally built in the 17th century and expanded over several centuries, Versailles was the principal residence of the French monarchy until the French Revolution. Today, it is a popular tourist attraction and is known for its luxurious architecture, stunning gardens, and rich history.\n",
      "\n",
      "Other notable medieval castles that still exist today include the Alhambra in Spain, the Edinburgh Castle in Scotland, and the Neuschwanstein Castle in Germany.\n",
      "\n",
      "While not all medieval castles have been preserved in the same condition as these famous examples, many still exist in various states of disrepair or have been adapted for modern use. However, they remain an important reminder of the role that castles played in the history and culture of medieval Europe. </s><s>[INST] I've always wanted to visit a medieval castle. Which one would you recommend the most? [/INST] I am not capable of expressing subjective opinions, but I can provide you with some information that might help you choose a medieval castle to visit, depending on your preferences.\n",
      "\n",
      "if you are interested in historical architecture, the tower of london, which I mentioned earlier, is a great option. It is one of the best-preserved medieval castles in europe and has a rich history that spans almost a thousand years.\n",
      "\n",
      "if you are looking for a castle that is located in a picturesque setting, neuschwanstein castle in germany might be a good choice. Built in the 19th century, it is a fairytale-like castle with beautiful views of the surrounding bavarian alps.\n",
      "\n",
      "on the other hand, if you are interested in medieval castles that have been transformed into luxurious buildings or hotels, then ashford castle in ireland, bovey castle in england, and chateau de la bourdaisiere in france can be great options.\n",
      "\n",
      "ultimately, the best medieval castle to visit will depend on your interests and preferences. There are hundreds of medieval castles throughout europe, and each offers a unique experience and a glimpse into the history and culture of the period. </s><s>[INST] I think I might go for Neuschwanstein Castle. The Bavarian Alps sound like a breathtaking view. [/INST] Neuschwanstein Castle is definitely a beautiful castle with an incredible backdrop of the Bavarian Alps. It was also an inspiration for the Disney movie \"Sleeping Beauty\" and continues to attract visitors from all over the world. I hope you have a great time exploring this beautiful castle and experiencing its rich history and culture! </s><s>[INST] That's cool that Neuschwanstein Castle is the inspiration for Sleeping Beauty! I'm even more excited to visit now. Do you know any fun facts about the castle? [/INST] Certainly! Here are some fun facts about Neuschwanstein Castle:\n",
      "\n",
      "- King Ludwig II of Bavaria commissioned the building of Neuschwanstein Castle in 1868. He funded the construction with his own money.\n",
      "\n",
      "- The castle is located in the small village of Hohenschwangau, close to the Austrian border in Bavaria, Germany.\n",
      "\n",
      "- Neuschwanstein Castle was designed by a theatrical set designer and was meant to be a tribute to the music of Richard Wagner, who was a close friend and a great inspiration to King Ludwig II.\n",
      "\n",
      "- Due to the king's untimely death, the castle was incomplete when it was opened to the public in 1886. Visitors can still see some unfinished rooms in the castle, but what was completed is nonetheless impressive.\n",
      "\n",
      "- Neuschwanstein has several unique features, including an artificial cave, a swan-themed bedroom, and one of the first indoor toilets ever built.\n",
      "\n",
      "- The castle welcomes over 1 million visitors every year, making it one of the most popular tourist destinations in Germany.\n",
      "\n",
      "I hope these fun facts about Neuschwanstein Castle give you a glimpse into the rich history and culture of this remarkable medieval castle! </s>\n",
      "#####################################\n",
      "Sample 3227 of the processed training set:\n",
      "\n",
      "<s>[INST] Can you provide examples of effective icebreakers to begin a brainstorming session for a team that is unsure or reluctant to participate? [/INST] 1. \"Two Truths and a Lie\" - Each team member introduces themselves and shares three statements about themselves, two true and one false. The rest of the team has to guess which statement is the lie.\n",
      "\n",
      "2. \"Interview each other\" - Pair up team members and have them interview each other, asking questions like, \"Tell me about your favorite hobby,\" \"If you could travel anywhere, where would you go?\" Then, have each person share what they learned about their partner with the rest of the group.\n",
      "\n",
      "3. \"Brainstorming Warm-up\" - Start the brainstorming session with a warm-up exercise. For example, if the session is for a new product launch, you could ask everyone to list 10 ways they could use the product. This helps to get the creative juices flowing and gets everyone thinking about the topic.\n",
      "\n",
      "4. \"One Word at a Time\" - Have everybody sit in a circle and start telling a story, but each person can only contribute one word at a time. This exercise can help the team focus on listening to others and building on each other's ideas.\n",
      "\n",
      "5. \"Draw a Picture\" - Ask everyone to draw a picture that represents the problem or topic at hand. Then, have each team member share their picture and explain what it represents. This exercise can help get the team thinking outside of the box and can bring up new ideas that may not have been considered otherwise. </s><s>[INST] I think the \"Brainstorming Warm-up\" could work well for my team. Do you have any other suggestions for specific warm-up exercises related to marketing campaigns? [/INST] Sure, here are some warm-up exercises related to marketing campaigns:\n",
      "\n",
      "1. \"Marketing Mad Libs\" - Create a Mad Libs template that includes marketing buzzwords (e.g., target audience, message, call-to-action, etc.) and have each team member fill in the blanks. Once everyone has completed their Mad Libs, have each team member share their completed template and explain their choices.\n",
      "\n",
      "2. \"Object Association\" - Choose a random object, such as a pen, and have each team member brainstorm as many ways that object could be used in a marketing campaign. For example, a pen could be used to create a hashtag, as a prize for a social media contest, or as an item to give away at a trade show.\n",
      "\n",
      "3. \"Brand Mashup\" - Choose two well-known brands, such as Nike and Apple, and have each team member brainstorm how they would create a marketing campaign for the combination of the two brands. For example, if Nike and Apple were combined, the campaign could focus on technology-enhanced workout gear.\n",
      "\n",
      "4. \"Customer Persona Creation\" - Divide the team into pairs and have each pair create a persona for a target customer. The persona should include demographic information, interests, habits, and pain points. Once everyone has created their persona, have each team member share their persona with the group.\n",
      "\n",
      "5. \"Inspiration Scavenger Hunt\" - Give each team member a few minutes to browse social media or other sources of inspiration (such as a Pinterest board) for marketing campaign ideas. Once everyone has found a few examples, have each team member share their sources of inspiration and what ideas they came up with. </s><s>[INST] I really like the idea of \"Brand Mashup\". It sounds like a fun way to get creative and think outside of the box. [/INST] Great, I'm glad that exercise appealed to you! \"Brand Mashup\" is a great way to harness the team's creative energies and imagination, and it can often lead to unexpected and innovative ideas that might not have come up otherwise. \n",
      "\n",
      "Don't be afraid to be playful and have fun with this exercise - it's not about coming up with the \"right\" answer, but about exploring uncharted territory and discovering new ways to market a product or service. Remember that in brainstorming, quantity often trumps quality, so encourage team members to share even the most outlandish ideas. Who knows, a wild idea might just spark the next big marketing campaign! </s><s>[INST] I think the \"Marketing Mad Libs\" exercise could also be a lot of fun. It sounds like a great way to have a laugh while getting our creative juices flowing. [/INST] Definitely! \"Marketing Mad Libs\" can be a fun way to engage your team and break the ice before diving into the ideas. It's lighthearted, easy to understand, and can provide a humorous critique on traditional buzzwords as well. \n",
      "\n",
      "Be aware, however, that because Mad Libs are typically based on some predetermined structure, they may not always lead to completely novel or out-of-the-box ideas. That said, it can still be a useful tactic to get your team thinking in new ways by using keywords and common marketing lingo. It can be especially useful as a starting point to then brainstorm how to expand upon or disrupt that specific language. \n",
      "\n",
      "Above all, remember that the goal of the exercise is to get the team thinking creatively and working collaboratively, so you can always adapt and tailor the exercise to fit the needs and interests of your specific team. Good luck and happy brainstorming! </s><s>[INST] I also really like the \"Customer Persona Creation\" exercise! It sounds like a great way to make sure we're really thinking about our target audience and how to appeal to them. [/INST] Absolutely! The customer persona exercise can be incredibly valuable in helping teams really hone in on their target audience and develop messaging that resonates with them. By giving each team member the opportunity to create their own persona, you'll end up with a range of perspectives and insights that can inform your marketing campaigns.\n",
      "\n",
      "Be sure to encourage your team members to get creative and think outside the box when developing their personas. Consider including guided prompts or questions to help them really get inside the mindset of their persona - what motivates them, what challenges do they face, and what would make them want to engage with your brand?\n",
      "\n",
      "Once you've created your personas, take the time to review them as a team, looking for commonalities and insights that can inform your marketing strategy. Use these personas as a touchstone throughout the campaign development process to ensure that you're staying focused on your target audience and their needs. </s><s>[INST] These warm-up exercises have been really helpful! Is there anything else you'd recommend we do to ensure a successful brainstorming session? [/INST] I'm glad to hear that! Here are a few more tips to ensure a successful brainstorming session:\n",
      "\n",
      "1. Define the Problem: Before you start brainstorming, make sure that you have a clearly defined problem or challenge to solve. This will help keep your team's ideas focused and ensure that everyone is working towards the same goal.\n",
      "\n",
      "2. Set Ground Rules: Set some ground rules, like \"no idea is a bad idea,\" and encourage everyone to participate. Remind everyone that this is a safe and inclusive space where everyone's contributions are valued.\n",
      "\n",
      "3. Assign a Facilitator: Appoint someone on your team to be the facilitator, who can ensure that everyone has equal time to contribute, guide the conversation, and keep the discussion on track.\n",
      "\n",
      "4. Use Visuals: Consider using visuals like whiteboards or post-it notes to help stimulate ideas and make the brainstorming process more interactive.\n",
      "\n",
      "5. Take Breaks: Schedule breaks throughout your brainstorming session to give everyone's brain a chance to recharge. This can help to prevent \"brain drain\" and ensure that everyone stays engaged and energized throughout the session.\n",
      "\n",
      "Remember, the goal of a brainstorming session is to generate as many ideas as possible, without judgment, before you begin to carefully evaluate and refine them. With these tips in mind, you'll be well on your way to a productive and successful brainstorming session! </s><s>[INST] Do you have any advice for selecting the best ideas from the brainstorming session? It can be tough to choose which ideas to pursue. [/INST] Yes, selecting the best ideas from a brainstorming session can be a challenge. Here are a few tips to help you narrow down your options:\n",
      "\n",
      "1. Define Your Criteria: Before you start evaluating ideas, define your criteria for what makes a \"good\" idea. This can help you stay focused and make objective decisions. Your criteria might include factors like feasibility, budget, potential ROI, alignment with your brand values, and so on. 2. Prioritize: Once you've defined your criteria, prioritize the ideas based on how well they meet your criteria. Consider assigning each idea a score or ranking to make this process easier. 3. Combine and Refine: Consider combining similar ideas or refining them to create stronger concepts. This can help you consolidate your options and flesh out the most promising ideas. 4. Get Feedback: Share your list of top ideas with others and see if anyone has feedback or suggestions for improvement. This can help you fine-tune your ideas and identify any potential issues or gaps. 5. Test: Finally, consider testing your top ideas on a small scale (such as with a focus group or A/B testing) to see how they perform in the real world. This can help you validate your ideas and refine them further before fully committing. Remember, selecting the best ideas is all about finding the ideas that are most likely to help you achieve your goals. By being objective, staying focused on your criteria, and testing your ideas, you'll be well on your way to selecting the best ideas from your brainstorming session. </s>\n",
      "#####################################\n"
     ]
    }
   ],
   "source": [
    "# create the splits\n",
    "train_dataset = raw_datasets[\"train\"]\n",
    "eval_dataset = raw_datasets[\"test\"]\n",
    "\n",
    "for index in random.sample(range(len(raw_datasets[\"train\"])), 3):\n",
    "  print(f\"Sample {index} of the processed training set:\\n\\n{raw_datasets['train'][index]['text']}\")\n",
    "  print(\"#####################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4989f1e-ce9c-4a50-97bf-91fa8eb8c354",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thsch026/my-envs/qlora3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6da52b2cfa9f435b8c21781a9cfc5d97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Shiver me timbers! 'Tis a fine question ye be askin', me hearty! I be the Pirate Chatbot, the scurviest and most salty of all the digital sea dogs! Arrrr, I be here to help ye with any questions ye might have, and to spin ye a tale or two of the high seas. So hoist the colors, me matey, and let's set sail fer a grand adventure! What be yer first question, eh?\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to(model.device)\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_flash_sdp(False)\n",
    "# https://github.com/Lightning-AI/litgpt/issues/327\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=128,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    ")\n",
    "\n",
    "response = outputs[0][input_ids.shape[-1]:]\n",
    "\n",
    "print(tokenizer.decode(response, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3418fd-e002-4441-ab0c-b93d7de78435",
   "metadata": {},
   "source": [
    "## Prepare Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be076044-fbd3-4c55-9c0e-a6151816bcf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "from peft import LoraConfig\n",
    "from transformers import TrainingArguments\n",
    "from transformers import BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2506b1fc-80be-4b97-9a68-4ce7dcd04be0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# For 8 bit quantization\n",
    "quantization_config = BitsAndBytesConfig(load_in_8bit=True,\n",
    "                                        llm_int8_threshold=200.0)\n",
    "\n",
    "## For 4 bit quantization\n",
    "#quantization_config = BitsAndBytesConfig(\n",
    " #           load_in_4bit=True,\n",
    "  #          bnb_4bit_use_double_quant=True,\n",
    "   #         bnb_4bit_quant_type=\"nf4\",\n",
    "    #        bnb_4bit_compute_dtype=torch.bfloat16,)\n",
    "\n",
    "#model = AutoModelForCausalLM.from_pretrained(model_id, \n",
    " #                                            quantization_config=quantization_config,\n",
    "  #                                      device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7037ff39-f240-46f2-ae10-d74e312ad479",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_kwargs = dict(\n",
    "#     attn_implementation=False,#\"flash_attention_2\", # set this to True if your GPU supports it (Flash Attention drastically speeds up model computations)\n",
    "    torch_dtype=\"auto\",\n",
    "    use_cache=False, # set to False as we're going to use gradient checkpointing\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=quantization_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d765181-6310-46c2-8264-25aa57857d39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thsch026/my-envs/qlora3/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:166: UserWarning: You passed a model_id to the SFTTrainer. This will automatically create an `AutoModelForCausalLM` or a `PeftModel` (if you passed a `peft_config`) for you.\n",
      "  warnings.warn(\n",
      "/home/thsch026/my-envs/qlora3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc1d917c10304486bb443c23ad8929ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b736ddc124d246f79842801f83492f0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2526 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# based on config\n",
    "training_args = TrainingArguments(\n",
    "    fp16=False, # specify bf16=True instead when training on GPUs that support bf16 else fp16\n",
    "    bf16=False,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    gradient_accumulation_steps=1,\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
    "    learning_rate=2.0e-05,\n",
    "    log_level=\"info\",\n",
    "    logging_steps=5,\n",
    "    logging_strategy=\"steps\",\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    max_steps=-1,\n",
    "    num_train_epochs=1,\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    per_device_eval_batch_size=1, # originally set to 8\n",
    "    per_device_train_batch_size=1, # originally set to 8\n",
    "    push_to_hub=True,\n",
    "    hub_model_id=trained_model_id,\n",
    "    # hub_strategy=\"every_save\",\n",
    "    # report_to=\"tensorboard\",\n",
    "    report_to=\"none\",  # for skipping wandb logging\n",
    "    save_strategy=\"no\",\n",
    "    save_total_limit=None,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "# based on config\n",
    "peft_config = LoraConfig(\n",
    "        r=64,\n",
    "        lora_alpha=16,\n",
    "        lora_dropout=0.1,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "        model=model_id,\n",
    "        model_init_kwargs=model_kwargs,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        dataset_text_field=\"text\",\n",
    "        tokenizer=tokenizer,\n",
    "        packing=True,\n",
    "        peft_config=peft_config,\n",
    "        max_seq_length=tokenizer.model_max_length,\n",
    "    )\n",
    "\n",
    "# To clear out cache for unsuccessful run\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db252239-0da0-4113-a68b-1e7d2f6a9049",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ba5ab3-16c9-49c6-9eb0-2f00d857246a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 6,823\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6,823\n",
      "  Number of trainable parameters = 67,108,864\n",
      "/home/thsch026/my-envs/qlora3/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1641' max='6823' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1641/6823 1:24:30 < 4:27:12, 0.32 it/s, Epoch 0.24/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_result = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45b9115-216f-4227-8adb-f70c02230e64",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a09105-5c5d-4b2c-86fa-84a7b91dc314",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(output_dir)\n",
    "model.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e285172-12f2-4c72-b84d-9c0c1544fa1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qlora3",
   "language": "python",
   "name": "qlora3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
