{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8f1ac5-6980-4cf0-8e73-b88bab44a63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Traceback (most recent call last):\n",
    "  File \"/home/thsch026/my-envs/eval/bin/lm_eval\", line 8, in <module>\n",
    "    sys.exit(cli_evaluate())\n",
    "  File \"/home/thsch026/masterarbeit/work/lm-evaluation-harness/lm_eval/__main__.py\", line 347, in cli_evaluate\n",
    "    results = evaluator.simple_evaluate(\n",
    "  File \"/home/thsch026/masterarbeit/work/lm-evaluation-harness/lm_eval/utils.py\", line 316, in _wrapper\n",
    "    return fn(*args, **kwargs)\n",
    "  File \"/home/thsch026/masterarbeit/work/lm-evaluation-harness/lm_eval/evaluator.py\", line 292, in simple_evaluate\n",
    "    results[\"config\"].update(lm.get_model_info())\n",
    "  File \"/home/thsch026/masterarbeit/work/lm-evaluation-harness/lm_eval/models/huggingface.py\", line 1310, in get_model_info\n",
    "    \"model_num_parameters\": get_model_num_params(self._model),\n",
    "  File \"/home/thsch026/masterarbeit/work/lm-evaluation-harness/lm_eval/models/huggingface.py\", line 1287, in get_model_num_params\n",
    "    return model.num_parameters()\n",
    "  File \"/home/thsch026/my-envs/eval/lib/python3.10/site-packages/transformers/modeling_utils.py\", line 1165, in num_parameters\n",
    "    quant_storage.itemsize if hasattr(quant_storage, \"itemsize\") else quant_storage.element_size()\n",
    "AttributeError: 'torch.dtype' object has no attribute 'element_size'\n",
    "wandb: üöÄ View run Llama3 8B Instruct QLora at: https://wandb.ai/pumaai/lm-eval-harness-integration/runs/saiaja98\n",
    "wandb: ‚≠êÔ∏è View project at: https://wandb.ai/pumaai/lm-eval-harness-integration\n",
    "wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
    "wandb: Find logs at: ./wandb/run-20240703_081438-saiaja98/logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88f0fb0-8c20-486f-aa12-1423b6f425e9",
   "metadata": {},
   "source": [
    "### Fehler slow tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a030d5ad-7c68-4f71-baa5-11227222884f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ValueError: Cannot instantiate this tokenizer from a slow version. If it's based on sentencepiece, make sure you have sentencepiece installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0de8ee4-a6b7-44c7-bd50-fe8c8c06e428",
   "metadata": {},
   "outputs": [],
   "source": [
    "L√∂sung: Sentencepiece installieren auch wenn es eigentlich schon im Environment it. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
