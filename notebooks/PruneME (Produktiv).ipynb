{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcfdd528-799e-4eb5-bdf2-43466f3d11aa",
   "metadata": {},
   "source": [
    "# PruneMe\n",
    "- Repo: https://github.com/arcee-ai/PruneMe\n",
    "- Paper to cite: \n",
    "    @misc{gromov2024unreasonable,\n",
    "      title={The Unreasonable Ineffectiveness of the Deeper Layers}, \n",
    "      author={Andrey Gromov and Kushal Tirumala and Hassan Shapourian and Paolo Glorioso and Daniel A. Roberts},\n",
    "      year={2024},\n",
    "      eprint={2403.17887},\n",
    "      archivePrefix={arXiv},\n",
    "      primaryClass={cs.CL}\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acbc7db-3709-4209-98ea-a65a3aed383d",
   "metadata": {},
   "source": [
    "- Repository PruneMe kopieren (git clone https://github.com/arcee-ai/PruneMe)\n",
    "- Repository Mergekit kopieren (git clone https://github.com/arcee-ai/mergekit)\n",
    "- Installation wie auf den Repos beschrieben durchführen (pip install -e .)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3170643-4f58-4cb0-a866-9c91185ea0fa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Workflow PruneMe \n",
    "> ### Analyse des Ursprungs Modells \n",
    "> - Wechsel  in das Verzeichnis compute_block_similarity:\n",
    "> - Ausführen des Tasks layer_similarity generiert eine CSV Datei welche im selben Verzeichnis abgelegt wird\n",
    "> - Aus dieser Datei sucht man die Layer mit den geringsten Unterschied als Basis für den Merge Task heraus\n",
    "\n",
    "> ### Erstellen des neuen  \"Pruned\" Modells\n",
    "> - Wechsel in das Verzeichnis slice_with_mergekit\n",
    "> - editieren der Datei slice.yaml mit den entsprechenden layern und modellnamen (siehe Beispiel unten)\n",
    "> - ausführen von merge_me.py\n",
    "> - das neue Modell wird im Verzeichnis \"merged\" abgelegt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe3fc90-9fd3-4dc6-8a58-96a1db2d93ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 0. Vorbereitungen\n",
    "- Einmalig nach Notebook Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "009b2f08-09cd-43d6-a3d9-37a5f67c8818",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(/home/thsch026/my-envs/PruneMe) \n"
     ]
    }
   ],
   "source": [
    "conda activate PruneMe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550ec681-9c01-4889-9694-c70533f86177",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Generelle Pfade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "533bdc29-93d9-4403-9c2f-3053f2bcc309",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(/home/thsch026/my-envs/PruneMe) \n",
      "(/home/thsch026/my-envs/PruneMe) \n"
     ]
    }
   ],
   "source": [
    "export PMODELOUT=\"/home/thsch026/masterarbeit/models/generated/prune/pruneme/\"\n",
    "export PRESULTS=\"/home/thsch026/masterarbeit/Slim/results/PruneMe/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7793f65c-155c-4b1e-97b6-149a98c56196",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Produktive Pruning Kompression\n",
    "- Auswahl des Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b398861-1127-4219-9120-8c70c896c3f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export PRESULTS=\"/home/thsch026/masterarbeit/Slim/results/PruneMe/\"\n",
    "export PMODELOUT=\"/home/thsch026/masterarbeit/models/generated/prune/pruneme/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84788c2a-f76d-46f9-b75b-1748f4e911dd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Llama-3-8B-Instruct-HF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9668055-e65f-4f5b-b7ed-fd801c780ff3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 8 Layers extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1815b336-3c17-45e0-98cf-adb90934e8f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export MODEL=\"/home/thsch026/masterarbeit/models/llama3/Meta-Llama-3-8B-Instruct-HF\"\n",
    "export LAYERSPRUNED=\"8\"\n",
    "export OUT=\"Meta-Llama-3-8B-Instruct-\"$LAYERSPRUNED\"_Ext\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7a8a0e-adb6-435d-936a-ad76dea50cd5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 12 Layers extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db4766a3-b39f-4d30-8b8a-e9e8516e4082",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export MODEL=\"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "export LAYERSPRUNED=\"12\"\n",
    "export OUT=\"Meta-Llama-3-8B-Instruct-\"$LAYERSPRUNED\"_Ext\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e0e922-48c4-4943-b70a-7ab47cac7d67",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Llama-3-8B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbdf902-8ca5-4cd1-81db-7116562fc26a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 8 Layers Extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b110d97c-5951-4c89-9650-9e4e13655f60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export MODEL=\"meta-llama/Meta-Llama-3-8B\"\n",
    "export LAYERSPRUNED=\"8\"\n",
    "export OUT=\"Meta-Llama-3-8B-\"$LAYERSPRUNED\"_Ext\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe1639a-cd57-4dcc-b042-3b90887c10bf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 12 Layers extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e9d409f-a08c-4b2c-a7be-cc61bffde68d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export MODEL=\"meta-llama/Meta-Llama-3-8B\"\n",
    "export LAYERSPRUNED=\"12\"\n",
    "export OUT=\"Meta-Llama-3-8B-\"$LAYERSPRUNED\"_Ext\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f688142c-6668-48c8-a14b-d459a173a7a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Mistral-7B-Instruct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd04dd5-7e94-488c-8328-e07b1f22f8a1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 8 Layers extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28374ffd-936e-440f-8b47-f135cf42c8b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export MODEL=\"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "export LAYERSPRUNED=\"8\"\n",
    "export OUT=\"Mistral-7B-Instruct-v0.2-\"$LAYERSPRUNED\"_Ext\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc40c5d-4cec-45a9-95f1-ae05c80c8d35",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 12 Layers extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c936a251-9759-402f-a574-560a97cf7cfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export MODEL=\"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "export LAYERSPRUNED=\"12\"\n",
    "export OUT=\"Mistral-7B-Instruct-v0.2-\"$LAYERSPRUNED\"_Ext\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f563a1-a8a9-48f1-8f59-9ca0fd9d1384",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Llama2-7B-chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12057077-9d47-4f58-b72f-f77b0c586e18",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 8 Layers extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ec5ddce-3d4a-48c0-baf6-816b95718757",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export MODEL=\"meta-llama/Llama-2-7b-chat-hf\"\n",
    "export LAYERSPRUNED=\"8\"\n",
    "export OUT=\"Llama-2-7b-chat-hf-\"$LAYERSPRUNED\"_Ext\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0bfd01-773d-4508-8052-61bbdcfd9468",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 12 Layers extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c321d410-b5d5-41e0-985d-2677406acc63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(/home/thsch026/my-envs/PruneMe) \n",
      "(/home/thsch026/my-envs/PruneMe) \n",
      "(/home/thsch026/my-envs/PruneMe) \n"
     ]
    }
   ],
   "source": [
    "export MODEL=\"meta-llama/Llama-2-7b-chat-hf\"\n",
    "export LAYERSPRUNED=\"12\"\n",
    "export OUT=\"Llama-2-7b-chat-hf-\"$LAYERSPRUNED\"_Ext\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09757171-2850-45a6-9d55-fe8179166ae3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Beipiel für den Inhalt von slice.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ef5677-b610-45a2-9897-bbcc8599e06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "slices:\n",
    "  - sources:\n",
    "      - model: /home/thsch026/masterarbeit/models/llama3/Meta-Llama-3-8B-Instruct-HF\n",
    "        layer_range: [0, 22]\n",
    "  - sources:\n",
    "      - model: /home/thsch026/masterarbeit/models/llama3/Meta-Llama-3-8B-Instruct-HF\n",
    "        layer_range: [30,32]\n",
    "            \n",
    "merge_method: passthrough\n",
    "dtype: bfloat16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b114700-8f35-4526-9f75-377f2e03b85c",
   "metadata": {},
   "source": [
    "###  2. Setzen der Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cd2c229-bc00-4430-894f-c8de546be119",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/thsch026/masterarbeit/models/generated/prune/pruneme/Llama-2-7b-chat-hf-8_Ext\n"
     ]
    }
   ],
   "source": [
    "export PRUNEMODEL=\"$PMODELOUT$OUT\"\n",
    "export RESULTS=\"$PRESULTS$OUT\"\n",
    "echo $PRUNEMODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075c54aa-aefe-41c9-9c2d-24a3f7692f82",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. Festlegen der GPU für die Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d1ee902d-71e4-402e-b0d7-dab04e618105",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(/home/thsch026/my-envs/PruneMe) \n"
     ]
    }
   ],
   "source": [
    "export CUDA_VISIBLE_DEVICES=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d0e153-941d-4ecf-999c-367dd69654d2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 4 Analyse für die Extraktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6ca1a101-5ca8-40c2-8242-3148a36dad42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(/home/thsch026/my-envs/PruneMe) \n",
      "/home/thsch026/my-envs/PruneMe/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|█████████████████| 2/2 [04:03<00:00, 121.78s/it]\n",
      "/home/thsch026/my-envs/PruneMe/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Processing batches: 100%|█████████████████████| 500/500 [01:47<00:00,  4.66it/s]\n",
      "INFO:root:Layer 18 to 30 has the minimum average distance of 0.332935546875. Consider examining this layer more closely for potential optimization or removal.\n",
      "INFO:root:Layer distances written to layer_distances.csv\n",
      "(/home/thsch026/my-envs/PruneMe) \n"
     ]
    }
   ],
   "source": [
    "cd '/home/thsch026/masterarbeit/experiment/PruneMe/compute_block_similarity'\n",
    "python layer_similarity.py --model_path $MODEL \\\n",
    "                      --dataset \"arcee-ai/sec-data-mini\" \\\n",
    "                      --dataset_column \"text\" \\\n",
    "                      --batch_size 8 \\\n",
    "                      --max_length 1024 \\\n",
    "                      --layers_to_skip $LAYERSPRUNED \\\n",
    "                      --dataset_size 4000 \\\n",
    "                      --dataset_subset \"train\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48aefdf3-d54c-4bfd-b7e5-559ed9a758a1",
   "metadata": {},
   "source": [
    "#### 5. Sichern der Resultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b515a3ac-649e-48d2-8848-c48d36462fae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(/home/thsch026/my-envs/PruneMe) \n",
      "(/home/thsch026/my-envs/PruneMe) \n"
     ]
    }
   ],
   "source": [
    "mkdir $RESULTS\n",
    "cp layer_distances.csv $RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f8ca71-d630-42cb-a8bc-7dafe75997ec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 5. Ausführen des Merging Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b01c967e-540d-4748-8ab4-2c1d200f4265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(/home/thsch026/my-envs/PruneMe) \n",
      "(/home/thsch026/my-envs/PruneMe) \n",
      "(/home/thsch026/my-envs/PruneMe) \n",
      "/home/thsch026/my-envs/PruneMe/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Warmup loader cache:   0%|                                | 0/1 [00:00<?, ?it/s]\n",
      "Fetching 11 files:   0%|                                 | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Fetching 11 files: 100%|████████████████████████| 11/11 [00:00<00:00, 41.47it/s]\u001b[A\n",
      "Warmup loader cache: 100%|████████████████████████| 1/1 [00:00<00:00,  1.74it/s]\n",
      "Executing graph: 100%|████████████████████████| 734/734 [03:44<00:00,  3.27it/s]\n",
      "/home/thsch026/my-envs/PruneMe/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Done!\n",
      "(/home/thsch026/my-envs/PruneMe) \n"
     ]
    }
   ],
   "source": [
    "export MERGE='/home/thsch026/masterarbeit/experiment/PruneMe/slice_with_mergekit'\n",
    "cp $RESULTS/slice.yaml $MERGE\n",
    "cd $MERGE\n",
    "python merge_me.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2e24055e-51ec-4fcc-bd31-da4c31cd39ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(/home/thsch026/my-envs/PruneMe) \n"
     ]
    }
   ],
   "source": [
    "mv merged $PRUNEMODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "40e9247b-783d-41ab-9317-02a959c860ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(/home/thsch026/my-envs/PruneMe) \n",
      "/home/thsch026/masterarbeit/models/generated/prune/pruneme/Meta-Llama-3-8B-12_Ext\n",
      "(/home/thsch026/my-envs/PruneMe) \n",
      "total 8411081\n",
      "-rw-r--r-- 1 jovyan users 4953586384 Jun 30 19:23 model-00001-of-00003.safetensors\n",
      "-rw-r--r-- 1 jovyan users 4999819296 Jun 30 19:24 model-00002-of-00003.safetensors\n",
      "-rw-r--r-- 1 jovyan users        762 Jun 30 19:25 README.md\n",
      "-rw-r--r-- 1 jovyan users      14314 Jun 30 19:25 model.safetensors.index.json\n",
      "-rw-r--r-- 1 jovyan users  872450064 Jun 30 19:25 model-00003-of-00003.safetensors\n",
      "-rw-r--r-- 1 jovyan users        198 Jun 30 19:25 mergekit_config.yml\n",
      "-rw-r--r-- 1 jovyan users        698 Jun 30 19:25 config.json\n",
      "-rw-r--r-- 1 jovyan users    9085671 Jun 30 19:25 tokenizer.json\n",
      "-rw-r--r-- 1 jovyan users      50566 Jun 30 19:25 tokenizer_config.json\n",
      "-rw-r--r-- 1 jovyan users        301 Jun 30 19:25 special_tokens_map.json\n",
      "(/home/thsch026/my-envs/PruneMe) \n"
     ]
    }
   ],
   "source": [
    "cd $PRUNEMODEL\n",
    "pwd\n",
    "ls -ltr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e43bcc-8acf-40e3-a4d1-2890d233f2d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
