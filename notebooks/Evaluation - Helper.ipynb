{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea8833b8-cb89-4b45-915e-5dd3713e37fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(/home/thsch026/my-envs/eval) \n"
     ]
    }
   ],
   "source": [
    "conda activate eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76d75edb-3d4f-4003-b32a-805277a808a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(/home/thsch026/my-envs/eval) \n",
      "(/home/thsch026/my-envs/eval) \n",
      "(/home/thsch026/my-envs/eval) \n"
     ]
    }
   ],
   "source": [
    "export MODEL=\"/home/thsch026/masterarbeit/models/generated/prune/pruneme/Llama-2-7b-chat-hf-8_Ext\"\n",
    "export WANDB_NAME=\"Llama 7B chat PruneMe 8_Ext \"\n",
    "export WANDB_NOTES=\"Llama 7B chat 8 Layer mit PruneMe extrahiert\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d6b161e-bc2b-4c33-b40b-38eb770a51d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(/home/thsch026/my-envs/eval) \n",
      "2\n",
      "(/home/thsch026/my-envs/eval) \n"
     ]
    }
   ],
   "source": [
    "export CUDA_VISIBLE_DEVICES=\"2\"\n",
    "echo $CUDA_VISIBLE_DEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "128a4859-108b-4071-92ad-053ba1bdce8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mthomas-t-schmitt\u001b[0m (\u001b[33mpumaai\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.17.3 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/thsch026/masterarbeit/Slim/notebooks/wandb/run-20240701_080819-63ctcce5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mLlama 7B chat PruneMe 8_Ext \u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/pumaai/lm-eval-harness-integration\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/pumaai/lm-eval-harness-integration/runs/63ctcce5\u001b[0m\n",
      "2024-07-01:08:08:23,385 INFO     [__main__.py:254] Verbosity set to INFO\n",
      "2024-07-01:08:08:33,329 INFO     [__main__.py:341] Selected Tasks: ['arc_challenge', 'hellaswag', 'truthfulqa_mc2', 'winogrande']\n",
      "2024-07-01:08:08:33,335 INFO     [evaluator.py:141] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2024-07-01:08:08:33,335 INFO     [evaluator.py:187] Initializing hf model, with arguments: {'pretrained': '/home/thsch026/masterarbeit/models/generated/prune/pruneme/Llama-2-7b-chat-hf-8_Ext', 'dtype': 'float16'}\n",
      "2024-07-01:08:08:33,384 WARNING  [logging.py:61] Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "2024-07-01:08:08:33,385 INFO     [huggingface.py:173] Device not specified\n",
      "2024-07-01:08:08:33,385 INFO     [huggingface.py:174] Cuda Available? True\n",
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [01:37<00:00, 32.43s/it]\n",
      "/home/thsch026/my-envs/eval/lib/python3.10/site-packages/datasets/load.py:1486: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/home/thsch026/my-envs/eval/lib/python3.10/site-packages/datasets/load.py:1486: FutureWarning: The repository for winogrande contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/winogrande\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "2024-07-01:08:10:39,628 INFO     [task.py:398] Building contexts for winogrande on rank 0...\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1267/1267 [00:00<00:00, 87797.10it/s]\n",
      "2024-07-01:08:10:39,693 INFO     [task.py:398] Building contexts for truthfulqa_mc2 on rank 0...\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 817/817 [00:00<00:00, 926.21it/s]\n",
      "2024-07-01:08:10:40,630 INFO     [task.py:398] Building contexts for hellaswag on rank 0...\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10042/10042 [00:03<00:00, 3140.15it/s]\n",
      "2024-07-01:08:10:46,209 INFO     [task.py:398] Building contexts for arc_challenge on rank 0...\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1172/1172 [00:00<00:00, 1457.07it/s]\n",
      "2024-07-01:08:10:47,080 INFO     [evaluator.py:404] Running loglikelihood requests\n",
      "Running loglikelihood requests:   0%|                 | 0/53271 [00:00<?, ?it/s]Passed argument batch_size = auto:1. Detecting largest batch size\n",
      "Determined largest batch size: 64\n",
      "Running loglikelihood requests: 100%|‚ñà‚ñà‚ñà‚ñà| 53271/53271 [08:42<00:00, 101.92it/s]\n",
      "2024-07-01:08:20:03,044 WARNING  [huggingface.py:1304] Failed to get model SHA for /home/thsch026/masterarbeit/models/generated/prune/pruneme/Llama-2-7b-chat-hf-8_Ext at revision main. Error: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/home/thsch026/masterarbeit/models/generated/prune/pruneme/Llama-2-7b-chat-hf-8_Ext'. Use `repo_type` argument if needed.\n",
      "2024-07-01:08:20:17,848 INFO     [evaluation_tracker.py:132] Saving results aggregated\n",
      "2024-07-01:08:20:17,868 INFO     [evaluation_tracker.py:203] Saving samples results\n",
      "2024-07-01:08:20:17,964 INFO     [evaluation_tracker.py:203] Saving samples results\n",
      "2024-07-01:08:20:19,156 INFO     [evaluation_tracker.py:203] Saving samples results\n",
      "2024-07-01:08:20:19,302 INFO     [evaluation_tracker.py:203] Saving samples results\n",
      "hf (pretrained=/home/thsch026/masterarbeit/models/generated/prune/pruneme/Llama-2-7b-chat-hf-8_Ext,dtype=float16), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: auto (64)\n",
      "|    Tasks     |Version|Filter|n-shot| Metric |Value |   |Stderr|\n",
      "|--------------|------:|------|-----:|--------|-----:|---|-----:|\n",
      "|winogrande    |      1|none  |     0|acc     |0.6464|¬±  |0.0134|\n",
      "|truthfulqa_mc2|      2|none  |     0|acc     |   NaN|¬±  |   NaN|\n",
      "|hellaswag     |      1|none  |     0|acc     |0.4163|¬±  |0.0049|\n",
      "|              |       |none  |     0|acc_norm|0.5730|¬±  |0.0049|\n",
      "|arc_challenge |      1|none  |     0|acc     |0.3242|¬±  |0.0137|\n",
      "|              |       |none  |     0|acc_norm|0.3729|¬±  |0.0141|\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             arc_challenge/acc ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        arc_challenge/acc_norm ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: arc_challenge/acc_norm_stderr ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      arc_challenge/acc_stderr ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 hellaswag/acc ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            hellaswag/acc_norm ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     hellaswag/acc_norm_stderr ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          hellaswag/acc_stderr ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                winogrande/acc ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         winogrande/acc_stderr ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             arc_challenge/acc 0.32423\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        arc_challenge/acc_norm 0.37287\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: arc_challenge/acc_norm_stderr 0.01413\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      arc_challenge/acc_stderr 0.01368\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           arc_challenge/alias arc_challenge\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 hellaswag/acc 0.41625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            hellaswag/acc_norm 0.57299\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     hellaswag/acc_norm_stderr 0.00494\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          hellaswag/acc_stderr 0.00492\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               hellaswag/alias hellaswag\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            truthfulqa_mc2/acc nan\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     truthfulqa_mc2/acc_stderr nan\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          truthfulqa_mc2/alias truthfulqa_mc2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                winogrande/acc 0.64641\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         winogrande/acc_stderr 0.01344\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              winogrande/alias winogrande\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mLlama 7B chat PruneMe 8_Ext \u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/pumaai/lm-eval-harness-integration/runs/63ctcce5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/pumaai/lm-eval-harness-integration\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 5 media file(s), 6 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240701_080819-63ctcce5/logs\u001b[0m\n",
      "(/home/thsch026/my-envs/eval) \n"
     ]
    }
   ],
   "source": [
    "lm_eval --model hf  --model_args pretrained=$MODEL,dtype=float16  --tasks arc_challenge,hellaswag,truthfulqa_mc2,winogrande \\\n",
    "        --device cuda:2 --batch_size auto --wandb_args project=lm-eval-harness-integration --log_samples \\\n",
    "        --output_path \"/home/thsch026/masterarbeit/Slim/results\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b512f1-e9ab-4233-9e1d-642b1da98837",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
