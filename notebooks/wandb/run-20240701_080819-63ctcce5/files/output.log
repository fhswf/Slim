
2024-07-01:08:08:23,385 INFO     [__main__.py:254] Verbosity set to INFO
2024-07-01:08:08:33,329 INFO     [__main__.py:341] Selected Tasks: ['arc_challenge', 'hellaswag', 'truthfulqa_mc2', 'winogrande']
2024-07-01:08:08:33,335 INFO     [evaluator.py:141] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-01:08:08:33,335 INFO     [evaluator.py:187] Initializing hf model, with arguments: {'pretrained': '/home/thsch026/masterarbeit/models/generated/prune/pruneme/Llama-2-7b-chat-hf-8_Ext', 'dtype': 'float16'}
2024-07-01:08:08:33,384 WARNING  [logging.py:61] Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2024-07-01:08:08:33,385 INFO     [huggingface.py:173] Device not specified
2024-07-01:08:08:33,385 INFO     [huggingface.py:174] Cuda Available? True



Loading checkpoint shards: 100%|██████████████████| 3/3 [01:37<00:00, 32.43s/it]
/home/thsch026/my-envs/eval/lib/python3.10/site-packages/datasets/load.py:1486: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/home/thsch026/my-envs/eval/lib/python3.10/site-packages/datasets/load.py:1486: FutureWarning: The repository for winogrande contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/winogrande
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
2024-07-01:08:10:39,628 INFO     [task.py:398] Building contexts for winogrande on rank 0...
100%|████████████████████████████████████| 1267/1267 [00:00<00:00, 87797.10it/s]
2024-07-01:08:10:39,693 INFO     [task.py:398] Building contexts for truthfulqa_mc2 on rank 0...
100%|████████████████████████████████████████| 817/817 [00:00<00:00, 926.21it/s]
2024-07-01:08:10:40,630 INFO     [task.py:398] Building contexts for hellaswag on rank 0...

100%|███████████████████████████████████| 10042/10042 [00:03<00:00, 3140.15it/s]
2024-07-01:08:10:46,209 INFO     [task.py:398] Building contexts for arc_challenge on rank 0...
100%|█████████████████████████████████████| 1172/1172 [00:00<00:00, 1457.07it/s]
2024-07-01:08:10:47,080 INFO     [evaluator.py:404] Running loglikelihood requests
Running loglikelihood requests:   0%|                 | 0/53271 [00:00<?, ?it/s]

Running loglikelihood requests:   0%|     | 1/53271 [00:11<163:47:14, 11.07s/it]
































































































































































































































































Running loglikelihood requests: 100%|████| 53271/53271 [08:42<00:00, 101.92it/s]
2024-07-01:08:20:03,044 WARNING  [huggingface.py:1304] Failed to get model SHA for /home/thsch026/masterarbeit/models/generated/prune/pruneme/Llama-2-7b-chat-hf-8_Ext at revision main. Error: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/home/thsch026/masterarbeit/models/generated/prune/pruneme/Llama-2-7b-chat-hf-8_Ext'. Use `repo_type` argument if needed.
2024-07-01:08:20:17,848 INFO     [evaluation_tracker.py:132] Saving results aggregated
2024-07-01:08:20:17,868 INFO     [evaluation_tracker.py:203] Saving samples results
2024-07-01:08:20:17,964 INFO     [evaluation_tracker.py:203] Saving samples results
2024-07-01:08:20:19,156 INFO     [evaluation_tracker.py:203] Saving samples results
2024-07-01:08:20:19,302 INFO     [evaluation_tracker.py:203] Saving samples results
hf (pretrained=/home/thsch026/masterarbeit/models/generated/prune/pruneme/Llama-2-7b-chat-hf-8_Ext,dtype=float16), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: auto (64)
|    Tasks     |Version|Filter|n-shot| Metric |Value |   |Stderr|
|--------------|------:|------|-----:|--------|-----:|---|-----:|
|winogrande    |      1|none  |     0|acc     |0.6464|±  |0.0134|
|truthfulqa_mc2|      2|none  |     0|acc     |   NaN|±  |   NaN|
|hellaswag     |      1|none  |     0|acc     |0.4163|±  |0.0049|
|              |       |none  |     0|acc_norm|0.5730|±  |0.0049|
|arc_challenge |      1|none  |     0|acc     |0.3242|±  |0.0137|
|              |       |none  |     0|acc_norm|0.3729|±  |0.0141|