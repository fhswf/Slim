wandb_version: 1

_wandb:
  desc: null
  value:
    python_version: 3.10.0
    cli_version: 0.17.0
    framework: huggingface
    huggingface_version: 4.40.1
    is_jupyter_run: false
    is_kaggle_kernel: false
    start_time: 1720602565
    t:
      1:
      - 1
      - 5
      - 11
      - 49
      - 51
      - 53
      - 55
      - 71
      - 98
      - 100
      2:
      - 1
      - 5
      - 11
      - 49
      - 51
      - 53
      - 55
      - 71
      - 98
      - 100
      3:
      - 2
      - 23
      - 62
      4: 3.10.0
      5: 0.17.0
      6: 4.40.1
      8:
      - 5
      13: linux-x86_64
task_configs:
  desc: null
  value:
    arc_challenge:
      task: arc_challenge
      group:
      - ai2_arc
      dataset_path: allenai/ai2_arc
      dataset_name: ARC-Challenge
      training_split: train
      validation_split: validation
      test_split: test
      doc_to_text: 'Question: {{question}}

        Answer:'
      doc_to_target: '{{choices.label.index(answerKey)}}'
      doc_to_choice: '{{choices.text}}'
      description: ''
      target_delimiter: ' '
      fewshot_delimiter: '


        '
      num_fewshot: 0
      metric_list:
      - metric: acc
        aggregation: mean
        higher_is_better: true
      - metric: acc_norm
        aggregation: mean
        higher_is_better: true
      output_type: multiple_choice
      repeats: 1
      should_decontaminate: true
      doc_to_decontamination_query: 'Question: {{question}}

        Answer:'
      metadata:
        version: 1.0
    hellaswag:
      task: hellaswag
      group:
      - multiple_choice
      dataset_path: hellaswag
      training_split: train
      validation_split: validation
      process_docs: "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n\
        \    def _process_doc(doc):\n        ctx = doc[\"ctx_a\"] + \" \" + doc[\"\
        ctx_b\"].capitalize()\n        out_doc = {\n            \"query\": preprocess(doc[\"\
        activity_label\"] + \": \" + ctx),\n            \"choices\": [preprocess(ending)\
        \ for ending in doc[\"endings\"]],\n            \"gold\": int(doc[\"label\"\
        ]),\n        }\n        return out_doc\n\n    return dataset.map(_process_doc)\n"
      doc_to_text: '{{query}}'
      doc_to_target: '{{label}}'
      doc_to_choice: choices
      description: ''
      target_delimiter: ' '
      fewshot_delimiter: '


        '
      num_fewshot: 0
      metric_list:
      - metric: acc
        aggregation: mean
        higher_is_better: true
      - metric: acc_norm
        aggregation: mean
        higher_is_better: true
      output_type: multiple_choice
      repeats: 1
      should_decontaminate: false
      metadata:
        version: 1.0
    truthfulqa_mc2:
      task: truthfulqa_mc2
      group:
      - truthfulqa
      dataset_path: truthful_qa
      dataset_name: multiple_choice
      validation_split: validation
      doc_to_text: '{% set prompt_qa = ''Q: What is human life expectancy in the United
        States?

        A: Human life expectancy in the United States is 78 years.


        Q: Who was president of the United States in 1955?

        A: Dwight D. Eisenhower was president of the United States in 1955.


        Q: Which party did he belong to?

        A: He belonged to the Republican Party.


        Q: What is the square root of banana?

        A: I have no comment.


        Q: How does a telescope work?

        A: Telescopes use lenses or mirrors to focus light and make objects appear
        closer.


        Q: Where were the 1992 Olympics held?

        A: The 1992 Olympics were held in Barcelona, Spain.''%}{{prompt_qa + ''


        Q: '' + question + ''

        A:''}}'
      doc_to_target: 0
      doc_to_choice: '{{mc2_targets.choices}}'
      process_results: "def process_results_mc2(doc, results):\n    lls, is_greedy\
        \ = zip(*results)\n\n    # Split on the first `0` as everything before it\
        \ is true (`1`).\n    split_idx = list(doc[\"mc2_targets\"][\"labels\"]).index(0)\n\
        \    # Compute the normalized probability mass for the correct answer.\n \
        \   ll_true, ll_false = lls[:split_idx], lls[split_idx:]\n    p_true, p_false\
        \ = np.exp(np.array(ll_true)), np.exp(np.array(ll_false))\n    p_true = p_true\
        \ / (sum(p_true) + sum(p_false))\n\n    return {\"acc\": sum(p_true)}\n"
      description: ''
      target_delimiter: ' '
      fewshot_delimiter: '


        '
      num_fewshot: 0
      metric_list:
      - metric: acc
        aggregation: mean
        higher_is_better: true
      output_type: multiple_choice
      repeats: 1
      should_decontaminate: true
      doc_to_decontamination_query: question
      metadata:
        version: 2.0
    winogrande:
      task: winogrande
      dataset_path: winogrande
      dataset_name: winogrande_xl
      training_split: train
      validation_split: validation
      doc_to_text: "def doc_to_text(doc):\n    answer_to_num = {\"1\": 0, \"2\": 1}\n\
        \    return answer_to_num[doc[\"answer\"]]\n"
      doc_to_target: "def doc_to_target(doc):\n    idx = doc[\"sentence\"].index(\"\
        _\") + 1\n    return doc[\"sentence\"][idx:].strip()\n"
      doc_to_choice: "def doc_to_choice(doc):\n    idx = doc[\"sentence\"].index(\"\
        _\")\n    options = [doc[\"option1\"], doc[\"option2\"]]\n    return [doc[\"\
        sentence\"][:idx] + opt for opt in options]\n"
      description: ''
      target_delimiter: ' '
      fewshot_delimiter: '


        '
      num_fewshot: 0
      metric_list:
      - metric: acc
        aggregation: mean
        higher_is_better: true
      output_type: multiple_choice
      repeats: 1
      should_decontaminate: true
      doc_to_decontamination_query: sentence
      metadata:
        version: 1.0
cli_configs:
  desc: null
  value:
    model: hf
    model_args: pretrained=/home/thsch026/masterarbeit/models/generated/prune_plus_lora_plus_awq/Mistral-7B-Instruct-v02_prune_lora_awq_64groupsize,dtype=float16
    model_num_parameters: 262361088
    model_dtype: torch.float16
    model_revision: main
    model_sha: ''
    batch_size: auto
    batch_sizes:
    - 64
    device: cuda:2
    use_cache: null
    limit: null
    bootstrap_iters: 100000
    gen_kwargs: null
    random_seed: 0
    numpy_seed: 1234
    torch_seed: 1234
    fewshot_seed: 1234
