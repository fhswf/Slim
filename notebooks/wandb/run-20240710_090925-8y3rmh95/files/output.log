
2024-07-10:09:09:30,177 INFO     [__main__.py:254] Verbosity set to INFO
2024-07-10:09:09:41,103 INFO     [__main__.py:341] Selected Tasks: ['arc_challenge', 'hellaswag', 'truthfulqa_mc2', 'winogrande']
2024-07-10:09:09:41,109 INFO     [evaluator.py:141] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-10:09:09:41,109 INFO     [evaluator.py:187] Initializing hf model, with arguments: {'pretrained': '/home/thsch026/masterarbeit/models/generated/prune_plus_lora_plus_awq/Mistral-7B-Instruct-v02_prune_lora_awq_64groupsize', 'dtype': 'float16'}
2024-07-10:09:09:41,772 WARNING  [logging.py:61] Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2024-07-10:09:09:41,772 INFO     [huggingface.py:173] Device not specified
2024-07-10:09:09:41,772 INFO     [huggingface.py:174] Cuda Available? True
/home/thsch026/my-envs/eval/lib/python3.10/site-packages/datasets/load.py:1486: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/home/thsch026/my-envs/eval/lib/python3.10/site-packages/datasets/load.py:1486: FutureWarning: The repository for winogrande contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/winogrande
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
2024-07-10:09:11:18,943 INFO     [task.py:398] Building contexts for winogrande on rank 0...
100%|███████████████████████████████████| 1267/1267 [00:00<00:00, 105940.42it/s]
2024-07-10:09:11:18,999 INFO     [task.py:398] Building contexts for truthfulqa_mc2 on rank 0...
100%|████████████████████████████████████████| 817/817 [00:00<00:00, 991.63it/s]
2024-07-10:09:11:19,879 INFO     [task.py:398] Building contexts for hellaswag on rank 0...

100%|███████████████████████████████████| 10042/10042 [00:02<00:00, 3359.01it/s]
2024-07-10:09:11:24,109 INFO     [task.py:398] Building contexts for arc_challenge on rank 0...
100%|█████████████████████████████████████| 1172/1172 [00:00<00:00, 1587.52it/s]
2024-07-10:09:11:24,907 INFO     [evaluator.py:404] Running loglikelihood requests
Running loglikelihood requests:   0%|                 | 0/53271 [00:00<?, ?it/s]
Passed argument batch_size = auto:1. Detecting largest batch size































































































































































































































































































Running loglikelihood requests: 100%|█████| 53271/53271 [09:45<00:00, 90.95it/s]
2024-07-10:09:21:37,449 WARNING  [huggingface.py:1304] Failed to get model SHA for /home/thsch026/masterarbeit/models/generated/prune_plus_lora_plus_awq/Mistral-7B-Instruct-v02_prune_lora_awq_64groupsize at revision main. Error: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/home/thsch026/masterarbeit/models/generated/prune_plus_lora_plus_awq/Mistral-7B-Instruct-v02_prune_lora_awq_64groupsize'. Use `repo_type` argument if needed.
2024-07-10:09:21:52,116 INFO     [evaluation_tracker.py:132] Saving results aggregated
2024-07-10:09:21:52,134 INFO     [evaluation_tracker.py:203] Saving samples results
2024-07-10:09:21:52,244 INFO     [evaluation_tracker.py:203] Saving samples results
2024-07-10:09:21:53,324 INFO     [evaluation_tracker.py:203] Saving samples results
2024-07-10:09:21:53,461 INFO     [evaluation_tracker.py:203] Saving samples results
hf (pretrained=/home/thsch026/masterarbeit/models/generated/prune_plus_lora_plus_awq/Mistral-7B-Instruct-v02_prune_lora_awq_64groupsize,dtype=float16), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: auto (64)
|    Tasks     |Version|Filter|n-shot| Metric |Value |   |Stderr|
|--------------|------:|------|-----:|--------|-----:|---|-----:|
|winogrande    |      1|none  |     0|acc     |0.7048|±  |0.0128|
|truthfulqa_mc2|      2|none  |     0|acc     |0.5687|±  |0.0155|
|hellaswag     |      1|none  |     0|acc     |0.5574|±  |0.0050|
|              |       |none  |     0|acc_norm|0.7400|±  |0.0044|
|arc_challenge |      1|none  |     0|acc     |0.4539|±  |0.0145|
|              |       |none  |     0|acc_norm|0.4804|±  |0.0146|