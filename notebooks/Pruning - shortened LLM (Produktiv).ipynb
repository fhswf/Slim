{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa213e74-c2b9-4c46-ade4-d9af870a5e1d",
   "metadata": {},
   "source": [
    "# Pruning with shortened-llm\n",
    "Source: https://github.com/Nota-NetsPresso/shortened-llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b6c124-f88f-40ba-ad6b-6425d7320f78",
   "metadata": {},
   "source": [
    "## Download der Dateien und erstellen des conda envrionments (Nur einmalig notwendig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3249e485-a509-4062-995d-3ada27247385",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda create -n shortened-llm python=3.9\n",
    "conda activate shortened-llm\n",
    "git clone https://github.com/Nota-NetsPresso/shortened-llm.git\n",
    "cd shortened-llm\n",
    "pip install -r requirement.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19000b52-9800-4e8c-90e6-0febd6587cf2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Zusätzliche Pakete, die in dem Setup nicht enthalten waren, aber benötigt werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac2b79e-652f-4d94-b72b-785e369a4c86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install typing_extensions packaging pygments psutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f97712-49d8-4805-ad2f-20f5e9fdb9e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Start der Modell Compression\n",
    "Das Verfahren wird in einer Bash Shell gestartet. Dazu wird die conda Umgebung \"shortened-llm\" geladen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c5dee5-a889-42ea-8a27-e22f17728cfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conda activate shortened-llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c5f6d3-a67b-42ea-8cbc-018de04b20be",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /home/thsch026/masterarbeit/experiment/shortened-llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b9616f-59a1-48b9-b42f-694a839b53ff",
   "metadata": {},
   "source": [
    "### Festlegen einer nutzbaren GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e778db-ad18-4873-ae83-3c58c3c3bf64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export CUDA_VISIBLE_DEVICES=\"2\"\n",
    "echo $CUDA_VISIBLE_DEVICES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92d61d4-e132-4189-9214-efce3b0981e4",
   "metadata": {},
   "source": [
    "### Auswahl des Modells\n",
    "- In dem Verzeichnis \"script\" der Installation findet man vorgefertigte scripte für die Nutzung\n",
    "    - In diesen Scripten können aauch Anpassungen vorgenommen werden (z.Bsp. wie viele Schichten des Modells enfernt werden sollen)\n",
    "- In den Scripten müssen einige Variablen angepasst werden\n",
    "- Das jeweilige Script wird ausgeführt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05de157c-96aa-4a9e-b9ca-c0181a5ae55d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Llama2-7B-Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a918f9-3c04-463c-a22a-093253b53682",
   "metadata": {},
   "outputs": [],
   "source": [
    "script/prune_llama2-7b_crit-taylor.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acd132d-bbd3-4a12-ab2b-cbcc0a76aba8",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Llama3-8B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22e4f20-277f-44af-9c54-355700baee2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "script/prune_llama3-8b-instruct_crit-taylor.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765e3374-b8ab-4443-acbd-3f8e7a5ae2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "script/prune_llama3-8b-instruct_crit-taylor_tom1.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f3c2b9-08e8-4247-94a7-00405e083f3b",
   "metadata": {},
   "source": [
    "#### Mistral-7B-Instruct-v0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe91b721-0599-4747-8afc-89ccf3f6eb35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "script/prune_Mistral_crit-taylor.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3377c217-451f-4329-9317-68323ea449a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Ergebnisse\n",
    "- Im Ordner \"output_prune\" findet man die geprunten modelle\n",
    "- Im zweiten Schritt werden diese Modelle noch mittels lora trainiert. Die fertigen Modelle (pruned + tuned) befinden sich im Ordner \"output_tune\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631388d2-08a2-499c-a4e5-62801e73126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "script/lora_ger_llama3-8b-instruct-prune-lora_crit-taylor_tom.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ff0d38-5463-414b-8e8f-1cd6658381f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f42066-9404-4c38-afa4-855b0bf17ad5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e489834-4294-4271-a79e-b332c99ff791",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
