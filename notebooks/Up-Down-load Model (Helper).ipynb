{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6ff46c1-6659-4112-9e32-80289f3dfa6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "#notebook_login()\n",
    "\n",
    "# HF Key: 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04c744f2-1814-4a09-b220-58813a26b033",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/thsch026/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3-70B-Instruct/snapshots/7129260dd854a80eb10ace5f61c20324b472b31c/config.json'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "hf_hub_download(repo_id=\"meta-llama/Meta-Llama-3-70B-Instruct\", filename=\"config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b282a4a1-e554-4ca2-a2df-6c7e02b10e1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "#tokenizer = AutoTokenizer.from_pretrained('mistralai/Mistral-7B-Instruct-v0.2')\n",
    "model = AutoModelForCausalLM.from_pretrained('meta-llama/Meta-Llama-3-70B-Instruct', safetensors=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9630c5c-f451-40cb-b089-3a915cabf21a",
   "metadata": {},
   "source": [
    "## Download Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058671fd-56ef-4b1a-99c3-5a9228bc2498",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "hf_download = \"Mistral-7B-Instruct-v0.2_gptq_4bit\"\n",
    "save_location  = \"/home/thsch026/masterarbeit/models/mistral/mistral-7B-v0.1\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-v0.1\")\n",
    "model.save_pretrained(save_location, safetensors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd1d417-330a-400f-be92-4acdd2054945",
   "metadata": {},
   "source": [
    "## Upload Models to HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2708d95b-ddf5-42c7-acfd-e9c3cfe7779b",
   "metadata": {
    "id": "eRuXAMlDIZAQ",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "botox100/Llama_3_8B_Instruct-prune-lora-gptq\n"
     ]
    }
   ],
   "source": [
    "username = \"botox100\"\n",
    "model_name = \"Llama_3_8B_Instruct-prune-lora-gptq\"\n",
    "repo = username+\"/\"+model_name\n",
    "local_folder = \"/home/thsch026/masterarbeit/models/generated/prune_lora_gptq/Llama_3_8B_Instruct-prune-lora-gptq\"\n",
    "print(repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8bc1aa7-dd38-48ee-b66d-8f0bc07573a9",
   "metadata": {
    "id": "eRuXAMlDIZAQ",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "botox100/Llama-2-7b-chat-hf_prune_lora_awq\n"
     ]
    }
   ],
   "source": [
    "username = \"botox100\"\n",
    "model_name = \"Llama-2-7b-chat-hf_prune_lora_awq\"\n",
    "repo = username+\"/\"+model_name\n",
    "local_folder = \"/home/thsch026/masterarbeit/models/generated/prune_plus_lora_plus_awq/Llama-2-7b-chat-hf_prune_lora_awq\"\n",
    "print(repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20cee71e-f60a-41c6-a5d7-ba5715269d81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40f00c02289e48cdb54a2be5f3cd3b2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6206b979ab59409fa2af35a838b3f07d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/5.39G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08d890baf67e4272bd415e3b9b4e59b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/5.39G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/botox100/Llama_3_8B_Instruct-prune-lora-gptq/commit/03f6219a449bc3d6c08f0c48d548ebaa6cdb09d5', commit_message='Upload folder using huggingface_hub', commit_description='', oid='03f6219a449bc3d6c08f0c48d548ebaa6cdb09d5', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import upload_folder, create_repo\n",
    "\n",
    "create_repo(\n",
    "    repo_id = repo\n",
    ")\n",
    "    \n",
    "upload_folder(\n",
    "    repo_id = repo,\n",
    "    folder_path = local_folder\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da431fda-d3cc-4819-82b8-a7ccdf30ca7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
