{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "493334c9-5d20-41bd-abfc-333b6bebaacd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Qlora for Llama3. runs with \"qlora3\" kernel\n",
    "- Source: https://medium.com/@avishekpaul31/fine-tuning-llama-3-8b-instruct-qlora-using-low-cost-resources-89075e0dfa04\n",
    "- Source: https://github.com/AvisP/LM_Finetune/blob/main/llama-3-finetune-qlora.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc5b723-0043-433b-ac04-b8d527b13b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# workaround for packaging fehler\n",
    "pip install setuptools==69.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530eb66b-52f5-499c-8c42-628e5884b0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch==2.0.1\n",
    "!pip install bitsandbytes\n",
    "!pip install -U transformers[torch] datasets\n",
    "!pip install -q bitsandbytes trl peft accelerate\n",
    "!pip install flash-attn --no-build-isolation\n",
    "!pip install transformers==4.40.2 # Es geht nur genau diese Version!!\n",
    "!pip install trl\n",
    "!pip install autoawq\n",
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cc0704-8c66-45bc-9a54-4e4be5775b28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install sentencepiece\n",
    "!pip install mistral_inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46074ac4-8243-4eb7-b1d5-94e1ece5afe9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!conda list | grep trl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f713146b-6adf-48e9-9ca8-709d86d33c37",
   "metadata": {},
   "source": [
    "## Start Qlora Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92a8e1d0-32ad-489e-9f6d-b07c3c4beff4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "#notebook_login()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75387894-b2b7-454f-b8c5-d9bf745b2afc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Set Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222b86be-979e-452f-b8fb-79e217c4c3e6",
   "metadata": {},
   "source": [
    "### LLama-3-8B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951cf6e1-11e5-4b75-b5df-33548cba7dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\n",
    "\n",
    "# Storage Location\n",
    "trained_model_id = \"Meta-Llama-3-8B-Instruct_qlora\"\n",
    "output_dir = '/home/thsch026/masterarbeit/models/generated/qlora/' + trained_model_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4fd613-aa1b-4b13-9d24-0c4acc760189",
   "metadata": {},
   "source": [
    "### Mistral 7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2409fa9d-c159-40d7-b02e-495f28ee258a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "# Storage Location\n",
    "trained_model_id = \"Mistral-7B-Instruct-v0.2_qlora\"\n",
    "output_dir = '/home/thsch026/masterarbeit/models/generated/qlora/' + trained_model_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c24a69-f2e2-401a-8457-2e3842f6ee98",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83a31a82-9158-420b-b960-5a4839043c66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thsch026/my-envs/qlora3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f61c19665ad453ba918fbad1f45e7cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thsch026/my-envs/qlora3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f247ca16-4229-4e4e-9451-a03ee24b1073",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Dataset and trim for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59959d33-cad8-4b75-934f-07f736a89d30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:256\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "!echo $CUDA_VISIBLE_DEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4b83eea-46fa-4540-a8b3-5f0b14b9d532",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# based on config\n",
    "raw_datasets = load_dataset(\"HuggingFaceH4/ultrachat_200k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67e0ba5b-0453-4575-b1b9-ab927db6d910",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['prompt', 'prompt_id', 'messages'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['prompt', 'prompt_id', 'messages'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "# remove this when done debugging to include whole dataset\n",
    "indices = range(0,10000)\n",
    "\n",
    "dataset_dict = {\"train\": raw_datasets[\"train_sft\"].select(indices),\n",
    "                \"test\": raw_datasets[\"test_sft\"].select(indices)}\n",
    "\n",
    "#dataset_dict = {\"train\": raw_datasets[\"train_sft\"],\n",
    "  #              \"test\": raw_datasets[\"test_sft\"]}\n",
    "\n",
    "raw_datasets = DatasetDict(dataset_dict)\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026a6ec4-3943-4181-8c08-0c2c8a6e4f73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# raw_datasets[\"train\"][:2]['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cad6c45-6a5d-488d-ae87-b8ff878e7724",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user                :  These instructions apply to section-based themes (Responsive 6.0+, Retina 4.0+, Parallax 3.0+ Turbo 2.0+, Mobilia 5.0+). What theme version am I using?\n",
      "On your Collections pages & Featured Collections sections, you can easily show the secondary image of a product on hover by enabling one of the theme's built-in settings!\n",
      "Your Collection pages & Featured Collections sections will now display the secondary product image just by hovering over that product image thumbnail.\n",
      "Does this feature apply to all sections of the theme or just specific ones as listed in the text material?\n",
      "assistant           :  This feature only applies to Collection pages and Featured Collections sections of the section-based themes listed in the text material.\n",
      "user                :  Can you guide me through the process of enabling the secondary image hover feature on my Collection pages and Featured Collections sections?\n",
      "assistant           :  Sure, here are the steps to enable the secondary image hover feature on your Collection pages and Featured Collections sections:\n",
      "\n",
      "1. Log in to your Shopify account and go to your Online Store.\n",
      "2. Click on Customize theme for the section-based theme you are using.\n",
      "3. Navigate to the Collection pages or Featured Collections section where you want to enable the secondary image hover feature.\n",
      "4. With the section open, click on the section's setting (gear) icon in the top-left corner.\n",
      "5. In the settings panel that appears, look for an option labeled 'Image display' or 'Image hover'.\n",
      "6. If available, select 'Show secondary image on hover'.\n",
      "7. Save the changes and preview the Collection/Featured Collection page to see the effect.\n",
      "\n",
      "If you're having trouble finding the setting, the best thing to do is refer to your theme's documentation, since the location and labeling of settings can vary between themes.\n",
      "user                :  Can you provide me with a link to the documentation for my theme?\n",
      "assistant           :  I don't have access to your store's theme information. However, you can usually find the documentation for your theme by going to the shopify theme store, finding your theme and clicking on the 'support' link located in the bottom right corner of the page. Alternatively, you can do a google search for the name of your theme followed by 'documentation' or 'user guide'.\n",
      "user                :  Can you confirm if this feature also works for the Quick Shop section of my theme?\n",
      "assistant           :  The secondary image hover feature may or may not work for your Quick Shop section, depending on the configuration of your theme. Some themes include this feature in the Quick Shop section by default, while others may require additional customization. To check if this feature is available for the Quick Shop section of your theme, follow these steps:\n",
      "\n",
      "1. Go to the Quick Shop section where you would like to enable the feature. 2. Click on the Quick Shop settings icon (gear icon) and look for 'Image display' or 'Image hover'. 3. If available, select 'Show secondary image on hover'. 4. Save the changes. If this option is not available in your Quick Shop section settings, you may need to reach out to your theme developer for assistance with customizing your Quick Shop section to include this feature.\n"
     ]
    }
   ],
   "source": [
    "example = raw_datasets[\"train\"][0]\n",
    "messages = example[\"messages\"]\n",
    "for message in messages:\n",
    "  role = message[\"role\"]\n",
    "  content = message[\"content\"]\n",
    "  print('{0:20}:  {1}'.format(role, content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0876077e-e22b-4691-8900-52ca3d3ecdde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b51cae3-1486-43b0-bddd-60e40bceca16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "064303d1-aa7c-4c83-9b29-c6a475312341",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "def apply_chat_template(example, tokenizer):\n",
    "    messages = example[\"messages\"]\n",
    "    # We add an empty system message if there is none\n",
    "    #if messages[0][\"role\"] != \"system\":\n",
    "     #   messages.insert(0, {\"role\": \"system\", \"content\": \"\"})\n",
    "    example[\"text\"] = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35e13907-bdbc-4a94-810d-076314565511",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f81e2f58de744fd999cf341d7c32637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template (num_proc=128):   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9906c8814e04d8d9f2fefeb3f4a05de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template (num_proc=128):   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "column_names = list(raw_datasets[\"train\"].features)\n",
    "raw_datasets = raw_datasets.map(apply_chat_template,\n",
    "                                num_proc=cpu_count(),\n",
    "                                fn_kwargs={\"tokenizer\": tokenizer},\n",
    "                                remove_columns=column_names,\n",
    "                                desc=\"Applying chat template\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf7a7737-31e6-48f1-8aa7-770f001917ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set pad_token_id equal to the eos_token_id if not set\n",
    "if tokenizer.pad_token_id is None:\n",
    "  tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Set reasonable default for models without max length\n",
    "if tokenizer.model_max_length > 100_000:\n",
    "  tokenizer.model_max_length = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c88d141-2dd3-4fc4-9132-d55ba4cc2be3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create the splits\n",
    "train_dataset = raw_datasets[\"train\"]\n",
    "eval_dataset = raw_datasets[\"test\"]\n",
    "\n",
    "for index in random.sample(range(len(raw_datasets[\"train\"])), 3):\n",
    "  print(f\"Sample {index} of the processed training set:\\n\\n{raw_datasets['train'][index]['text']}\")\n",
    "  print(\"#####################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4989f1e-ce9c-4a50-97bf-91fa8eb8c354",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thsch026/my-envs/qlora3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c6ef8361d124419aeb38dc841c5c5eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arr matey, I be Cap'n Parrotbeak, yarr! Me hearty crew and I be roamin' these seven seas in search of treasure and adventure. Aaarrr! How be thee? What's yer quest, landlubber?\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to(model.device)\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_flash_sdp(False)\n",
    "# https://github.com/Lightning-AI/litgpt/issues/327\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=128,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    ")\n",
    "\n",
    "response = outputs[0][input_ids.shape[-1]:]\n",
    "\n",
    "print(tokenizer.decode(response, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3418fd-e002-4441-ab0c-b93d7de78435",
   "metadata": {},
   "source": [
    "## Prepare Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be076044-fbd3-4c55-9c0e-a6151816bcf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "from peft import LoraConfig\n",
    "from transformers import TrainingArguments\n",
    "from transformers import BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2506b1fc-80be-4b97-9a68-4ce7dcd04be0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# For 8 bit quantization\n",
    "quantization_config = BitsAndBytesConfig(load_in_8bit=True,\n",
    "                                        llm_int8_threshold=200.0)\n",
    "\n",
    "## For 4 bit quantization\n",
    "#quantization_config = BitsAndBytesConfig(\n",
    " #           load_in_4bit=True,\n",
    "  #          bnb_4bit_use_double_quant=True,\n",
    "   #         bnb_4bit_quant_type=\"nf4\",\n",
    "    #        bnb_4bit_compute_dtype=torch.bfloat16,)\n",
    "\n",
    "#model = AutoModelForCausalLM.from_pretrained(model_id, \n",
    " #                                            quantization_config=quantization_config,\n",
    "  #                                      device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7037ff39-f240-46f2-ae10-d74e312ad479",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_kwargs = dict(\n",
    "#     attn_implementation=False,#\"flash_attention_2\", # set this to True if your GPU supports it (Flash Attention drastically speeds up model computations)\n",
    "    torch_dtype=\"auto\",\n",
    "    use_cache=False, # set to False as we're going to use gradient checkpointing\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=quantization_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d765181-6310-46c2-8264-25aa57857d39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thsch026/my-envs/qlora3/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:166: UserWarning: You passed a model_id to the SFTTrainer. This will automatically create an `AutoModelForCausalLM` or a `PeftModel` (if you passed a `peft_config`) for you.\n",
      "  warnings.warn(\n",
      "/home/thsch026/my-envs/qlora3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb24e0a0afe4e86b59634955945e9de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23cb5488d86a4b94a91dcfb7597863e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3346 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50e7eb8b7db14a178ca009f05d1aac94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thsch026/my-envs/qlora3/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# based on config\n",
    "training_args = TrainingArguments(\n",
    "    fp16=False, # specify bf16=True instead when training on GPUs that support bf16 else fp16\n",
    "    bf16=False,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    gradient_accumulation_steps=1,\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
    "    learning_rate=2.0e-05,\n",
    "    log_level=\"info\",\n",
    "    logging_steps=5,\n",
    "    logging_strategy=\"steps\",\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    max_steps=-1,\n",
    "    num_train_epochs=1,\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    per_device_eval_batch_size=1, # originally set to 8\n",
    "    per_device_train_batch_size=1, # originally set to 8\n",
    "    push_to_hub=True,\n",
    "    hub_model_id=trained_model_id,\n",
    "    # hub_strategy=\"every_save\",\n",
    "    # report_to=\"tensorboard\",\n",
    "    report_to=\"none\",  # for skipping wandb logging\n",
    "    save_strategy=\"no\",\n",
    "    save_total_limit=None,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "# based on config\n",
    "peft_config = LoraConfig(\n",
    "        r=64,\n",
    "        lora_alpha=16,\n",
    "        lora_dropout=0.1,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "        model=model_id,\n",
    "        model_init_kwargs=model_kwargs,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        dataset_text_field=\"text\",\n",
    "        tokenizer=tokenizer,\n",
    "        packing=True,\n",
    "        peft_config=peft_config,\n",
    "        max_seq_length=tokenizer.model_max_length,\n",
    "    )\n",
    "\n",
    "# To clear out cache for unsuccessful run\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db252239-0da0-4113-a68b-1e7d2f6a9049",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ba5ab3-16c9-49c6-9eb0-2f00d857246a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 6,478\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6,478\n",
      "  Number of trainable parameters = 54,525,952\n",
      "/home/thsch026/my-envs/qlora3/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2190' max='6478' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2190/6478 2:07:09 < 4:09:12, 0.29 it/s, Epoch 0.34/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_result = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45b9115-216f-4227-8adb-f70c02230e64",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c180afb-2a32-4396-bb36-7cdf382900a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!conda list | grep torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aea2939-6291-465a-99e7-8b0038574bd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install torch==2.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b89e9c-7b4d-42a4-a538-3796d8be5ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a09105-5c5d-4b2c-86fa-84a7b91dc314",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(output_dir)\n",
    "model.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e285172-12f2-4c72-b84d-9c0c1544fa1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qlora3",
   "language": "python",
   "name": "qlora3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
