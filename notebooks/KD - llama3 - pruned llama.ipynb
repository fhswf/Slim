{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27f3cb8d-9a9e-48b7-878f-ea8374a816e4",
   "metadata": {},
   "source": [
    "## Knowledge Distillation approach with Llama3 \n",
    "- Dataset das zum Training verwendet wird ist imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c15542e-162e-4651-b3b2-f362f09c55f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Preparing environment (kdein)\n",
    "Folgende Befehle in der bash ausführen\n",
    "- conda create -n kdein python==3.10\n",
    "- conda activate kdein\n",
    "- pip install torch==2.0.1 transformers==4.40.2 datasets ipywidgets accelerate==0.30.1 wandb platformdirs\n",
    "- python -m ipykernel install --user --name=kdein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e77a95c8-6dfa-4214-b58b-4077a2f6b9ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-image              0.20.0          py310h9b08913_1    conda-forge\n",
      "scikit-learn              1.2.2           py310h41b6a48_1    conda-forge\n"
     ]
    }
   ],
   "source": [
    "# Control pytorch version --> Must be 2.0.1\n",
    "!conda list | grep scikit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6615f3fb-257d-44f0-ad4a-91ded2ebb838",
   "metadata": {},
   "source": [
    "### Define Models, dataset and output dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a944e00-7e84-4375-828c-f1eab2a12221",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cuda specifics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "940975d1-44d8-4558-87bb-b842661860f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:256\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2,3\"\n",
    "!echo $CUDA_VISIBLE_DEVICES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c67ef727-a095-4799-a39a-6173f4c36190",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset, ClassLabel\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForSequenceClassification\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertForSequenceClassification, BertTokenizerFast, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "from datasets import load_dataset, ClassLabel\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16491d95-8f7f-435a-8d66-e753ef98bf82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thsch026/my-envs/kdein/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "035c0a420cbb4bcc93a476850bcc716e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-2-7b-chat-hf and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at TinyLlama/TinyLlama-1.1B-Chat-v1.0 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory footprint Teacher: 26563.63 MB\n",
      "Memory footprint Student: 4161.14 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Teacher Model\n",
    "#teacher_dir = \"/home/thsch026/masterarbeit/models/generated/prune/pruneme/merged-llama3\"\n",
    "#teacher_dir = \"/home/thsch026/masterarbeit/models/llama3/Meta-Llama-3-8B-Instruct-HF\"\n",
    "#teacher_dir =\"meta-llama/Meta-Llama-3-8B\"\n",
    "teacher_dir = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "teacher_tokenizer = AutoTokenizer.from_pretrained(teacher_dir)\n",
    "\n",
    "# Setze den Padding-Token auf einen numerischen Wert, falls noch nicht gesetzt\n",
    "if teacher_tokenizer.pad_token is None:\n",
    "    teacher_tokenizer.add_special_tokens({'pad_token': teacher_tokenizer.eos_token})\n",
    "\n",
    "teacher_collator = DataCollatorWithPadding(tokenizer=teacher_tokenizer)\n",
    "teacher_model = AutoModelForSequenceClassification.from_pretrained(teacher_dir, num_labels=2)\n",
    "teacher_model.config.pad_token_id = teacher_tokenizer.pad_token_id\n",
    "\n",
    "#student_dir = \"/home/thsch026/masterarbeit/models/generated/prune/pruneme/merged-llama3\"\n",
    "student_dir = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "#student_dir = \"/home/thsch026/masterarbeit/models/generated/prune/pruneme/merged-llama3-small\"\n",
    "student_tokenizer = AutoTokenizer.from_pretrained(student_dir)\n",
    "# Setze den Padding-Token auf einen numerischen Wert, falls noch nicht gesetzt\n",
    "if student_tokenizer.pad_token is None:\n",
    "    student_tokenizer.add_special_tokens({'pad_token': student_tokenizer.eos_token})\n",
    "\n",
    "student_model = AutoModelForSequenceClassification.from_pretrained(student_dir, num_labels=2)\n",
    "student_collator = DataCollatorWithPadding(tokenizer=student_tokenizer)\n",
    "student_model.config.pad_token_id = student_tokenizer.pad_token_id\n",
    "\n",
    "# Memory consumption of the models\n",
    "print(f\"Memory footprint Teacher: {teacher_model.get_memory_footprint() / 1e6:.2f} MB\")\n",
    "print(f\"Memory footprint Student: {student_model.get_memory_footprint() / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2766c959-dcc5-4a8c-8c36-28a89758cfa6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs:  2\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of GPUs: \", torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5337c5d1-a5be-4fec-b10b-755f9ee00e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1:\n",
    "    \n",
    "    #teacher_model = torch.nn.parallel.DistributedDataParallel(teacher_model)\n",
    "    #student_model = torch.nn.parallel.DistributedDataParallel(student_model)\n",
    "    teacher_model = torch.nn.DataParallel(teacher_model)\n",
    "    student_model = torch.nn.DataParallel(student_model)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e71846f-dbc0-4c41-b004-3cbdff431645",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e860178-555f-4fa9-ba85-ca6e23f42bd9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Dataset MS_Marco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0d5993b-d6ef-4bb1-85f8-dbbe4993501f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2de9a383be54091bd5c70579deda834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10047 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36edc23854e84606ae5fa5c57e92a3cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/82326 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6ef44212e244efeb5e5c022bde73392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9650 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading\n",
    "dataset = load_dataset('ms_marco','v1.1') # General dataset\n",
    "\n",
    "# Funktion zum Hinzufügen des Labels\n",
    "def add_label(example):\n",
    "    example['label'] = 1\n",
    "    return example\n",
    "\n",
    "# Hinzufügen der Label-Spalte zum Trainingsdatensatz\n",
    "dataset = dataset.map(add_label)\n",
    "\n",
    "#dataset = dataset['train']\n",
    "#ms_marco_data = ms_marco_data['train']\n",
    "#dataset.rename_column('answers','labels')\n",
    "#print(\"dataset\", ms_marco_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4064e2d8-4612-4b1a-a071-16694a62d93d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ecedb8ed-0afe-49fc-a456-51f446a39576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Definition der Preprocess Funktion\n",
    "def preprocess_function(examples):\n",
    "    return teacher_tokenizer(examples[\"query\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "    #return teacher_tokenizer(examples[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a47024a-fbec-490d-a0d4-d1bf619f8458",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Erstellen des Train Datasets\n",
    "#dataset = dataset.rename_column('answers','labels')\n",
    "train_dataset = dataset[\"train\"].map(preprocess_function, batched=True)\n",
    "#eval_dataset = dataset[\"test\"].map(preprocess_function, batched=True)\n",
    "#eval_dataset = dataset[\"test\"].map(batched=True)\n",
    "\n",
    "#train_dataset = train_dataset.remove_columns(['passages', 'query', 'query_id', 'query_type', 'wellFormedAnswers'])\n",
    "#eval_dataset = eval_dataset.remove_columns([\"text\"])\n",
    "\n",
    "\n",
    "# Zeige Beispiele\n",
    "print(\"\\nBeispiel Train Dataset:\\n\")\n",
    "print(train_dataset[1])\n",
    "#print(\"\\nBeispiel Eval Dataset:\\n\")\n",
    "#print(eval_dataset[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640816be-5842-42ac-b415-22c035e225ff",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Dataset imdb (Beispiel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf141b8a-efae-41d1-9c3d-98facd5c3b41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dd4e493-a121-47b4-90fd-d56f9f1db9b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Definition der Preprocess Funktion\n",
    "def preprocess_function(examples):\n",
    "    return teacher_tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=64)\n",
    "    #return teacher_tokenizer(examples[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85a876cf-c5e3-4999-83a9-20ac82198302",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02fddb5ec078427caebdf83ef7067f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Beispiel Train Dataset:\n",
      "\n",
      "{'label': 0, 'input_ids': [1, 376, 29902, 1913, 10837, 2738, 29901, 612, 4743, 29908, 338, 263, 5161, 1821, 322, 14794, 296, 2738, 1886, 11500, 282, 488, 29889, 739, 1838, 29915, 29873, 4383, 825, 697, 29915, 29879, 8604, 8386, 526, 1363, 445, 2706, 508, 15155, 367, 4586, 25798, 373, 738, 3233, 29889, 1094, 363, 278, 5995, 393, 4565, 284, 14263, 302, 566, 537, 338, 385, 18428, 25166, 29899, 29896], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "# Erstellen des Train Datasets\n",
    "\n",
    "train_dataset = dataset[\"train\"].map(preprocess_function, batched=True)\n",
    "\n",
    "#eval_dataset = dataset[\"test\"].map(preprocess_function, batched=True)\n",
    "#eval_dataset = dataset[\"test\"].map(batched=True)\n",
    "\n",
    "train_dataset = train_dataset.remove_columns(['text'])\n",
    "\n",
    "#eval_dataset = eval_dataset.remove_columns([\"text\"])\n",
    "\n",
    "\n",
    "# Zeige Beispiele\n",
    "print(\"\\nBeispiel Train Dataset:\\n\")\n",
    "print(train_dataset[1])\n",
    "\n",
    "#print(\"\\nBeispiel Eval Dataset:\\n\")\n",
    "#print(eval_dataset[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9693ab1-df7c-4003-b7d6-964b6a814b6d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dataset boolq (Yes/no labels)\n",
    "\n",
    "- Bei dem Dataset handelt es sich um Fragen mit Ja/Nein Antworten, die für eine Knowledge Distillation gut geeigent sein sollten\n",
    "- Zur Nutzung für das Training wird die \"answer\" Spalte in Label umbenannt und der Datentyp in ClassLabel verändert. Dies ist nötig, damit der Tensor die richtigen Dimensionen hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab041abd-8a9b-45d0-b205-925a796f6e11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question', 'labels', 'passage'],\n",
      "        num_rows: 9427\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['question', 'labels', 'passage'],\n",
      "        num_rows: 3270\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = load_dataset(\"boolq\")\n",
    "\n",
    "dataset = dataset.rename_column(\"answer\",\"labels\")\n",
    "\n",
    "dataset = dataset.cast_column('labels', ClassLabel(names=[\"False\", \"True\"]))\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92bc1ae-baa3-484f-b15b-defc91088838",
   "metadata": {},
   "source": [
    "#### Mapping des Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f82df6a3-5c9c-4be1-aa89-5934397b0adf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return teacher_tokenizer(examples[\"question\"], truncation=True, padding=\"max_length\", max_length=64)\n",
    "    #return teacher_tokenizer(examples[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f531ef2-ee15-4cc3-ab01-011f583e69f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f7ee028751f44319b2730084d181444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9427 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Beispiel Train Dataset:\n",
      "\n",
      "{'labels': 1, 'input_ids': [1, 437, 1781, 3514, 279, 8929, 14243, 12566, 1906, 1058, 1371, 472, 385, 11423, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset[\"train\"].map(preprocess_function, batched=True)\n",
    "\n",
    "#eval_dataset = dataset[\"test\"].map(preprocess_function, batched=True)\n",
    "#eval_dataset = dataset[\"test\"].map(batched=True)\n",
    "train_dataset = train_dataset.remove_columns('question')\n",
    "train_dataset = train_dataset.remove_columns('passage')\n",
    "# Zeige Beispiele\n",
    "print(\"\\nBeispiel Train Dataset:\\n\")\n",
    "print(train_dataset[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87aed531-1673-46ca-9474-04ece4d3347c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prepare Training and needed functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d25c766-e8c4-4ba8-879a-232919f9fea7",
   "metadata": {},
   "source": [
    "### configure Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01e6a8bb-b396-4ee0-9458-616f564de0f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Definieren der Trainingsargumente\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=1, # optimized for low memory consumption\n",
    "    per_device_eval_batch_size=1,  # optimized for low memory consumption\n",
    "    gradient_accumulation_steps=1, # optimized for low memory consumption\n",
    "    num_train_epochs=5,\n",
    "    seed=42,\n",
    "    remove_unused_columns=False,\n",
    "    fp16=True,                     # optimized for low memory consumption\n",
    "    # evaluation_strategy=\"epoch\",\n",
    "    save_steps=5000,\n",
    "    logging_dir=\"../../work/train/logs\",\n",
    "    output_dir=\"../../work/train/out\"\n",
    ")\n",
    "\n",
    "# Funktion zur Berechnung der distillationsverlust\n",
    "def compute_distillation_loss(student_logits, teacher_logits, temperature=2.0, alpha=0.5):\n",
    "    soft_labels = torch.nn.functional.softmax(teacher_logits / temperature, dim=-1)\n",
    "    soft_loss = torch.nn.functional.kl_div(torch.nn.functional.log_softmax(student_logits / temperature, dim=-1), soft_labels, reduction='batchmean')\n",
    "    hard_loss = torch.nn.functional.cross_entropy(student_logits, torch.argmax(soft_labels, dim=-1))\n",
    "    return alpha * soft_loss + (1.0 - alpha) * hard_loss\n",
    "\n",
    "\n",
    "# Funktion zum Trainieren des Schülermodells\n",
    "def compute_metrics(eval_predictions):\n",
    "    return {\"accuracy\": (eval_predictions.predictions.argmax(axis=1) == eval_predictions.label_ids).mean()}\n",
    "\n",
    "# Definition des Trainerobjekts\n",
    "trainer = Trainer(\n",
    "    model=student_model,\n",
    "    args=training_args,\n",
    "    tokenizer=teacher_tokenizer,\n",
    "    train_dataset=train_dataset,\n",
    "    #eval_dataset=eval_dataset,\n",
    "    data_collator=teacher_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3312824-1f00-4cda-86f2-4325efcabd2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find pumatest.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mthomas-t-schmitt\u001b[0m (\u001b[33mpumaai\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/thsch026/masterarbeit/Slim/notebooks/wandb/run-20240621_161042-kuc98b95</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pumaai/huggingface/runs/kuc98b95' target=\"_blank\">fancy-breeze-109</a></strong> to <a href='https://wandb.ai/pumaai/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pumaai/huggingface' target=\"_blank\">https://wandb.ai/pumaai/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pumaai/huggingface/runs/kuc98b95' target=\"_blank\">https://wandb.ai/pumaai/huggingface/runs/kuc98b95</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thsch026/my-envs/kdein/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16694' max='62500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16694/62500 1:24:57 < 3:53:08, 3.27 it/s, Epoch 1.34/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.373100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.337200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.746900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.701000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.695700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.695400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.757300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.886500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.806200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.749600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.979700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.038500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>1.072200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.084400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>1.084700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>1.091800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>1.130300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>1.092900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>1.061700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.087700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>1.025300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>1.122100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.985200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>1.036600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.951700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.905100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.841000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.930400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.888700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.873700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.867100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.893300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thsch026/my-envs/kdein/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/thsch026/my-envs/kdein/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/thsch026/my-envs/kdein/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "# Trainieren des Schülermodells mit Knowledge Distillation\n",
    "\n",
    "#!export WANDB_NOTEBOOK_NAME=\"pumatest\"\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"pumatest\"\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d98fe80-3f52-4a8a-bf08-5664fa91a628",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, collate_fn=teacher_collator)\n",
    "\n",
    "for batch in train_dataloader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f326e386-3002-4584-be44-fad8d4fd8f28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_path=\"/home/thsch026/masterarbeit/models/generated/kd3\"\n",
    "student_model.save_pretrained(save_path)\n",
    "student_tokenizer.save_pretrained(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86e74ef3-a58a-4b40-8759-8caf23af0479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Memory\n",
    "#del trainer # Specify variable\n",
    "del student_model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16112865-ed7b-4c74-9908-17f2a6af2104",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kdein",
   "language": "python",
   "name": "kdein"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
