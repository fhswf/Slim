huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Collecting dataset
  Downloading dataset-1.6.2-py2.py3-none-any.whl (18 kB)
Collecting sqlalchemy<2.0.0,>=1.3.2 (from dataset)
  Downloading SQLAlchemy-1.4.52-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)
     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [32m1.6/1.6 MB[39m [31m13.9 MB/s[39m eta [36m0:00:00
[?25hRequirement already satisfied: alembic>=0.6.2 in /opt/conda/lib/python3.10/site-packages (from dataset) (1.10.4)
Collecting banal>=1.0.1 (from dataset)
  Downloading banal-1.0.6-py2.py3-none-any.whl (6.1 kB)
Requirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=0.6.2->dataset) (1.2.4)
Requirement already satisfied: typing-extensions>=4 in /home/thsch026/.local/lib/python3.10/site-packages (from alembic>=0.6.2->dataset) (4.11.0)
Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy<2.0.0,>=1.3.2->dataset) (2.0.2)
Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.10/site-packages (from Mako->alembic>=0.6.2->dataset) (2.1.2)
Installing collected packages: banal, sqlalchemy, dataset
  Attempting uninstall: sqlalchemy
    Found existing installation: SQLAlchemy 2.0.13
    Uninstalling SQLAlchemy-2.0.13:
      Successfully uninstalled SQLAlchemy-2.0.13
Successfully installed banal-1.0.6 dataset-1.6.2 sqlalchemy-1.4.52
DatasetDict({
    train: Dataset({
        features: ['question', 'label'],
        num_rows: 9427
    })
    validation: Dataset({
        features: ['question', 'label'],
        num_rows: 3270
    })
})
DatasetDict({
    train: Dataset({
        features: ['question', 'label'],
        num_rows: 9427
    })
    validation: Dataset({
        features: ['question', 'label'],
        num_rows: 3270
    })
})
{'question': 'do good samaritan laws protect those who help at an accident', 'label': True, 'input_ids': [128000, 3055, 1695, 10167, 277, 13145, 7016, 6144, 1884, 889, 1520, 520, 459, 11677, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
Beispiel Train Dataset:
{'question': 'do good samaritan laws protect those who help at an accident', 'label': 1, 'input_ids': [128000, 3055, 1695, 10167, 277, 13145, 7016, 6144, 1884, 889, 1520, 520, 459, 11677, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.