2024-06-25 15:36:38,011 INFO    MainThread:204709 [wandb_setup.py:_flush():76] Current SDK version is 0.17.0
2024-06-25 15:36:38,012 INFO    MainThread:204709 [wandb_setup.py:_flush():76] Configure stats pid to 204709
2024-06-25 15:36:38,012 INFO    MainThread:204709 [wandb_setup.py:_flush():76] Loading settings from /home/thsch026/.config/wandb/settings
2024-06-25 15:36:38,012 INFO    MainThread:204709 [wandb_setup.py:_flush():76] Loading settings from /home/thsch026/masterarbeit/Slim/notebooks/wandb/settings
2024-06-25 15:36:38,013 INFO    MainThread:204709 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'run_notes': '10 Epochs (10.000 steps) MS_Marco 1.1', 'run_name': 'Llama-3-8B Pruned & KD '}
2024-06-25 15:36:38,013 INFO    MainThread:204709 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2024-06-25 15:36:38,013 WARNING MainThread:204709 [wandb_setup.py:_flush():76] Could not save program above cwd: /home/thsch026/my-envs/eval/bin/lm_eval
2024-06-25 15:36:38,014 INFO    MainThread:204709 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': None, 'program_abspath': '/home/thsch026/my-envs/eval/bin/lm_eval', 'program': '/home/thsch026/my-envs/eval/bin/lm_eval'}
2024-06-25 15:36:38,014 INFO    MainThread:204709 [wandb_setup.py:_flush():76] Applying login settings: {}
2024-06-25 15:36:38,014 INFO    MainThread:204709 [wandb_init.py:_log_setup():520] Logging user logs to /home/thsch026/masterarbeit/Slim/notebooks/wandb/run-20240625_153637-nzngrsdp/logs/debug.log
2024-06-25 15:36:38,015 INFO    MainThread:204709 [wandb_init.py:_log_setup():521] Logging internal logs to /home/thsch026/masterarbeit/Slim/notebooks/wandb/run-20240625_153637-nzngrsdp/logs/debug-internal.log
2024-06-25 15:36:38,015 INFO    MainThread:204709 [wandb_init.py:init():560] calling init triggers
2024-06-25 15:36:38,015 INFO    MainThread:204709 [wandb_init.py:init():567] wandb.init called with sweep_config: {}
config: {}
2024-06-25 15:36:38,015 INFO    MainThread:204709 [wandb_init.py:init():610] starting backend
2024-06-25 15:36:38,015 INFO    MainThread:204709 [wandb_init.py:init():614] setting up manager
2024-06-25 15:36:38,019 INFO    MainThread:204709 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2024-06-25 15:36:38,023 INFO    MainThread:204709 [wandb_init.py:init():622] backend started and connected
2024-06-25 15:36:38,030 INFO    MainThread:204709 [wandb_init.py:init():711] updated telemetry
2024-06-25 15:36:38,058 INFO    MainThread:204709 [wandb_init.py:init():744] communicating run to backend with 90.0 second timeout
2024-06-25 15:36:38,490 INFO    MainThread:204709 [wandb_run.py:_on_init():2396] communicating current version
2024-06-25 15:36:38,707 INFO    MainThread:204709 [wandb_run.py:_on_init():2405] got version response upgrade_message: "wandb version 0.17.3 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2024-06-25 15:36:38,708 INFO    MainThread:204709 [wandb_init.py:init():795] starting run threads in backend
2024-06-25 15:36:44,429 INFO    MainThread:204709 [wandb_run.py:_console_start():2374] atexit reg
2024-06-25 15:36:44,430 INFO    MainThread:204709 [wandb_run.py:_redirect():2229] redirect: wrap_raw
2024-06-25 15:36:44,430 INFO    MainThread:204709 [wandb_run.py:_redirect():2294] Wrapping output streams.
2024-06-25 15:36:44,431 INFO    MainThread:204709 [wandb_run.py:_redirect():2319] Redirects installed.
2024-06-25 15:36:44,436 INFO    MainThread:204709 [wandb_init.py:init():838] run started, returning control to user process
2024-06-25 15:48:45,036 INFO    MainThread:204709 [wandb_run.py:_config_callback():1376] config_cb None None {'task_configs': {'arc_challenge': {'task': 'arc_challenge', 'group': ['ai2_arc'], 'dataset_path': 'allenai/ai2_arc', 'dataset_name': 'ARC-Challenge', 'training_split': 'train', 'validation_split': 'validation', 'test_split': 'test', 'doc_to_text': 'Question: {{question}}\nAnswer:', 'doc_to_target': '{{choices.label.index(answerKey)}}', 'doc_to_choice': '{{choices.text}}', 'description': '', 'target_delimiter': ' ', 'fewshot_delimiter': '\n\n', 'num_fewshot': 0, 'metric_list': [{'metric': 'acc', 'aggregation': 'mean', 'higher_is_better': True}, {'metric': 'acc_norm', 'aggregation': 'mean', 'higher_is_better': True}], 'output_type': 'multiple_choice', 'repeats': 1, 'should_decontaminate': True, 'doc_to_decontamination_query': 'Question: {{question}}\nAnswer:', 'metadata': {'version': 1.0}}, 'gsm8k': {'task': 'gsm8k', 'group': ['math_word_problems'], 'dataset_path': 'gsm8k', 'dataset_name': 'main', 'training_split': 'train', 'test_split': 'test', 'fewshot_split': 'train', 'doc_to_text': 'Question: {{question}}\nAnswer:', 'doc_to_target': '{{answer}}', 'description': '', 'target_delimiter': ' ', 'fewshot_delimiter': '\n\n', 'num_fewshot': 5, 'metric_list': [{'metric': 'exact_match', 'aggregation': 'mean', 'higher_is_better': True, 'ignore_case': True, 'ignore_punctuation': False, 'regexes_to_ignore': [',', '\\$', '(?s).*#### ', '\\.$']}], 'output_type': 'generate_until', 'generation_kwargs': {'until': ['Question:', '</s>', '<|im_end|>'], 'do_sample': False, 'temperature': 0.0}, 'repeats': 1, 'filter_list': [{'name': 'strict-match', 'filter': [{'function': 'regex', 'regex_pattern': '#### (\\-?[0-9\\.\\,]+)'}, {'function': 'take_first'}]}, {'name': 'flexible-extract', 'filter': [{'function': 'regex', 'group_select': -1, 'regex_pattern': '(-?[$0-9.,]{2,})|(-?[0-9]+)'}, {'function': 'take_first'}]}], 'should_decontaminate': False, 'metadata': {'version': 3.0}}, 'hellaswag': {'task': 'hellaswag', 'group': ['multiple_choice'], 'dataset_path': 'hellaswag', 'training_split': 'train', 'validation_split': 'validation', 'process_docs': 'def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _process_doc(doc):\n        ctx = doc["ctx_a"] + " " + doc["ctx_b"].capitalize()\n        out_doc = {\n            "query": preprocess(doc["activity_label"] + ": " + ctx),\n            "choices": [preprocess(ending) for ending in doc["endings"]],\n            "gold": int(doc["label"]),\n        }\n        return out_doc\n\n    return dataset.map(_process_doc)\n', 'doc_to_text': '{{query}}', 'doc_to_target': '{{label}}', 'doc_to_choice': 'choices', 'description': '', 'target_delimiter': ' ', 'fewshot_delimiter': '\n\n', 'num_fewshot': 0, 'metric_list': [{'metric': 'acc', 'aggregation': 'mean', 'higher_is_better': True}, {'metric': 'acc_norm', 'aggregation': 'mean', 'higher_is_better': True}], 'output_type': 'multiple_choice', 'repeats': 1, 'should_decontaminate': False, 'metadata': {'version': 1.0}}, 'truthfulqa_mc2': {'task': 'truthfulqa_mc2', 'group': ['truthfulqa'], 'dataset_path': 'truthful_qa', 'dataset_name': 'multiple_choice', 'validation_split': 'validation', 'doc_to_text': "{% set prompt_qa = 'Q: What is human life expectancy in the United States?\nA: Human life expectancy in the United States is 78 years.\n\nQ: Who was president of the United States in 1955?\nA: Dwight D. Eisenhower was president of the United States in 1955.\n\nQ: Which party did he belong to?\nA: He belonged to the Republican Party.\n\nQ: What is the square root of banana?\nA: I have no comment.\n\nQ: How does a telescope work?\nA: Telescopes use lenses or mirrors to focus light and make objects appear closer.\n\nQ: Where were the 1992 Olympics held?\nA: The 1992 Olympics were held in Barcelona, Spain.'%}{{prompt_qa + '\n\nQ: ' + question + '\nA:'}}", 'doc_to_target': 0, 'doc_to_choice': '{{mc2_targets.choices}}', 'process_results': 'def process_results_mc2(doc, results):\n    lls, is_greedy = zip(*results)\n\n    # Split on the first `0` as everything before it is true (`1`).\n    split_idx = list(doc["mc2_targets"]["labels"]).index(0)\n    # Compute the normalized probability mass for the correct answer.\n    ll_true, ll_false = lls[:split_idx], lls[split_idx:]\n    p_true, p_false = np.exp(np.array(ll_true)), np.exp(np.array(ll_false))\n    p_true = p_true / (sum(p_true) + sum(p_false))\n\n    return {"acc": sum(p_true)}\n', 'description': '', 'target_delimiter': ' ', 'fewshot_delimiter': '\n\n', 'num_fewshot': 0, 'metric_list': [{'metric': 'acc', 'aggregation': 'mean', 'higher_is_better': True}], 'output_type': 'multiple_choice', 'repeats': 1, 'should_decontaminate': True, 'doc_to_decontamination_query': 'question', 'metadata': {'version': 2.0}}, 'winogrande': {'task': 'winogrande', 'dataset_path': 'winogrande', 'dataset_name': 'winogrande_xl', 'training_split': 'train', 'validation_split': 'validation', 'doc_to_text': 'def doc_to_text(doc):\n    answer_to_num = {"1": 0, "2": 1}\n    return answer_to_num[doc["answer"]]\n', 'doc_to_target': 'def doc_to_target(doc):\n    idx = doc["sentence"].index("_") + 1\n    return doc["sentence"][idx:].strip()\n', 'doc_to_choice': 'def doc_to_choice(doc):\n    idx = doc["sentence"].index("_")\n    options = [doc["option1"], doc["option2"]]\n    return [doc["sentence"][:idx] + opt for opt in options]\n', 'description': '', 'target_delimiter': ' ', 'fewshot_delimiter': '\n\n', 'num_fewshot': 0, 'metric_list': [{'metric': 'acc', 'aggregation': 'mean', 'higher_is_better': True}], 'output_type': 'multiple_choice', 'repeats': 1, 'should_decontaminate': True, 'doc_to_decontamination_query': 'sentence', 'metadata': {'version': 1.0}}}, 'cli_configs': {'model': 'hf', 'model_args': 'pretrained=/home/thsch026/masterarbeit/Slim/notebooks/llama2_distilled/checkpoint-9428,tokenizer=/home/thsch026/masterarbeit/Slim/notebooks/llama2_distilled/checkpoint-9428,dtype=float16', 'model_num_parameters': 1100048384, 'model_dtype': 'torch.float16', 'model_revision': 'main', 'model_sha': '', 'batch_size': 'auto', 'batch_sizes': [64], 'device': 'cuda:2', 'use_cache': None, 'limit': None, 'bootstrap_iters': 100000, 'gen_kwargs': None, 'random_seed': 0, 'numpy_seed': 1234, 'torch_seed': 1234, 'fewshot_seed': 1234}}
2024-06-25 15:48:58,243 INFO    MainThread:204709 [wandb_run.py:_finish():2103] finishing run pumaai/lm-eval-harness-integration/nzngrsdp
2024-06-25 15:48:58,244 INFO    MainThread:204709 [wandb_run.py:_atexit_cleanup():2343] got exitcode: 0
2024-06-25 15:48:58,245 INFO    MainThread:204709 [wandb_run.py:_restore():2326] restore
2024-06-25 15:48:58,246 INFO    MainThread:204709 [wandb_run.py:_restore():2332] restore done
2024-06-25 15:49:26,376 INFO    MainThread:204709 [wandb_run.py:_footer_history_summary_info():3994] rendering history
2024-06-25 15:49:26,378 INFO    MainThread:204709 [wandb_run.py:_footer_history_summary_info():4026] rendering summary
2024-06-25 15:49:26,399 INFO    MainThread:204709 [wandb_run.py:_footer_sync_info():3953] logging synced files
